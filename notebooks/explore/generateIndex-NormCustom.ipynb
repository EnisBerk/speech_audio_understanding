{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generates annoy indexes and related function caches. Forked from explore/generateIndex.ipynb\n",
    "\n",
    "TODO merge with explore/generateIndex.ipynb\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from nna.fileUtils import list_files,save_to_csv\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/enis/projects/similarSoundsApp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('/home/enis/projects/similarSoundsApp/'))\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnSearch import loadOnDisk,buildOnDisk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexIDname = \"photoEmbeddings_V3_norm_euc_custom\"\n",
    "\n",
    "outputFolder = Path(\"/scratch/enis/data/nna/realMerged/\")\n",
    "metadataCSV = outputFolder / (indexIDname+\".csv\")\n",
    "fn = outputFolder / (indexIDname+\".ann\")\n",
    "\n",
    "# vector size\n",
    "f=128\n",
    "  # Length of item vector that will be indexed\n",
    "# distance='hamming'\n",
    "distance='euclidean'\n",
    "\n",
    "#prepares annoy to build the index in the specified file instead of RAM \n",
    "#(execute before adding items, no need to save after build)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load embeddings to memory\n",
    "#### 1.0) find images so we can just load embeddings from these locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load datasets\n",
    "realFolderPath=\"/scratch/enis/data/nna/real/\"\n",
    "\n",
    "\n",
    "# Look where the images are so we index only these locations\n",
    "pathDatasets = \"/home/enis/projects/similarSoundsApp/resources/TimeLapse_Databases/\"\n",
    "datasetList=[[m for m in i.glob(\"*\") if \".ddb\" in str(m) ][0] for i in (Path(pathDatasets).glob(\"*\"))]\n",
    "# locations with only images\n",
    "labeledImgLocations = [m.parent.stem for m in datasetList]\n",
    "# all existing locations\n",
    "region_locId=[[m for m in i.glob(\"*\") if m.is_dir() ] for i in (Path(realFolderPath).glob(\"*\")) if i.is_dir()]\n",
    "\n",
    "#keep locations only with images\n",
    "allLocations=[]\n",
    "for m in region_locId:\n",
    "    for n in m:\n",
    "        if n.stem in labeledImgLocations:\n",
    "            allLocations.append(n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/scratch/enis/data/nna/real/anwr/46'),\n",
       " PosixPath('/scratch/enis/data/nna/real/anwr/31'),\n",
       " PosixPath('/scratch/enis/data/nna/real/anwr/36'),\n",
       " PosixPath('/scratch/enis/data/nna/real/anwr/38'),\n",
       " PosixPath('/scratch/enis/data/nna/real/anwr/32'),\n",
       " PosixPath('/scratch/enis/data/nna/real/anwr/45'),\n",
       " PosixPath('/scratch/enis/data/nna/real/anwr/48'),\n",
       " PosixPath('/scratch/enis/data/nna/real/anwr/42'),\n",
       " PosixPath('/scratch/enis/data/nna/real/anwr/35'),\n",
       " PosixPath('/scratch/enis/data/nna/real/anwr/40'),\n",
       " PosixPath('/scratch/enis/data/nna/real/anwr/37'),\n",
       " PosixPath('/scratch/enis/data/nna/real/anwr/50'),\n",
       " PosixPath('/scratch/enis/data/nna/real/anwr/34'),\n",
       " PosixPath('/scratch/enis/data/nna/real/anwr/33'),\n",
       " PosixPath('/scratch/enis/data/nna/real/prudhoe/11'),\n",
       " PosixPath('/scratch/enis/data/nna/real/prudhoe/29'),\n",
       " PosixPath('/scratch/enis/data/nna/real/prudhoe/24'),\n",
       " PosixPath('/scratch/enis/data/nna/real/prudhoe/16'),\n",
       " PosixPath('/scratch/enis/data/nna/real/prudhoe/12'),\n",
       " PosixPath('/scratch/enis/data/nna/real/prudhoe/27'),\n",
       " PosixPath('/scratch/enis/data/nna/real/prudhoe/15'),\n",
       " PosixPath('/scratch/enis/data/nna/real/prudhoe/17'),\n",
       " PosixPath('/scratch/enis/data/nna/real/prudhoe/22'),\n",
       " PosixPath('/scratch/enis/data/nna/real/prudhoe/26'),\n",
       " PosixPath('/scratch/enis/data/nna/real/prudhoe/14'),\n",
       " PosixPath('/scratch/enis/data/nna/real/prudhoe/13'),\n",
       " PosixPath('/scratch/enis/data/nna/real/prudhoe/19')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allLocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 find embeddings in the given locations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20029\n"
     ]
    }
   ],
   "source": [
    "# filenamePattern=\"*_embeddings*.npy\"\n",
    "filenamePattern=\"*_rawembeddings*.npy\"\n",
    "\n",
    "all_embeddings=[]\n",
    "for loc in allLocations:\n",
    "    # find all files\n",
    "    search_path=loc\n",
    "    all_embeddings+=list_files(str(search_path),filename=filenamePattern)\n",
    "\n",
    "print(len(all_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/scratch/enis/data/nna/real/anwr/46/2019/S4A10290_20190504_000000_vgg/S4A10290_20190504_000000_rawembeddings000.npy',\n",
       " '/scratch/enis/data/nna/real/anwr/46/2019/S4A10290_20190504_011602_vgg/S4A10290_20190504_011602_rawembeddings000.npy',\n",
       " '/scratch/enis/data/nna/real/anwr/46/2019/S4A10290_20190504_043000_vgg/S4A10290_20190504_043000_rawembeddings000.npy',\n",
       " '/scratch/enis/data/nna/real/anwr/46/2019/S4A10290_20190504_054602_vgg/S4A10290_20190504_054602_rawembeddings000.npy',\n",
       " '/scratch/enis/data/nna/real/anwr/46/2019/S4A10290_20190504_093000_vgg/S4A10290_20190504_093000_rawembeddings000.npy',\n",
       " '/scratch/enis/data/nna/real/anwr/46/2019/S4A10290_20190504_104602_vgg/S4A10290_20190504_104602_rawembeddings000.npy',\n",
       " '/scratch/enis/data/nna/real/anwr/46/2019/S4A10290_20190504_140000_vgg/S4A10290_20190504_140000_rawembeddings000.npy',\n",
       " '/scratch/enis/data/nna/real/anwr/46/2019/S4A10290_20190504_151602_vgg/S4A10290_20190504_151602_rawembeddings000.npy',\n",
       " '/scratch/enis/data/nna/real/anwr/46/2019/S4A10290_20190504_190000_vgg/S4A10290_20190504_190000_rawembeddings000.npy',\n",
       " '/scratch/enis/data/nna/real/anwr/46/2019/S4A10290_20190504_201602_vgg/S4A10290_20190504_201602_rawembeddings000.npy']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by loc and time \n",
    "# loc: locationID\n",
    "# time: calendar day\n",
    "\n",
    "all_embeddings[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemSet=set()\n",
    "regionSet=set()\n",
    "locationIDset=set()\n",
    "timeGroupset = set()\n",
    "all_embeddingsItemDict = {}\n",
    "for m in all_embeddings:\n",
    "    splitList = m.split(\"/\")\n",
    "    region=splitList[6]\n",
    "    locationID = splitList[7]\n",
    "    timeGroup = splitList[9].split(\"_\")[1]\n",
    "    items = (region,locationID,timeGroup)\n",
    "    itemSet.add(items)\n",
    "    all_embeddingsItemDict.setdefault(items,[])\n",
    "    all_embeddingsItemDict[items].append(m)\n",
    "    regionSet.add(region)\n",
    "    locationIDset.add(locationID)\n",
    "    timeGroupset.add(timeGroup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/scratch/enis/data/nna/real/anwr/32/2019/S4A10266_20190512_003000_vgg/S4A10266_20190512_003000_rawembeddings000.npy',\n",
       " '/scratch/enis/data/nna/real/anwr/32/2019/S4A10266_20190512_014602_vgg/S4A10266_20190512_014602_rawembeddings000.npy',\n",
       " '/scratch/enis/data/nna/real/anwr/32/2019/S4A10266_20190512_053000_vgg/S4A10266_20190512_053000_rawembeddings000.npy',\n",
       " '/scratch/enis/data/nna/real/anwr/32/2019/S4A10266_20190512_064602_vgg/S4A10266_20190512_064602_rawembeddings000.npy',\n",
       " '/scratch/enis/data/nna/real/anwr/32/2019/S4A10266_20190512_100000_vgg/S4A10266_20190512_100000_rawembeddings000.npy',\n",
       " '/scratch/enis/data/nna/real/anwr/32/2019/S4A10266_20190512_111602_vgg/S4A10266_20190512_111602_rawembeddings000.npy',\n",
       " '/scratch/enis/data/nna/real/anwr/32/2019/S4A10266_20190512_150000_vgg/S4A10266_20190512_150000_rawembeddings000.npy',\n",
       " '/scratch/enis/data/nna/real/anwr/32/2019/S4A10266_20190512_161602_vgg/S4A10266_20190512_161602_rawembeddings000.npy',\n",
       " '/scratch/enis/data/nna/real/anwr/32/2019/S4A10266_20190512_193000_vgg/S4A10266_20190512_193000_rawembeddings000.npy',\n",
       " '/scratch/enis/data/nna/real/anwr/32/2019/S4A10266_20190512_204602_vgg/S4A10266_20190512_204602_rawembeddings000.npy']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embeddingsItemDict[list(itemSet)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regionSet,locationIDset,timeGroupset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index=0\n",
    "# for group_embed in all_embeddingsItemDict.values():\n",
    "#     group_embedLoaded = []\n",
    "#     for embed_file in (group_embed):\n",
    "#         embed = np.load(embed_file)\n",
    "#         group_embedLoaded.append(embed)\n",
    "#     XX = np.concatenate(group_embedLoaded)\n",
    "#     XX_normalized = preprocessing.normalize(XX, norm='l2')\n",
    "#     for ii in range(XX_normalized.shape[0]):\n",
    "#         t.add_item(index, XX_normalized[ii, :])\n",
    "#         index += 1\n",
    "    \n",
    "#     break\n",
    "    \n",
    "# for i, embed_file in enumerate(all_embeddings):\n",
    "#     embed = np.load(embed_file)\n",
    "#     for ii in range(embed.shape[0]):\n",
    "#         t.add_item(index, embed[ii, :])\n",
    "#         index += 1\n",
    "#     if i % 1000 == 0:\n",
    "#         print(\"Current index:\", i)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XX = np.concatenate(group_embedLoaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49550, 128)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4560, 128)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(itemSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of embeddings 11235 for photoEmbeddings_V1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) save metadata, embedding file names and sizes as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedSizes=[]\n",
    "for i,embed_file in enumerate(all_embeddings):\n",
    "    embed=np.load(embed_file)\n",
    "    embedSizes.append(embed.shape[0])\n",
    "\n",
    "metadata = list(zip(all_embeddings,embedSizes))\n",
    "save_to_csv(metadataCSV,metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n",
    "\n",
    "def buildOnDisk(all_embeddings, filePath, vectorLen,distance='euclidean', seed=42, treeN=16):\n",
    "    filePath = str(filePath)\n",
    "    t = AnnoyIndex(vectorLen, distance)\n",
    "    t.on_disk_build(filePath)\n",
    "    index = 0\n",
    "    for i, embed_file in enumerate(all_embeddings):\n",
    "        embed = np.load(embed_file)\n",
    "        for ii in range(embed.shape[0]):\n",
    "            t.add_item(index, embed[ii, :])\n",
    "            index += 1\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Current index:\", i)\n",
    "        # build index\n",
    "    t.set_seed(seed)\n",
    "    t.build(treeN)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n",
    "from sklearn import preprocessing\n",
    "def buildOnDiskV2(all_embeddingsItemDict, filePath, vectorLen,distance='euclidean', seed=42, treeN=16):\n",
    "    filePath = str(filePath)\n",
    "    t = AnnoyIndex(vectorLen, distance)\n",
    "    t.on_disk_build(filePath)\n",
    "    index = 0\n",
    "    for group_embed in all_embeddingsItemDict.values():\n",
    "        group_embedLoaded = []\n",
    "        for embed_file in (group_embed):\n",
    "            embed = np.load(embed_file)\n",
    "            group_embedLoaded.append(embed)\n",
    "        XX = np.concatenate(group_embedLoaded)\n",
    "        XX_normalized = preprocessing.normalize(XX, norm='l2')\n",
    "        for ii in range(XX_normalized.shape[0]):\n",
    "            t.add_item(index, XX_normalized[ii, :])\n",
    "            index += 1\n",
    "        if index % 10**5 == 0:\n",
    "            print(\"Current index:\", i)\n",
    "\n",
    "    t.set_seed(seed)\n",
    "    t.build(treeN)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2) Create and save annoy index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=Path(fn)\n",
    "fn=str(fn)\n",
    "if p.exists():\n",
    "    print(p,\"EXISTS\")\n",
    "    t = loadOnDisk(fn,f,distance=distance)\n",
    "else:\n",
    "    t = buildOnDiskV2(all_embeddingsItemDict,fn,f,distance=distance,seed=42,treeN=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) create functions caches depending on the Index and Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1) npy2originalFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allEmbeddings_prudhoe26_V11.csv  photoEmbeddings_V1.csv\n",
      "allEmbeddingsV11.ann\t\t photoEmbeddings_V2_hamming.ann\n",
      "allEmbeddings_V11.csv\t\t photoEmbeddings_V2_hamming.csv\n",
      "photoEmbeddings_V1.ann\t\t prudhoe26_V11.ann\n"
     ]
    }
   ],
   "source": [
    "!ls /scratch/enis/data/nna/realMerged/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "#### LOAD corresponding metadata if different or new\n",
    "\n",
    "# indexIDname = \"photoEmbeddings_V1\"\n",
    "# outputFolder = Path(\"/scratch/enis/data/nna/realMerged/\")\n",
    "# metadataCSV = outputFolder / (indexIDname+\".csv\")\n",
    "# fn = outputFolder / (indexIDname+\".ann\")\n",
    "\n",
    "# metadata=[]\n",
    "# with open(metadataCSV) as csv_file:\n",
    "#     csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "#     for row in csv_reader:\n",
    "#         metadata.append((row[0], int(row[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NNA folder\n",
    "nnaProjectDataFolder = Path(\"/home/enis/projects/nna/data/\")\n",
    "\n",
    "# name and folder of the cached function  file\n",
    "npy2originalFileCacheFileName = \"npy2originalFileCache_\"+indexIDname+\".pkl\"\n",
    "pklPath = nnaProjectDataFolder / \"funcCache\" / npy2originalFileCacheFileName\n",
    "\n",
    "\n",
    "# parameters for the npy2originalFile\n",
    "# file_properties_df_FilePath = nnaProjectDataFolder / \"allFields_dataV3.pkl\"\n",
    "file_properties_df_FilePath = nnaProjectDataFolder / \"prudhoeAndAnwr4photoExp_dataV1.pkl\"\n",
    "\n",
    "\n",
    "\n",
    "embeddataPath=\"/scratch/enis/data/nna/real/\"\n",
    "outputPath=embeddataPath\n",
    "inputPath=\"/tank/data/nna/real/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_properties_df_FilePath='/home/enis/projects/nna/data/prudhoeAndAnwr4photoExp_dataV1.pkl'\n",
    "file_properties_df = pd.read_pickle(str(file_properties_df_FilePath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nna.fileUtils import npy2originalfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npy2originalFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters ,inputPath,outputPath,file_properties_df\n",
    "\n",
    "npy2originalFileCache={}\n",
    "for i,meta in enumerate(metadata):\n",
    "    orgFilePath = npy2originalfile(Path(meta[0]),outputPath,\n",
    "                                               file_properties_df,                                               debug=0)\n",
    "    npy2originalFileCache[meta[0]] = orgFilePath\n",
    "    if i%1000==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[None,inputPath,outputPath,str(file_properties_df_FilePath),None,None,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy2originalFileCache[\"params\"] = [None,inputPath,outputPath,str(file_properties_df_FilePath),None,None,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open(pklPath, 'wb') as handle:\n",
    "    pickle.dump(npy2originalFileCache, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    \n",
    "with open(pklPath, 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "\n",
    "print (npy2originalFileCache == b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pklPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADD INFO OF SOUND EXISTENCE TO IMG DATATABLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search import findFileGetIndex\n",
    "from utils import loadFiles\n",
    "from paramsExample import *\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(file_properties_df, imgOnlyDate, metadata,\n",
    "NNIndexbyAnnoy, funcCache, dictNumpyTables,\n",
    "dictDataTable,file_time_locationDict) = loadFiles(file_properties_df_FilePath, imageInfo, metadatCsv,\n",
    "                                                   annoyIndexPath, vectorSize, distance,\n",
    "                                                   npy2originalFileCacheFilePath, dictDataTablePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "handleQueryRequest_params = {\n",
    "    \"file_properties_df\":file_properties_df,\n",
    "    \"metadata\" : metadata,\n",
    "    \"embeddataPath\" : embeddataPath,\n",
    "    \"NNIndexbyAnnoy\" : NNIndexbyAnnoy,\n",
    "    \"split_folder\" : split_folder,\n",
    "    \"inputPath\" : inputPath,\n",
    "    \"outputPath\" : outputPath,\n",
    "    \"searchDepth\":searchDepth,\n",
    "    \"outputCount\":outputCount,\n",
    "    \"queryLen\":queryLen,\n",
    "    \"saveFiles\":saveFiles,\n",
    "    \"debug\":debug,\n",
    "    \"funcCache\":funcCache\n",
    "}\n",
    "\n",
    "scoresPerImage_params={\n",
    "    \"buffer4ImageMatch\":buffer4ImageMatch,\n",
    "    \"file_time_locationDict\":file_time_locationDict,\n",
    "    \"dictNumpyTables\":dictNumpyTables\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nna.fileUtils import find_filesv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/enis/projects/nna/data/prudhoeAndAnwr4photoExp_dataV1.pkl')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFileGetIndex(location,start_time,end_time,queryLen,\n",
    "                     buffer,file_properties_df,metadata,embeddataPath):\n",
    "    # time-> mp3,flac(original file) -> embed name 000.npy -> embed index\n",
    "    end_time=start_time+datetime.timedelta(queryLen)\n",
    "\n",
    "    output = find_filesv2(location,start_time,end_time,queryLen,buffer,file_properties_df)\n",
    "#     sorted_filtered,start_time,end_time,start_time_org,end_time_org = output\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleQueryRequest(location,year,month,day,hour,minute,second,file_properties_df,\n",
    "                        metadata,embeddataPath,NNIndexbyAnnoy,split_folder,inputPath,\n",
    "                        outputPath,\n",
    "                        searchDepth=2,outputCount=5,theta4GroupbyResults=2,\n",
    "                        queryLen=10,saveFiles=True,debug=0,buffer=0,funcCache=None):\n",
    "#     #### values from search\n",
    "#     # /prudhoe/26/2019/S4A10255_20190507_073000_vgg\n",
    "#     location=\"26\"\n",
    "#     year=2019;month=5;day=7;hour=7;minute=31;second=10\n",
    "#     queryLen=10\n",
    "#     ####\n",
    "    if funcCache==None:\n",
    "        funcCache = {}\n",
    "\n",
    "    start_time=datetime.datetime(year=year,month=month,day=day,\n",
    "                                 hour=hour,minute=minute,second=second)\n",
    "    end_time=start_time+datetime.timedelta(queryLen)\n",
    "    output = findFileGetIndex(location,start_time,end_time,\n",
    "                                        queryLen,buffer,file_properties_df,\n",
    "                                        metadata,embeddataPath)\n",
    "#     embeddingFileIndex=int(embeddingFileIndex)\n",
    "# #     print(embeddingFileIndex)\n",
    "#     if embeddingFileIndex<queryLen:\n",
    "#         if debug>0: print(\"file not found\")\n",
    "#         return []\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "1000 32.66358995437622\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-ad4f5289de8e>\u001b[0m in \u001b[0;36mhandleQueryRequest\u001b[0;34m(location, year, month, day, hour, minute, second, file_properties_df, metadata, embeddataPath, NNIndexbyAnnoy, split_folder, inputPath, outputPath, searchDepth, outputCount, theta4GroupbyResults, queryLen, saveFiles, debug, buffer, funcCache)\u001b[0m\n\u001b[1;32m     18\u001b[0m     output = findFileGetIndex(location,start_time,end_time,\n\u001b[1;32m     19\u001b[0m                                         \u001b[0mqueryLen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_properties_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                                         metadata,embeddataPath)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m#     embeddingFileIndex=int(embeddingFileIndex)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# #     print(embeddingFileIndex)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-851039210335>\u001b[0m in \u001b[0;36mfindFileGetIndex\u001b[0;34m(location, start_time, end_time, queryLen, buffer, file_properties_df, metadata, embeddataPath)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mend_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueryLen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_filesv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mqueryLen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_properties_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#     sorted_filtered,start_time,end_time,start_time_org,end_time_org = output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/nna/src/nna/fileUtils.py\u001b[0m in \u001b[0;36mfind_filesv2\u001b[0;34m(location, start_time, end_time, length, buffer, file_properties_df)\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0mbeginning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0mstart_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msite_filtered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msite_filtered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mbeginning\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m     \u001b[0mtime_site_filtered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msite_filtered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msite_filtered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mbeginning\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mtime_site_filtered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_site_filtered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime_site_filtered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/enis/conda/envs/speechEnv/lib/python3.7/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/enis/conda/envs/speechEnv/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/enis/conda/envs/speechEnv/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36m_construct_result\u001b[0;34m(left, result, index, name)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;31m#  does inference in the case where `result` has object-dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Set the result's name after __finalize__ is called because __finalize__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# def runExp_V1(file_properties_df,dictDataTable,handleQueryRequest_params,scoresPerImage_params):\n",
    "# allResults={}\n",
    "c=0\n",
    "s=time.time()\n",
    "for loc,dataTable in list(dictDataTable.items())[2:]:\n",
    "    print(loc)\n",
    "    audioNotFound=0\n",
    "\n",
    "#     results4Location={}\n",
    "#     cc = dataTable[dataTable[\"Caribou\"]>0]\n",
    "    location=loc\n",
    "    queryLen=10\n",
    "    for ID,timestamp in (zip(dataTable[\"Id\"],dataTable[\"timestamp\"])):\n",
    "\n",
    "        year,month,day,hour,minute,second = (timestamp.year,\n",
    "                                            timestamp.month,timestamp.day,\n",
    "                                            timestamp.hour,timestamp.minute,timestamp.second)\n",
    "\n",
    "        output = handleQueryRequest(location,year,month,day,hour,minute,second,**handleQueryRequest_params)\n",
    "        output = ([str(i) for i in output[0].index.values]+list(output[1:]))\n",
    "        if len(output)>4:\n",
    "            if allResults2[(location,timestamp)] != (output[0],output[1]):\n",
    "                print((location,timestamp))\n",
    "                break\n",
    "\n",
    "        c+=1\n",
    "        if c%1000==0:\n",
    "            e=time.time()\n",
    "            print(c,e-s)\n",
    "            s=time.time()\n",
    "\n",
    "\n",
    "#     allResults[loc] = results4Location.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allResults2={}\n",
    "for loc,IDs in allResults.items():\n",
    "    if loc==\"params\":\n",
    "        continue\n",
    "    for ID,output in IDs.items():\n",
    "        \n",
    "        if len(output)>4:\n",
    "#             print(loc,ID,output)\n",
    "            allResults2[(loc,output[-2])] = (output[0],output[1])\n",
    "        else:\n",
    "            allResults2[(loc,output[-2])] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "allResults2[\"params\"] = [None,None,None,10,0,str(file_properties_df_FilePath)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_filesv2CacheFolderPath = nnaProjectDataFolder / \"funcCache\"\n",
    "# allResultsPath.parent.mkdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "find_filesv2CacheFilePath = find_filesv2CacheFolderPath /  (\"_\".join([\"find_filesv2func_cache\",timestr])+\".pkl\")\n",
    "\n",
    "with open(find_filesv2CacheFilePath, 'wb') as handle:\n",
    "    pickle.dump(allResults2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE paramsExample.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "992711"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=list(allResults2.values())[130:131][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "site_id                          38\n",
       "locationId                       38\n",
       "site_name                          \n",
       "recorderId                 S4A10270\n",
       "hour_min_sec                 000000\n",
       "year                           2019\n",
       "month                            05\n",
       "day                              04\n",
       "region                         anwr\n",
       "timestamp       2019-05-04 00:00:00\n",
       "durationSec                    4560\n",
       "timestampEnd    2019-05-04 01:16:00\n",
       "Name: /tank/data/nna/real/anwr/38/2019/S4A10270_20190504_000000.flac, dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(file_properties_df.loc[Path('/tank/data/nna/real/anwr/38/2019/S4A10270_20190504_000000.flac')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "site_id                          17\n",
       "locationId                       17\n",
       "site_name                          \n",
       "recorderId                 S4A10307\n",
       "hour_min_sec                 221602\n",
       "year                           2019\n",
       "month                            07\n",
       "day                              31\n",
       "region                      prudhoe\n",
       "timestamp       2019-07-31 22:16:02\n",
       "durationSec                    4438\n",
       "timestampEnd    2019-07-31 23:30:00\n",
       "Name: /tank/data/nna/real/prudhoe/17/2019/S4A10307_20190731_221602.flac, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_properties_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_filteredSeries = file_properties_df.loc[Path(output[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "site_id                          38\n",
       "locationId                       38\n",
       "site_name                          \n",
       "recorderId                 S4A10270\n",
       "hour_min_sec                 000000\n",
       "year                           2019\n",
       "month                            05\n",
       "day                              04\n",
       "region                         anwr\n",
       "timestamp       2019-05-04 00:00:00\n",
       "durationSec                    4560\n",
       "timestampEnd    2019-05-04 01:16:00\n",
       "Name: /tank/data/nna/real/anwr/38/2019/S4A10270_20190504_000000.flac, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_filteredSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'38'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_filteredSeries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/tank/data/nna/real/prudhoe/17/2019/S4A10307_20190731_221602.flac')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_properties_df.iloc[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/tank/data/nna/real/anwr/38/2019/S4A10270_20190504_000000.flac')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_filteredSeries.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-05-04 00:00:00')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_filteredSeries.timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechEnv",
   "language": "python",
   "name": "speechenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
