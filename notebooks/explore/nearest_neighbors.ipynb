{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../nna/src'))\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import datetime \n",
    "import os\n",
    "\n",
    "\n",
    "from fileUtils import read_file_properties_v2,find_filesv2,list_files,get_labeled_exif\n",
    "from fileUtils import get_audio,str2timestamp,query_audio\n",
    "from labeling_utils import splitmp3\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np\n",
    "\n",
    "from pydub import AudioSegment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import paired_distances\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "\n",
    "def paired_distances_broadcast(X,Y):\n",
    "    return paired_distances(np.repeat(X,Y.shape[0],axis=0), Y)\n",
    "\n",
    "\n",
    "def sigmoid(X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "\n",
    "def sigmoidT(X,t):\n",
    "    return 1/(1+np.exp(-X*t))\n",
    "\n",
    "def dist2sim(results,gamma=1/512):\n",
    "    return np.exp(-results*gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = find_filesv2(location,start_time,end_time,length,0,file_properties_df)\n",
    "# sorted_filtered,start_time,end_time,start_time_org,end_time_org = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find the embedding for a given image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_path=\"/home/enis/projects/nna/data/cameraTraps/test.txt\"\n",
    "\n",
    "# with open(p_path) as p_file:\n",
    "#     photo_paths=p_file.readlines()\n",
    "#     photo_paths = [i.strip() for i in photo_paths]\n",
    "\n",
    "# other_folder=[\"anwr_35_2019_101RECNX_RCNX3373.JPG\",\n",
    "# \"anwr_42_2019_100RECNX_RCNX3574.JPG\",\n",
    "# \"ivvavik_SINP03_2019_100RECNX_IMG_3219.JPG\",\n",
    "# \"ivvavik_SINP05_2019_100RECNX_IMG_2867.JPG\",\n",
    "# \"ivvavik_SINP06_2019_100RECNX_IMG_1884.JPG\",\n",
    "# \"ivvavik_SINP09_2019_100RECNX_IMG_2743.JPG\",\n",
    "# \"prudhoe_17_2019_100RECNX_RCNX3916.JPG\",]\n",
    "\n",
    "# parent_path1=\"/tank/data/nna/examples/randomPhotos10k/\"\n",
    "# parent_path2=\"/tank/data/nna/examples/randomPhotos1k/\"\n",
    "\n",
    "# # photo with Caribou\n",
    "# photo_paths=['anwr_37_2019_100RECNX_RCNX9317.jpg']\n",
    "\n",
    "# given image paths finds files, code is at:\n",
    "# notebooks/explore/get_audio4photos.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. pick a sound to use for queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/enis/data/nna/real/anwr/37/2019/S4A10279_20190605_091602_FCmodel\n",
      "/scratch/enis/data/nna/real/anwr/37/2019/S4A10279_20190605_091602_FCmodel/S4A10279_20190605_091602_FCmodel000.npy\n",
      "/scratch/enis/data/nna/real/anwr/37/2019/S4A10279_20190605_091602_vgg\n",
      "/scratch/enis/data/nna/real/anwr/37/2019/S4A10279_20190605_091602_vgg/S4A10279_20190605_091602_rawembeddings000.npy\n",
      "/scratch/enis/data/nna/real/anwr/37/2019/S4A10279_20190605_091602_vgg/S4A10279_20190605_091602_embeddings000.npy\n"
     ]
    }
   ],
   "source": [
    "# sound with Caribou\n",
    "\n",
    "!find /scratch/enis/data/nna/real/ -iname \"S4A10279_20190605_091602*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# aircraft sound\n",
    "\n",
    "!find /scratch/enis/data/nna/real/ -iname \"S4A10255_20190507_073000*\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 find similar embeddings for given embeddings in the same location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sound with Caribou\n",
    "\n",
    "raw_embed_name=\"/scratch/enis/data/nna/real/anwr/37/2019/S4A10279_20190605_091602_vgg/S4A10279_20190605_091602_rawembeddings000.npy\"\n",
    "raw_embed=np.load(raw_embed_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aircraft sound\n",
    "# raw_embed_name=\"/scratch/enis/data/nna/real/prudhoe/26/2019/S4A10255_20190507_073000_vgg/S4A10255_20190507_073000_rawembeddings000.npy\"\n",
    "raw_embed_name=\"/scratch/enis/data/nna/real/prudhoe/26/2019/S4A10255_20190507_073000_vgg/S4A10255_20190507_073000_embeddings000.npy\"\n",
    "\n",
    "raw_embed=np.load(raw_embed_name)\n",
    "raw_embed=raw_embed.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1808"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# S4A10255_20190507_073000-1808second\n",
    "(30*60)+8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Slice embedding for exact time of interest from a big file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aircraft sound\n",
    "start_seconds=(30*60)+8\n",
    "raw_embed_audio=raw_embed[int(start_seconds):int(start_seconds)+60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # sound with Caribou\n",
    "# start_seconds=(start_time-sorted_filtered[\"timestamp\"])[0].total_seconds()\n",
    "# raw_embed_audio=raw_embed[int(start_seconds):int(start_seconds)+60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 128)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_embed_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileIndex(raw_embed_name,metadata):\n",
    "    aircraftIndex=0\n",
    "    for em,length in metadata:\n",
    "        if em==raw_embed_name:\n",
    "            return aircraftIndex\n",
    "        aircraftIndex=aircraftIndex+length\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_properties_df=pd.read_pickle(\"../../data/allFields_dataV2.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/tank/data/nna/real/anwr/31/2019/S4A10297_20190616_124602.flac')"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standardPathStyle(parentPath,row,subDirectoryAddon=None,fileNameAddon=None):\n",
    "    src=Path(parentPath) / row.region /row.locationId/ row.year\n",
    "    if subDirectoryAddon or fileNameAddon:\n",
    "        fileName=Path(row.name)\n",
    "    if subDirectoryAddon:\n",
    "        src = src / (fileName.stem +subDirectoryAddon)\n",
    "    if fileNameAddon:\n",
    "        src= src / (fileName.stem +fileNameAddon)\n",
    "    return src\n",
    "\n",
    "thePath=Path(metadata[445][0])\n",
    "parentDistance=0\n",
    "thePath.parents[parentDistance],thePath\n",
    "outputPath=\"/scratch/enis/data/nna/real/\"\n",
    "inputPath=\"/tank/data/nna/real/\"\n",
    "\n",
    "def npy2originalFile(thePath,inputPath,outputPath,file_properties_df,\n",
    "                     subDirectoryAddon=None,fileNameAddon=None):\n",
    "#     thePath.parents[parentDistance]\n",
    "    relative2Main=thePath.relative_to(parentPath)\n",
    "    fileName=relative2Main.parents[0].stem\n",
    "    \n",
    "    # find possible files in the file properties \n",
    "    region=relative2Main.parts[0]\n",
    "    locationId=relative2Main.parts[1]\n",
    "    year=relative2Main.parts[2]\n",
    "    isRegion=file_properties_df.region==region\n",
    "    islocationID=file_properties_df.locationId==locationId\n",
    "    isYear=file_properties_df.year==year\n",
    "    truthTable=isRegion &  islocationID &  isYear\n",
    "    filteredProperties=file_properties_df[truthTable]\n",
    "    \n",
    "    timestamp=\"_\".join(fileName.split(\"_\")[1:3])\n",
    "    for row in filteredProperties.iterrows():\n",
    "        if timestamp in str(row[0]):\n",
    "            return row[0]\n",
    "    return -1\n",
    "\n",
    "\n",
    "npy2originalFile(thePath,inputPath,outputPath,file_properties_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/scratch/enis/data/nna/real/stinchcomb/01-Itkillik/2016/ITK01_20160602_130218_vgg/ITK01_20160602_130218_embeddings000.npy',\n",
       " 44589)"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[m][0],m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=5\n",
    "i=44589\n",
    "ii=i\n",
    "meta=metadata[i]\n",
    "\n",
    "distance=int(Path(meta[0]).stem[-3:])\n",
    "secondsInOriginalFile=0\n",
    "for m in range(i-1,i-distance-1,-1):\n",
    "    secondsInOriginalFile+=metadata[m][1]\n",
    "secondsInOriginalFile\n",
    "# while True:\n",
    "#     if Path(meta[0]).stem[-3:]==\"000\":\n",
    "#         print(meta[0])\n",
    "#         break\n",
    "#     else:\n",
    "#         ii-=1\n",
    "#         meta=metadata[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getFileIndex(raw_embed_name,metadata,secondsfromBeginningofFile=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/scratch/enis/data/nna/real/stinchcomb/01-Itkillik/2016/ITK01_20160602_130218_vgg/ITK01_20160602_130218_embeddings001.npy', 3600) 44590\n"
     ]
    }
   ],
   "source": [
    "for i,m in enumerate(metadata):\n",
    "    if \"001.npy\" in m[0]:\n",
    "        print(m,i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 load embeddings to search from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386\n",
      "CPU times: user 748 ms, sys: 1.82 s, total: 2.57 s\n",
      "Wall time: 5min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# find all files\n",
    "import glob\n",
    "search_path=\"/scratch/enis/data/nna/real/prudhoe/26/\"\n",
    "metadataCSV=\"/scratch/enis/data/nna/realMerged/\"+\"allEmbeddings_\"+\"prudhoe26_V11\"+\".csv\"\n",
    "\n",
    "filenamePattern=\"*_embeddings*.npy\"\n",
    "\n",
    "# all_embeddings=list_files(\"/scratch/enis/data/nna/real/anwr/37/\",filenamePattern)\n",
    "# aircraft sound\n",
    "all_embeddings=list_files(search_path,filename=filenamePattern)\n",
    "# remove original embedding from the list\n",
    "# del all_embeddings[all_embeddings.index(raw_embed_name)]\n",
    "\n",
    "embedSizes=[]\n",
    "for i,embed_file in enumerate(all_embeddings):\n",
    "    embed=np.load(embed_file)\n",
    "    embedSizes.append(embed.shape[0])\n",
    "\n",
    "metadata=list(zip(all_embeddings,embedSizes))\n",
    "save_to_csv(metadataCSV,metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we are trying to create a matrix, rows are queries and columns are data points in database\n",
    "* values are similarity, \n",
    "* then \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 this is for calculating distances ourself "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 996 ms, sys: 1 s, total: 2 s\n",
      "Wall time: 4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load and merge embedding files\n",
    "#LOAD:\n",
    "embeds=[None]*len(all_embeddings)\n",
    "index=0\n",
    "for i,embed_file in enumerate(all_embeddings):\n",
    "    embed=np.load(embed_file)\n",
    "    index+=embed.shape[0]\n",
    "    embeds[i]=(embed)\n",
    "#MERGE:\n",
    "# Faster then np.concatenate\n",
    "concat_embeds=np.zeros([index,128],dtype=np.float32)\n",
    "index=0\n",
    "for i,embed in enumerate(embeds):\n",
    "    concat_embeds[index:(index+embed.shape[0]),:]=embed[:]\n",
    "    index+=embed.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1736614, 128)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_embeds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 create an ANNOY index for files at all_path on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector size\n",
    "f=128\n",
    "  # Length of item vector that will be indexed\n",
    "distance='euclidean'\n",
    "#prepares annoy to build the index in the specified file instead of RAM \n",
    "#(execute before adding items, no need to save after build)\n",
    "fn=\"/scratch/enis/data/nna/realMerged/prudhoe26_V11.ann\"\n",
    "fn=\"/scratch/enis/data/nna/realMerged/allEmbeddingsV11.ann\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 19.1 µs\n",
      "Compiler : 2.62 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "def buildOnDisk(fn,f,distance='euclidean',seed=42,treeN=16):\n",
    "    t = AnnoyIndex(f, distance)\n",
    "    t.on_disk_build(fn)\n",
    "    index=0\n",
    "    start=time.time()\n",
    "    for i,embed_file in enumerate(all_embeddings):\n",
    "        embed=np.load(embed_file)\n",
    "        for ii in range(embed.shape[0]):\n",
    "            t.add_item(index, embed[ii,:])\n",
    "            index+=1\n",
    "        if i%1000==0:\n",
    "            end=time.time()\n",
    "            print(\"Current index:\",i,\"time for 1000 index\",end-start)\n",
    "            start=end\n",
    "        # build index\n",
    "    t.set_seed(seed)\n",
    "    t.build(treeN)\n",
    "    return t\n",
    "\n",
    "def loadOnDisk(fn,f,distance='euclidean'):\n",
    "    t = AnnoyIndex(f, distance)\n",
    "    t.load(fn)\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "p=Path(fn)\n",
    "if p.exists():\n",
    "    t = loadOnDisk(fn,f,distance=distance)\n",
    "else:\n",
    "    t = buildOnDisk(fn,f,distance=distance,seed=42,treeN=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "def MatrixApproxV2(queries,t,searchDepth=2):\n",
    "    #(SearchDept,QuerySelf,QueryOther)\n",
    "    # first row is for first item in queries, closest point in NNs, others are aligned.\n",
    "    QmatrixDistance=np.zeros((searchDepth,len(queries),len(queries)))\n",
    "    QmatrixIDs=np.zeros((searchDepth,len(queries),len(queries)),dtype=np.int)\n",
    "    sizeOfDataset=t.get_n_items()\n",
    "    for i,q in enumerate(queries):\n",
    "        IDs,Distances=t.get_nns_by_item(q, searchDepth+1,include_distances=True)\n",
    "        IDs,Distances=IDs[1:],Distances[1:]\n",
    "        QmatrixDistance[:,i,i]=Distances[:]\n",
    "        QmatrixIDs[:,i,i]=IDs[:]\n",
    "        for i2,q2 in enumerate(queries):\n",
    "            if i==i2:\n",
    "                continue\n",
    "            for SearchDepthIndex,ID in enumerate(IDs):\n",
    "                alingedID=(ID+(i2-i))\n",
    "                alingedID=0 if (alingedID)<0 else alingedID\n",
    "                alingedID = alingedID if alingedID<sizeOfDataset else sizeOfDataset-1\n",
    "                QmatrixDistance[SearchDepthIndex,i,i2]=t.get_distance(q2,alingedID)\n",
    "                QmatrixIDs[SearchDepthIndex,i,i2]=alingedID\n",
    "\n",
    "    return QmatrixDistance,QmatrixIDs\n",
    "\n",
    "def groupResByDistance(res,theta=5):\n",
    "    # find consequtive points that are close to each other\n",
    "\n",
    "    sortedbyInd=sorted(res,key=lambda x:x[1])\n",
    "    previous=sortedbyInd[0][1]\n",
    "    count=0\n",
    "    series=[]\n",
    "    starts=[]\n",
    "    \n",
    "    #last one is ignored, add a fake one\n",
    "    sortedbyInd.append((sortedbyInd[-1][0],sortedbyInd[-1][1]+theta+1))\n",
    "    \n",
    "    for score,index in sortedbyInd:\n",
    "        if index<=previous+theta:\n",
    "            series.append((score,index))\n",
    "        else:\n",
    "            starts.append(series)\n",
    "            series=[]\n",
    "            series.append((score,index))\n",
    "        previous=index\n",
    "\n",
    "    return starts\n",
    "\n",
    "\n",
    "def embedIndex2fileSecond(index,embeds,all_embeddings,excerptLen=1):\n",
    "    alist=[]\n",
    "    countStart=0\n",
    "    embed_count=index*excerptLen\n",
    "    for i,em in enumerate(embeds):\n",
    "        countEnd=countStart+(em.shape[0])\n",
    "        if countStart<=embed_count and embed_count<=countEnd:\n",
    "            startSecond=embed_count-countStart\n",
    "    #             print(i,countStart,countEnd,\"start second:\",startSecond)\n",
    "            filename=(\"/tank/\"+\"/\".join(all_embeddings[i].split(\"/\")[3:-2])+\"/\"+all_embeddings[i].split(\"/\")[-2][:-4]+\".flac\")\n",
    "#             alist.append((filename,startSecond))\n",
    "            return((filename,startSecond))\n",
    "#             break\n",
    "        countStart=countEnd\n",
    "\n",
    "def embedIndex2fileSecond(index,metadata,excerptLen=1):\n",
    "    alist=[]\n",
    "    countStart=0\n",
    "    embed_count=index*excerptLen\n",
    "    \n",
    "    for i,meta in enumerate(metadata):\n",
    "        countEnd=countStart+(meta[1])\n",
    "        if countStart<=embed_count and embed_count<=countEnd:\n",
    "            startSecond=embed_count-countStart\n",
    "    #             print(i,countStart,countEnd,\"start second:\",startSecond)\n",
    "            filename=(\"/tank/\"+\"/\".join(meta[0].split(\"/\")[3:-2])+\"/\"+meta[0].split(\"/\")[-2][:-4]+\".flac\")\n",
    "            return((filename,startSecond))\n",
    "        countStart=countEnd\n",
    "\n",
    "\n",
    "def loadOnDisk(fn,f,distance='euclidean'):\n",
    "    t = AnnoyIndex(f, distance)\n",
    "    t.load(fn)\n",
    "    return t\n",
    "\n",
    "# vector size\n",
    "f=128\n",
    "  # Length of item vector that will be indexed\n",
    "distance='euclidean'\n",
    "#prepares annoy to build the index in the specified file instead of RAM \n",
    "#(execute before adding items, no need to save after build)\n",
    "fn=\"/scratch/enis/data/nna/realMerged/allEmbeddingsV11.ann\"\n",
    "metadatCsv=\"/scratch/enis/data/nna/realMerged/allEmbeddingsV11.csv\"\n",
    "t = loadOnDisk(fn,f,distance=distance)\n",
    "\n",
    "metadata=[]\n",
    "with open(metadatCsv) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        metadata.append((row[0],int(row[1])))\n",
    "\n",
    "\n",
    "aircraftFileIndex=getFileIndex(raw_embed_name,metadata)\n",
    "startIndex=aircraftFileIndex+1808\n",
    "\n",
    "queries=[i for i in range(startIndex,startIndex+10,1)]\n",
    "searchDepth=2\n",
    "\n",
    "QmatrixDistance,QmatrixIDs=MatrixApproxV2(queries,t,searchDepth=2)\n",
    "averageDistance_approx=np.average(QmatrixDistance,axis=1)\n",
    "\n",
    "similarities,IDs=dist2sim(averageDistance_approx).flatten(),QmatrixIDs[:,:,0].flatten()\n",
    "res=list(zip(similarities,IDs))\n",
    "\n",
    "ResGrouped=groupResByDistance(res,theta=5)\n",
    "split_folder=\"/home/enis/projects/nna/data/nearestNeighbours/prudhoe26_ApproxV2/\"\n",
    "\n",
    "exp_name=\"\"\n",
    "for indexes in (ResGrouped):\n",
    "    score,index=(indexes[0])\n",
    "    groupLength=indexes[-1][1]-indexes[0][1]+10\n",
    "#     print(groupLength)\n",
    "#     print(score,index)\n",
    "\n",
    "    clipAddBip([index],exp_name,split_folder,metadata,excerptLen=groupLength,reductionLen=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort results by similarity \n",
    "scores=[max([i[0] for i in x]) for x in ResGrouped]\n",
    "ResGroupedwScores=list(zip(scores,ResGrouped))\n",
    "ResGroupedwScores.sort(key=lambda x: x[0],reverse=True)\n",
    "ResGrouped=[i[1] for i in ResGroupedwScores]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Use Annoy NNs to approximate matrix, (find highest per second, then calculate others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities,IDs=dist2sim(averageDistance_approx).flatten(),QmatrixIDs[:,:,0].flatten()\n",
    "res=list(zip(similarities,IDs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highest scores might be consequtive, merging these as one result helps decrease amount of files to listen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total groups 19\n",
      "short distances\n",
      "1329648 1329953\n"
     ]
    }
   ],
   "source": [
    "def groupResByDistance(res,theta=5):\n",
    "    # find consequtive points that are close to each other\n",
    "\n",
    "    sortedbyInd=sorted(res,key=lambda x:x[1])\n",
    "    previous=sortedbyInd[0][1]\n",
    "    count=0\n",
    "    series=[]\n",
    "    starts=[]\n",
    "    \n",
    "    #last one is ignored, add a fake one\n",
    "    sortedbyInd.append((sortedbyInd[-1][0],sortedbyInd[-1][1]+theta+1))\n",
    "    \n",
    "    for score,index in sortedbyInd:\n",
    "        if index<=previous+theta:\n",
    "            series.append((score,index))\n",
    "        else:\n",
    "            starts.append(series)\n",
    "            series=[]\n",
    "            series.append((score,index))\n",
    "        previous=index\n",
    "\n",
    "    return starts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResGrouped=groupResByDistance(res,theta=5)\n",
    "# print(\"total groups\",len(ResGrouped))\n",
    "# previous=0\n",
    "# print(\"short distances\")\n",
    "# for score_indexes in ResGrouped:\n",
    "#     if (score_indexes[-1][1]-score_indexes[0][1])>30:\n",
    "#         print(score_indexes[0][1],score_indexes[-1][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0.3420873627434949, 199662)],\n",
       " [(0.23513666278291756, 199763),\n",
       "  (0.24773782430353594, 199765),\n",
       "  (0.25793467015829874, 199765)],\n",
       " [(0.22867374500591423, 199775)],\n",
       " [(0.3133193261908106, 199898), (0.26999331052534553, 199899)],\n",
       " [(0.3049009514846011, 208611)],\n",
       " [(0.21640606362211398, 274935),\n",
       "  (0.24928697352579735, 274935),\n",
       "  (0.22077357382274507, 274936)],\n",
       " [(0.3502257485041737, 398432)],\n",
       " [(0.2747582949889767, 403581)],\n",
       " [(0.2555197891287858, 828917)],\n",
       " [(0.3149978497165593, 879141)],\n",
       " [(0.1842298181046157, 1051635), (0.24000938942737535, 1051636)],\n",
       " [(0.2830081520104452, 1674383)],\n",
       " [(0.22750286629790317, 1686194)],\n",
       " [(0.36534653708099707, 1686206)]]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResGrouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0.3420873627434949 199662\n",
      "/tank/data/nna/real/prudhoe/26/2019/S4A10255_20190507_073000.flac 1706\n",
      "12\n",
      "0.23513666278291756 199763\n",
      "/tank/data/nna/real/prudhoe/26/2019/S4A10255_20190507_073000.flac 1807\n",
      "10\n",
      "0.22867374500591423 199775\n",
      "/tank/data/nna/real/prudhoe/26/2019/S4A10255_20190507_073000.flac 1819\n",
      "11\n",
      "0.3133193261908106 199898\n",
      "/tank/data/nna/real/prudhoe/26/2019/S4A10255_20190507_073000.flac 1942\n",
      "10\n",
      "0.3049009514846011 208611\n",
      "/tank/data/nna/real/prudhoe/26/2019/S4A10255_20190507_120000.flac 1657\n",
      "11\n",
      "0.21640606362211398 274935\n",
      "/tank/data/nna/real/prudhoe/26/2019/S4A10255_20190508_221602.flac 435\n",
      "10\n",
      "0.3502257485041737 398432\n",
      "/tank/data/nna/real/prudhoe/26/2019/S4A10255_20190511_150000.flac 2520\n",
      "10\n",
      "0.2747582949889767 403581\n",
      "/tank/data/nna/real/prudhoe/26/2019/S4A10255_20190511_161602.flac 3109\n",
      "10\n",
      "0.2555197891287858 828917\n",
      "/tank/data/nna/real/prudhoe/26/2019/S4A10255_20190521_003000.flac 1101\n",
      "10\n",
      "0.3149978497165593 879141\n",
      "/tank/data/nna/real/prudhoe/26/2019/S4A10255_20190522_011602.flac 1775\n",
      "11\n",
      "0.1842298181046157 1051635\n",
      "/tank/data/nna/real/prudhoe/26/2019/S4A10255_20190525_181602.flac 3307\n",
      "10\n",
      "0.2830081520104452 1674383\n",
      "/tank/data/nna/real/prudhoe/26/2019/S4A10255_20190608_100000.flac 755\n",
      "10\n",
      "0.22750286629790317 1686194\n",
      "/tank/data/nna/real/prudhoe/26/2019/S4A10255_20190608_150000.flac 3568\n",
      "10\n",
      "0.36534653708099707 1686206\n",
      "/tank/data/nna/real/prudhoe/26/2019/S4A10255_20190608_150000.flac 3580\n"
     ]
    }
   ],
   "source": [
    "ResGrouped=groupResByDistance(res,theta=5)\n",
    "split_folder=\"/home/enis/projects/nna/data/nearestNeighbours/prudhoe26_ApproxV2/\"\n",
    "\n",
    "exp_name=\"\"\n",
    "for indexes in (ResGrouped):\n",
    "    score,index=(indexes[0])\n",
    "    groupLength=indexes[-1][1]-indexes[0][1]+10\n",
    "    print(groupLength)\n",
    "    print(score,index)\n",
    "\n",
    "    clipAddBip([index],exp_name,split_folder,metadata,excerptLen=groupLength,reductionLen=1)\n",
    "\n",
    "# indexes=[indexes[len(indexes)//2] for indexes,count in (starts)]\n",
    "# # indexes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4562"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 lets calculate exact values with ANNOY to see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "matrixList=[]\n",
    "queries=[i for i in range(100,110,1)]\n",
    "for i,q in enumerate(queries):\n",
    "    IDs,Distances=t.get_nns_by_item(q, sizeOfDataset,include_distances=True)\n",
    "    a=list(zip(IDs,Distances))\n",
    "    a.sort()\n",
    "    print(i)\n",
    "    matrixList.append(a[:])\n",
    "\n",
    "for a in matrixList:\n",
    "    print(len(a))\n",
    "\n",
    "matrixList2=[]\n",
    "for a in matrixList:\n",
    "    b=[i[1] for i in a]\n",
    "    matrixList2.append(b)\n",
    "bb=np.array(matrixList2)\n",
    "\n",
    "gamma=1/450\n",
    "results=np.exp(-bb*gamma)\n",
    "\n",
    "%%time\n",
    "windowSize=10\n",
    "# here I used average, normally we were using np.max\n",
    "windowMax=np.average(results,axis=0)\n",
    "windowMean=pd.Series(windowMax).rolling(window=windowSize).mean().iloc[windowSize-1:].values\n",
    "\n",
    "# arr = np.array([1, 3, 2, 4, 5,6,7,8,8,1,1,9])\n",
    "kth=40\n",
    "ind = np.argpartition(windowMean, -kth)[-kth:]\n",
    "sortedbyScore=sorted(list(zip(windowMean[ind],ind)),reverse=True)\n",
    "\n",
    "for _,index in sortedbyScore[10:]:\n",
    "    \n",
    "    print(np.argmax(bb[:,index:index+10],axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.0 there are three methods for creating vectors (I was experimenting merging vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Method 1   1 second \n",
    "excerptLen=1\n",
    "exp_name=\"1second\"\n",
    "concat_embeds2=concat_embeds[:]\n",
    "raw_embed_audio2=raw_embed_audio[:]\n",
    "raw_embed_audio2=raw_embed_audio2[20:21,:]\n",
    "rowN=100000\n",
    "\n",
    "#Method 2    mean 10 second\n",
    "# excerptLen=10\n",
    "# exp_name=\"Mean10Second\"\n",
    "# concat_embeds2=concat_embeds.reshape(-1,10,128).mean(axis=1)\n",
    "# raw_embed_audio2=raw_embed_audio.reshape(-1,10,128).mean(axis=1)\n",
    "# raw_embed_audio2=raw_embed_audio2[2:3,:]\n",
    "# rowN=10000\n",
    "\n",
    "# #Method 3    concat 10 second\n",
    "# excerptLen=10\n",
    "# exp_name=\"Concat10Second\"\n",
    "# concat_embeds2=concat_embeds.reshape(-1,1280)\n",
    "# raw_embed_audio2=raw_embed_audio.reshape(-1,1280)\n",
    "# raw_embed_audio2=raw_embed_audio2[2:3,:]\n",
    "# rowN=10000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Exp: Fastest Way to calculate exact matrix, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52 ms, sys: 788 ms, total: 840 ms\n",
      "Wall time: 2.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import multiprocessing\n",
    "\n",
    "def worker(index,numberItems):\n",
    "    allA=[None]*numberItems\n",
    "\n",
    "    for i in range(numberItems):\n",
    "        a=u.get_distance(i, index)\n",
    "    return None\n",
    "\n",
    "jobs = []\n",
    "for index in range(10):\n",
    "    numberItems=u.get_n_items()\n",
    "    p = multiprocessing.Process(target=worker,args=(index,numberItems))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "\n",
    "for p in jobs:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 55s, sys: 17.2 s, total: 3min 12s\n",
      "Wall time: 5.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# one sample/query\n",
    "# res=paired_distances_broadcast(raw_embed_audio2,concat_embeds2)\n",
    "# res.shape\n",
    "\n",
    "#\n",
    "# 10 queries\n",
    "queryCount=10\n",
    "startSecond=0\n",
    "excerptLen=1\n",
    "\n",
    "gamma=1/512\n",
    "startIndex=int(startSecond/excerptLen)\n",
    "endIndex=startIndex+queryCount\n",
    "\n",
    "\n",
    "results = pairwise_distances(raw_embed_audio[startIndex:10,:], concat_embeds)\n",
    "\n",
    "# results=np.exp(-results*gamma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 472 ms, sys: 2.57 s, total: 3.04 s\n",
      "Wall time: 3.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = dist2sim(results,gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.9 s, sys: 960 ms, total: 30.8 s\n",
      "Wall time: 29.8 s\n"
     ]
    }
   ],
   "source": [
    "# I might have to use this method, if I want to get maximum without replacement\n",
    "\n",
    "# %%time\n",
    "# stepSize=1\n",
    "# windowSize=10\n",
    "# resultsMax=[]\n",
    "# resultsAvg=[]\n",
    "\n",
    "# windowMax=np.max(results2,axis=0)\n",
    "\n",
    "# for i in range(0,results2.shape[1],stepSize):\n",
    "# #     windowElements=(results2[:,i:(i+windowSize+1)])\n",
    "# #     colMax=np.max(windowElements,axis=0)\n",
    "\n",
    "#     resultAvg=np.average(colMax)\n",
    "#     resultsAvg.append(resultAvg)\n",
    "# #     resultsMax.append(windowMax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Run sliding window over the exact Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.31 s, sys: 1min 3s, total: 1min 5s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "windowSize=10\n",
    "windowMax=np.max(results,axis=0)\n",
    "windowMean=pd.Series(windowMax).rolling(window=windowSize).mean().iloc[windowSize-1:].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "windowSize=10\n",
    "windowMax=np.max(resultMatrix,axis=0)\n",
    "windowMean=pd.Series(windowMax).rolling(window=windowSize).mean().iloc[windowSize-1:].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look into stats of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=1732041, minmax=(0.05875636413693428, 0.3321208477020264), mean=0.12500929506519953, variance=0.00040337682893698085, skewness=1.7658461475250447, kurtosis=8.105885715994328)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stats.describe(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=windowMean[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find kth highest scores (similarity of queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr = np.array([1, 3, 2, 4, 5,6,7,8,8,1,1,9])\n",
    "kth=250\n",
    "ind = np.argpartition(res, -kth)[-kth:]\n",
    "sortedbyScore=sorted(list(zip(res[ind],ind)),reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generating figures for similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1732041,), 100000, 17.32041)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape,rowN,res.shape[0]/rowN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "\n",
    "minY,maxY=min(res),max(res)\n",
    "exp_name=\"slidingWindow_AverageOfMax_short20k\"\n",
    "name=f\"Euclidian Similarity {exp_name}\"\n",
    "nrows=res.shape[0]//rowN\n",
    "print(nrows)\n",
    "fig, ax = plt.subplots(nrows=nrows,figsize=(200, 20*nrows))\n",
    "for i,axes in enumerate(ax):\n",
    "    axes.plot(res[i*(rowN):(i+1)*(rowN)])\n",
    "    axes.set_ylim(minY,maxY)\n",
    "    axes.grid(True)\n",
    "\n",
    "ax[0].set_ylabel(f\"{name}\",fontsize=32)\n",
    "\n",
    "# plt.grid(True)\n",
    "\n",
    "# loc = plticker.MultipleLocator(base=5000) # this locator puts ticks at regular intervals\n",
    "# ax.xaxis.set_major_locator(loc)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.show()\n",
    "filename=name.replace(\" \",\"_\")\n",
    "fig.savefig(f\"/home/enis/projects/nna/results/vis/nearestNeighbour/{filename}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "excerptLen=10\n",
    "exp_name=\"Concat10Second\"\n",
    "concat_embeds2=concat_embeds.reshape(-1,1280)\n",
    "raw_embed_audio2=raw_embed_audio.reshape(-1,1280)\n",
    "raw_embed_audio2=raw_embed_audio2[2:3,:]\n",
    "rowN=10000\n",
    "\n",
    "res=paired_distances_broadcast(raw_embed_audio2,concat_embeds2)\n",
    "res.shape\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "\n",
    "name=f\"Euclidian Distance {exp_name}\"\n",
    "nrows=res.shape[0]//rowN\n",
    "\n",
    "fig, ax = plt.subplots(nrows=nrows,figsize=(200, 20*nrows))\n",
    "for i,axes in enumerate(ax):\n",
    "    axes.plot(res[i*(rowN):(i+1)*(rowN)])\n",
    "\n",
    "ax[0].set_ylabel(f\"{name}\",fontsize=32)\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "# loc = plticker.MultipleLocator(base=5000) # this locator puts ticks at regular intervals\n",
    "# ax.xaxis.set_major_locator(loc)\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.show()\n",
    "filename=name.replace(\" \",\"_\")\n",
    "fig.savefig(f\"/home/enis/projects/nna/results/vis/nearestNeighbour/{filename}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(385, 10)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_embeddings),excerptLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted([sorted(start) for start in starts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create corresponding clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_folder=\"/home/enis/projects/nna/data/nearestNeighbours/S4A10255_20190507_073000-1808seconds/slidingWindow_AverageOfMax/\"\n",
    "excerptLen=1\n",
    "# for indexes in (starts):\n",
    "#     score,index=(indexes[len(indexes)//2])\n",
    "#     print(score)\n",
    "#     print(embedIndex2fileSecond(index,embeds,all_embeddings,excerptLen=1))\n",
    "    \n",
    "for score,index in (sortedbyScore):\n",
    "#     score,index=(indexes[len(indexes)//2])\n",
    "    print(score)\n",
    "    print(embedIndex2fileSecond(index,embeds,all_embeddings,excerptLen=1))\n",
    "\n",
    "# indexes=[indexes[len(indexes)//2] for indexes,count in (starts)]\n",
    "# # # indexes\n",
    "# clipAddBip(indexes,exp_name,split_folder,embeds,all_embeddings,excerptLen=10,reductionLen=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdt = KDTree(concat_embeds2, leaf_size=30, metric='euclidean')\n",
    "distances,indexes=kdt.query(raw_embed_audio2, k=10, return_distance=True)\n",
    "allResults=[ (distance,index) for index,distance in (zip(indexes.flatten(),distances.flatten()))]\n",
    "allResults.sort()\n",
    "# distances,indexes=allResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedIndex2fileSecond(index,embeds,all_embeddings,excerptLen=1):\n",
    "    alist=[]\n",
    "    countStart=0\n",
    "    embed_count=index*excerptLen\n",
    "    for i,em in enumerate(embeds):\n",
    "        countEnd=countStart+(em.shape[0])\n",
    "        if countStart<=embed_count and embed_count<=countEnd:\n",
    "            startSecond=embed_count-countStart\n",
    "    #             print(i,countStart,countEnd,\"start second:\",startSecond)\n",
    "            filename=(\"/tank/\"+\"/\".join(all_embeddings[i].split(\"/\")[3:-2])+\"/\"+all_embeddings[i].split(\"/\")[-2][:-4]+\".flac\")\n",
    "#             alist.append((filename,startSecond))\n",
    "            return((filename,startSecond))\n",
    "#             break\n",
    "        countStart=countEnd\n",
    "\n",
    "def embedIndex2fileSecond(index,metadata,excerptLen=1):\n",
    "    alist=[]\n",
    "    countStart=0\n",
    "    embed_count=index*excerptLen\n",
    "    \n",
    "    for i,meta in enumerate(metadata):\n",
    "        countEnd=countStart+(meta[1])\n",
    "        if countStart<=embed_count and embed_count<=countEnd:\n",
    "            startSecond=embed_count-countStart\n",
    "    #             print(i,countStart,countEnd,\"start second:\",startSecond)\n",
    "            filename=(\"/tank/\"+\"/\".join(meta[0].split(\"/\")[3:-2])+\"/\"+meta[0].split(\"/\")[-2][:-4]+\".flac\")\n",
    "            return((filename,startSecond))\n",
    "        countStart=countEnd\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_folder=\"/home/enis/projects/nna/data/nearestNeighbours/\"\n",
    "def clipAddBip(allIndexes,exp_name,split_folder,metadata,excerptLen,reductionLen):\n",
    "    # embed_count=823804\n",
    "    beep_wav=\"/home/enis/projects/nna/data/beep.wav\"\n",
    "    beep_wav = AudioSegment.from_file(beep_wav)\n",
    "    beep_wav=beep_wav-30\n",
    "    \n",
    "    \n",
    "    split_folder=(split_folder+exp_name)\n",
    "    Path(split_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for index in allIndexes[:]:\n",
    "        (filename,startSecond)=embedIndex2fileSecond(index,metadata,excerptLen=reductionLen)\n",
    "        endSecond=startSecond+excerptLen\n",
    "        print(filename,startSecond)\n",
    "        input_file=filename\n",
    "        buffer=10\n",
    "        start_time=\"{}.{}\".format((startSecond-buffer)//60,(startSecond-buffer)%60)\n",
    "        end_time=\"{}.{}\".format((endSecond+buffer)//60,(endSecond+buffer)%60)\n",
    "        outputSuffix=\".wav\"\n",
    "        output_file = splitmp3(input_file,split_folder,start_time,end_time,depth=1,backend=\"ffmpeg\",outputSuffix=outputSuffix)\n",
    "\n",
    "        other_wav=AudioSegment.from_file(output_file)\n",
    "        start,end=(buffer*1000),((buffer+excerptLen)*1000)\n",
    "        result_wav=other_wav[:start]+(beep_wav)+other_wav[start:end]+beep_wav+other_wav[end:]\n",
    "        o_file=result_wav.export(output_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notes\n",
    "!ls -alh /scratch/enis/data/nna/realMerged/allEmbeddings.ann"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechEnv",
   "language": "python",
   "name": "speechenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
