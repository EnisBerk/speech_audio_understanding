{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding following folder to path:  /home/enis/projects/nna/src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../src'))\n",
    "print(\"adding following folder to path: \",module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from numpy import linspace\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import datetime\n",
    "from scipy import stats\n",
    "import time\n",
    "import copy\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "import csv \n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "import pickle\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.dates as dates\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import cm\n",
    "\n",
    "from pytz import timezone\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_process_func import read_queue\n",
    "from fileUtils import read_file_properties\n",
    "from labeling_utils import load_labels\n",
    "from visUtils import get_cycle,createTimeIndex,file2TableDict,reverseTableDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_DIR_PARENT = \"/home/data/nna/stinchcomb/NUI_DATA/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def createFigure(months,monthsTime):\n",
    "    plt.rcParams[\"axes.prop_cycle\"] = get_cycle(\"tab10\",N=8)\n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(80,len(months)*9),nrows=len(months),sharex=True, sharey=True,gridspec_kw={'hspace': 0})\n",
    "    ax = np.array(ax).reshape(-1) # subplot returns single element for single row\n",
    "\n",
    "    markers = itertools.cycle((',', '+', '.', 'o', '*')) \n",
    "\n",
    "    weather_colors=[\"firebrick\",\"darkorange\",\"green\",\"seagreen\",\"lightpink\"]\n",
    "\n",
    "    for monthi,month in enumerate(months):\n",
    "        # for col in df_freq.columns:\n",
    "        for i,(col,(lat,long)) in enumerate(cord_list):\n",
    "#             if col in weather_cols:\n",
    "#                 index=weather_cols.index(col)\n",
    "#                 ax[monthi].plot_date(month.index.to_pydatetime(), month[col],linestyle=\"-\",marker=\" \",color=weather_colors[index])\n",
    "#             else:\n",
    "            ax[monthi].plot_date(month.index.to_pydatetime(), month[col],linestyle=\"-\",marker=\" \")\n",
    "\n",
    "\n",
    "    ax[0].legend( labels=[id2name.get(x[0],x[0][1:]) for x in cord_list],loc='upper left', \n",
    "                borderpad=0.2, labelspacing=0.2, fontsize=28, \n",
    "                frameon=True) # frameon=False to remove frame.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ax[-1].set_xlabel('Day Number', fontsize=32)\n",
    "\n",
    "#     uniqueYears=pd.unique([month.year for month in monthsTime])\n",
    "#     uniqueYears.size\n",
    "    for i,an_ax in enumerate(ax):\n",
    "        \n",
    "        an_ax.set_ylabel('{}'.format(monthsTime[i].strftime(\"%Y-%B\")),fontsize=48) #, fontweight='black')\n",
    "\n",
    "        locator=dates.DayLocator()\n",
    "        an_ax.xaxis.set_minor_locator(locator)\n",
    "\n",
    "        an_ax.xaxis.set_minor_formatter(dates.DateFormatter('%d\\n'))\n",
    "\n",
    "        an_ax.xaxis.grid(True, which=\"minor\")\n",
    "        an_ax.xaxis.grid(True, which=\"major\")\n",
    "\n",
    "\n",
    "        an_ax.xaxis.set_major_locator(dates.AutoDateLocator())\n",
    "        an_ax.xaxis.set_major_formatter(dates.DateFormatter('%d\\n'))\n",
    "        \n",
    "\n",
    "        an_ax.yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:.0f}'))\n",
    "        an_ax.yaxis.grid()\n",
    "        an_ax.tick_params(labelsize=22,which=\"minor\")\n",
    "        an_ax.tick_params(labelsize=25,which=\"major\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.margins(x=0)\n",
    "    plt.subplots_adjust(top=0.90)\n",
    "\n",
    "\n",
    "    fig.suptitle('Site {}, Normalized Bi-hourly Frequency [%]'.format(selected_area),fontsize=48)\n",
    "#     plt.show()\n",
    "\n",
    "    figDir= Path(visFilePath) / (\"Freq-\"+freq) / regionName \n",
    "    figDir.mkdir(parents=True,exist_ok=True)\n",
    "    figPath= figDir / (\"_\".join([selected_area,str(year)]) +'.'+\"png\")\n",
    "    \n",
    "    fig.savefig(figPath)\n",
    "#     fig.savefig(\"test\" +'.png')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileUtils import standardPathStyle,list_files\n",
    "from visUtils import loadResults\n",
    "\n",
    "def file2TableDict(selected_areas,model_tag_names,globalindex,globalcolumns,\n",
    "                    file_properties_df,freq,dataFreq=\"10S\",dataThreshold=0.5,\n",
    "                    channel=1,gathered_results_perTag=None,\n",
    "                    result_path=None,fileNameAddon=\"\",prob2binaryFlag=True):\n",
    "    # using gathered_results_perTag dictionary or  result_path to create\n",
    "    # a pandas dataframe for visualizations\n",
    "\n",
    "    # dataFreq is sampling frequency of the data,\n",
    "    #most of the time we have predictions for each 10 second\n",
    "\n",
    "    df_dict={key: None for (key) in selected_areas}\n",
    "    no_result_paths=[]\n",
    "\n",
    "    #we need to load it from files\n",
    "    if gathered_results_perTag==None and (result_path==None):\n",
    "        print(\"ERROR: gathered_results_perTag or (result_path and subDirectoryAddon )should be defined\")\n",
    "        return (None,None)\n",
    "\n",
    "\n",
    "    for i,area in enumerate(selected_areas):\n",
    "        df_sums = pd.DataFrame(index=globalindex, columns=globalcolumns).fillna(0)\n",
    "        df_count = pd.DataFrame(index=globalindex, columns=globalcolumns).fillna(0)\n",
    "\n",
    "        for modelTagName in model_tag_names:\n",
    "            dfRawList=[]\n",
    "    #         for afile in selected_areas_dict[area]:\n",
    "            area_filtered=file_properties_df[file_properties_df.site_id==area]\n",
    "            for afile,row in area_filtered.iterrows():\n",
    "        #         data=gathered_results[afile][0]\n",
    "                afile=Path(afile)\n",
    "                # we either load data from multiple files or from single one\n",
    "                if gathered_results_perTag==None:\n",
    "                    # TODO, make _FCmodel variable\n",
    "                    checkFolder=standardPathStyle(result_path,row,subDirectoryAddon=modelTagName\n",
    "                                        ,fileNameAddon=fileNameAddon)\n",
    "                    allSegments = list_files(str(checkFolder)+\"/\")\n",
    "                    if not allSegments:\n",
    "                        data=np.empty(0)\n",
    "                    else:\n",
    "                        data=loadResults(allSegments,prob2binaryFlag=prob2binaryFlag,\n",
    "                                        threshold=dataThreshold,channel=channel)\n",
    "                        # gathered_results[file]=result[:]\n",
    "                else:\n",
    "                    data=gathered_results_perTag[modelTagName].get(afile,np.empty(0))[:]\n",
    "                    if data.size!=0 and prob2binaryFlag==True:\n",
    "                        data=prob2binary(data,threshold=0.5,channel=channel)\n",
    "\n",
    "                if data.size==0:\n",
    "                    no_result_paths.append(afile)\n",
    "                    continue\n",
    "\n",
    "                start=file_properties_df.loc[afile][\"timestamp\"]\n",
    "                end =start+timedelta(seconds=(10*(len(data)-1)))\n",
    "                index = pd.date_range(start,end, freq=dataFreq)\n",
    "                df_afile=pd.DataFrame(data,index=index,columns=[modelTagName])\n",
    "\n",
    "\n",
    "                dfRawList.append(df_afile)\n",
    "            if dfRawList:\n",
    "                dfRaw=pd.concat(dfRawList)\n",
    "                dfRaw=dfRaw.sort_index()\n",
    "                \n",
    "                df_afile_grouped = dfRaw.groupby([pd.Grouper(freq=freq)])\n",
    "                counts=df_afile_grouped.count()\n",
    "                sums=df_afile_grouped.sum()\n",
    "\n",
    "                df_count=df_count.add(counts, fill_value=0) #df_count.update(counts)\n",
    "                df_sums=df_sums.add(sums, fill_value=0) #df_sums.update(sums)\n",
    "\n",
    "            \n",
    "        df_dict[area]=(df_count.copy(),df_sums.copy())\n",
    "\n",
    "    return df_dict,no_result_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyle_str = [\n",
    "     ('solid', 'solid'),      # Same as (0, ()) or '-'\n",
    "     ('dotted', 'dotted'),    # Same as (0, (1, 1)) or '.'\n",
    "     ('dashed', 'dashed'),    # Same as '--'\n",
    "     ('dashdot', 'dashdot'),  # Same as '-.\n",
    "     ('densely dotted',        (0, (1, 1))),\n",
    "     ('densely dashed',        (0, (5, 1))),\n",
    "    ('densely dashdotted',    (0, (3, 1, 1, 1))),\n",
    "     ('densely dashdotdotted', (0, (3, 1, 1, 1, 1, 1)))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFlder=\"/home/enis/projects/nna/data/\"\n",
    "resultsFlder=\"/home/enis/projects/nna/results/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2name={}\n",
    "id2name[\"_CABLE\"]=\"Cable\"\n",
    "id2name[\"_RUNNINGWATER\"]=\"Running Water\"\n",
    "id2name[\"_INSECT\"]=\"Insect\"\n",
    "id2name[\"_RAIN\"]=\"Rain\"\n",
    "id2name[\"_WATERBIRD\"]=\"Water Bird\"\n",
    "id2name[\"_WIND\"]=\"Wind\"\n",
    "id2name[\"_SONGBIRD\"]=\"Songbird\"\n",
    "id2name[\"_AIRCRAFT\"]=\"Aircraft\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_properties_df=pd.read_pickle(\"../../data/stinchcomb_dataV1.pkl\")\n",
    "# file_properties_df=pd.read_pickle(\"../../data/realdata_v2No_stinchcomb.pkl\")\n",
    "\n",
    "#important to keep them in order\n",
    "file_properties_df.sort_values(by=['timestamp'],inplace=True)\n",
    "\n",
    "# delete older than 2016\n",
    "fromtime=datetime(2016, 1, 1, 0)\n",
    "file_properties_df=file_properties_df[file_properties_df.timestamp>=fromtime]\n",
    "all_areas=sorted(pd.unique(file_properties_df.site_id.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_properties_df[file_properties_df.site_id==\"15-FishCreek1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "# FREQS to reduce results \n",
    "freq=\"2H\"\n",
    "\n",
    "\n",
    "# possible places to pick\n",
    "# sorted(pd.unique(file_properties_df.site_id.values))\n",
    "# areas to be visualized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# globalindex,all_start,all_end=createTimeIndex(selected_areas,file_properties_df,freq)\n",
    "\n",
    "# selected_tag_name=\"_SONGBIRD\"\n",
    "model_tag_names=[\"CABLE\",\"RUNNINGWATER\",\"INSECT\", \"RAIN\", \"WATERBIRD\", \"WIND\", \"SONGBIRD\", \"AIRCRAFT\"]\n",
    "\n",
    "model_tag_names=[\"_\"+i for i in model_tag_names]\n",
    "selected_tag_name=model_tag_names[:]\n",
    "\n",
    "weather_cols=[]\n",
    "globalcolumns=model_tag_names#selected_areas+weather_cols\n",
    "\n",
    "visFilePath=\"/home/enis/projects/nna/results/vis/AreaBased/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\" Duration of selected data period:\",(all_end-all_start).days,\"days\")\n",
    "# print(\" Starts: {} \\n Ends:   {}\".format(all_start,all_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-Itkillik 0\n",
      "8 number of files do not have results\n",
      "02-Colville2 1\n",
      "8 number of files do not have results\n",
      "03-OceanPt 2\n",
      "4 number of files do not have results\n",
      "04-Colville4 3\n",
      "0 number of files do not have results\n",
      "05-Colville5 4\n",
      "0 number of files do not have results\n",
      "06-Umiruk 5\n",
      "0 number of files do not have results\n",
      "07-IceRd 6\n",
      "4 number of files do not have results\n",
      "08-CD3 7\n",
      "0 number of files do not have results\n",
      "09-USGS 8\n",
      "16 number of files do not have results\n",
      "10-Nigliq1 9\n",
      "0 number of files do not have results\n",
      "11-Nigliq2 10\n",
      "0 number of files do not have results\n",
      "12-Anaktuvuk 11\n",
      "0 number of files do not have results\n",
      "13-Shorty 12\n",
      "0 number of files do not have results\n",
      "14-Rocky 13\n",
      "0 number of files do not have results\n",
      "15-FishCreek1 14\n",
      "0 number of files do not have results\n",
      "17-FishCreek3 15\n",
      "0 number of files do not have results\n",
      "18-FishCreek4 16\n",
      "0 number of files do not have results\n",
      "19-Itkillik2 17\n",
      "0 number of files do not have results\n",
      "CPU times: user 1min 41s, sys: 19.7 s, total: 2min 1s\n",
      "Wall time: 3min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_path=\"/scratch/enis/data/nna/real/\"\n",
    "\n",
    "for selected_area in all_areas[:]:\n",
    "    print(selected_area,all_areas.index(selected_area))\n",
    "    selected_areas=[selected_area,]\n",
    "    \n",
    "    regionName=file_properties_df[file_properties_df.site_id==selected_area][:1].region[0]\n",
    "\n",
    "    globalindex,all_start,all_end=createTimeIndex(selected_areas,file_properties_df,freq)\n",
    "\n",
    "    df_dict,no_result_paths = file2TableDict(selected_areas,model_tag_names,globalindex,\n",
    "                                             globalcolumns,file_properties_df,freq,dataFreq=\"10S\",\n",
    "                                             result_path=result_path,prob2binaryFlag=False)\n",
    "\n",
    "    print(\"{} number of files do not have results\".format(len(no_result_paths)))\n",
    "\n",
    "    # df_dict_reverse=reverseTableDict(selected_areas,df_dict,model_tag_names)\n",
    "    df_count,df_sums=df_dict[selected_area]\n",
    "\n",
    "    df_freq=df_sums/df_count\n",
    "    # del df_freq['UMIAT']\n",
    "\n",
    "    df_freq=df_freq*100\n",
    "    df_freq=df_freq.dropna(how='all')\n",
    "    # df_freq=pd.concat([df_freq, normal_weather], axis=1, join='inner')\n",
    "\n",
    "\n",
    "    # cord_list=sorted(list(cord.items()),key=lambda x: x[1][0],reverse=True)\n",
    "\n",
    "    # cord_list=list(filter(lambda x: x[0] in df_freq.columns ,cord_list))\n",
    "\n",
    "    cord_list=[(i,(0,0)) for i in df_freq.columns]\n",
    "    \n",
    "    monthsTime=pd.unique(df_freq.index.strftime(\"%Y-%m-01\"))\n",
    "    monthsTime=[pd.Timestamp(i) for i in monthsTime]\n",
    "    \n",
    "#     monthsTime=pd.date_range(\"{}-{}\".format(all_start.year,all_start.month),\"{}-{}\".format(all_end.year,all_end.month), freq='MS',)\n",
    "    monthsTimeStr=[\"{}-{}\".format(month.year,month.month) for month in monthsTime]\n",
    "    # months=[df_freq.loc['2019-05':'2019-05'],df_freq.loc['2019-06':'2019-06']]\n",
    "    months=[df_freq.loc[month:month] for month in monthsTimeStr]\n",
    "#     months=[month for month in months if month.size>0]\n",
    "    # months2=[df_freq.loc['2016-06-01':'2016-06-30'],df_freq.loc['2016-07-01':'2016-07-31'],df_freq.loc['2016-08-01':'2016-08-31']]\n",
    "#     break\n",
    "    # make them all same month for aligning \n",
    "    for i,month in enumerate(months):\n",
    "        months[i]=month.rename(index=lambda x: x.replace(month=7,year=2019))\n",
    "\n",
    "    uniqueYears=np.unique([month.year for month in monthsTime])\n",
    "    for year in uniqueYears:\n",
    "        monthsInAYear=[months[i] for i,month in enumerate(monthsTime) if month.year==year]\n",
    "        monthsTimeInAYear=[monthsTime[i] for i,month in enumerate(monthsTime) if month.year==year]\n",
    "        createFigure(monthsInAYear,monthsTimeInAYear)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda run -n speechEnv python /home/enis/projects/nna/src/slack_message.py -m \"Stinchcomb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('2018-05', Timestamp('2018-05-08 20:00:00')),\n",
       "       ('2018-05', Timestamp('2018-05-09 00:00:00')),\n",
       "       ('2018-05', Timestamp('2018-05-09 02:00:00')), ...,\n",
       "       ('2019-08', Timestamp('2019-08-27 04:00:00')),\n",
       "       ('2019-08', Timestamp('2019-08-27 06:00:00')),\n",
       "       ('2019-08', Timestamp('2019-08-27 08:00:00'))], dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(list(zip(df_freq.index.strftime(\"%Y-%m\"),df_freq.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniquMonth=pd.unique(df_freq.index.strftime(\"%Y-%m-01\"))\n",
    "uniquMonth=[pd.Timestamp(i) for i in uniquMonth]\n",
    "# monthsTime=[month for month in monthsTime if month.strftime(\"%Y-%m\") in uniquMonth]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2018-05-01 00:00:00'),\n",
       " Timestamp('2018-06-01 00:00:00'),\n",
       " Timestamp('2018-07-01 00:00:00'),\n",
       " Timestamp('2018-08-01 00:00:00'),\n",
       " Timestamp('2019-05-01 00:00:00'),\n",
       " Timestamp('2019-06-01 00:00:00'),\n",
       " Timestamp('2019-07-01 00:00:00'),\n",
       " Timestamp('2019-08-01 00:00:00')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, Int64Index([5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4], dtype='int64'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthsTime=pd.date_range(\"{}-{}\".format(all_start.year,all_start.month),\"{}-{}\".format(all_end.year,all_end.month), freq='MS',)\n",
    "# monthsTimeStr=[\"{}-{}\".format(month.year,month.month) for month in monthsTime]\n",
    "# months=[df_freq.loc[month:month] for month in monthsTimeStr]\n",
    "# months=[month for month in months if month.size>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'June'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechEnv",
   "language": "python",
   "name": "speechenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
