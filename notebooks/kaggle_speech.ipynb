{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example dataset-1 from [TensorFlow Speech Recognition Challenge](https://www.tensorflow.org/tutorials/sequences/audio_recognition) <br>\n",
    "I will go through shared kernels. \n",
    "\n",
    "\n",
    "Resources:\n",
    "* Most popular data exploration [kernel](https://www.kaggle.com/davids1992/speech-representation-and-data-exploration) on kaggle\n",
    "* Tensorflow simple audio [tutorial](https://www.tensorflow.org/tutorials/sequences/audio_recognition)\n",
    "* Google Research [Blog Post](https://ai.googleblog.com/2017/08/launching-speech-commands-dataset.html) announcing the Speech Commands Dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1420M  100 1420M    0     0  12.3M      0  0:01:55  0:01:55 --:--:-- 13.8M 12.3M      0  0:01:55  0:01:24  0:00:31 10.6M\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "# Dataset is updated (April 11th 2018) after the competition, we will use new version \n",
    "    \n",
    "# Create  a folder for data\n",
    "if not os.path.exists('../data'):\n",
    "    os.makedirs('../data')\n",
    "if not os.path.exists('../data/speech_commands'):\n",
    "    os.makedirs('../data/speech_commands')\n",
    "\n",
    "# Download dataset\n",
    "!curl --output \"../data/speech_commands_v0.02.tar.gz\" \"http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\"\n",
    "!tar -xzf \"../data/speech_commands_v0.02.tar.gz\" --directory=\"../data/speech_commands\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dataset \n",
    "It include 65,000 one-second long utterances of 30 short words, by thousands of different people. <br>\n",
    "Such as \"yes\",\"no\",\"up\" ..<br>\n",
    "data folder \"speech_commands\" includes folders named after each command<br>\n",
    ">./data\n",
    ">>/speech_commands\n",
    ">>>/yes\n",
    ">>>>/0a7c2a8d_nohash_0.wav\n",
    "\n",
    ">>>/no\n",
    "\n",
    "0a7c2a8d_nohash_0.wav:  0a7c2a8d --> speaker's id, nohash for sorting reasons, 0 means first utterance of that word by this speaker in the data set  \n",
    "Chechout ../data/speech_commands/README.md for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python speechEnv",
   "language": "python",
   "name": "speechenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
