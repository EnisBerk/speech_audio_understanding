{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../src'))\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "import pickle\n",
    "\n",
    "from labeling_utils import load_labels\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "# tags=[\"Songbird\",\"Water Bird\",\"Insect\",\"Running Water\",\"Rain\",\"Cable\",\"Wind\",\"Vehicle\",\"Aircraft\"]\n",
    "tags=[\"Songbird\",\"Water Bird\",\"Insect\",\"Running Water\",\"Rain\",\"Cable\",\"Wind\",\"Aircraft\"]\n",
    "\n",
    "from tabulate import tabulate\n",
    "tag_set=tags[:]\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD MODEL predictions\n",
    "splits_path= Path('/files/scratch/enis/data/nna/labeling/splits/')\n",
    "\n",
    "labelsbymodelpath=Path('/scratch/enis/data/nna/labeling/deep_labels/')\n",
    "dbfile = open(labelsbymodelpath / \"classifications_all_2.pkl\", 'rb')  \n",
    "modelresults = pickle.load(dbfile) \n",
    "dbfile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(modelresults))\n",
    "# aiter=iter(modelresults.keys())\n",
    "# akey=next(aiter)\n",
    "# print(akey)\n",
    "# modelresults[akey]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique files: 1300 \n",
      "total files 1366\n"
     ]
    }
   ],
   "source": [
    "# LOAD LABELS by human\n",
    "labelsbyhumanpath=Path('/scratch/enis/data/nna/labeling/results/')\n",
    "# filter by username\n",
    "labelsbyhuman=[i for i in listdir(labelsbyhumanpath) if (\".csv\" in i) ]\n",
    "\n",
    "humanresults={}\n",
    "counter=0\n",
    "for apath in labelsbyhuman:\n",
    "    with open(labelsbyhumanpath / apath, newline='') as f:\n",
    "        reader=csv.reader(f)\n",
    "        for row in reader:\n",
    "            counter+=1\n",
    "            humanresults[row[0]]=row[1:]\n",
    "\n",
    "print(\"unique files:\",len(humanresults),\"\\ntotal files\",counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join vehicle and Aircraft\n",
    "for file_name,tagshere in humanresults.items():\n",
    "#     print(file_name,tagshere)\n",
    "    \n",
    "    tagshere=[\"Aircraft\" if tag == \"Vehicle\" else tag for tag in tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram={}\n",
    "for file_name in humanresults:\n",
    "    place_name=file_name.split(\"_\")[0]\n",
    "#     print(file_name)\n",
    "    histogram.setdefault(place_name,0)\n",
    "    histogram[place_name]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a=list(histogram.items())\n",
    "a.sort(key=lambda x:x[1],reverse=True)\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load name of the labels\n",
    "labels=load_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "items={}\n",
    "from IPython.display import Audio,display,HTML\n",
    "from ipywidgets import Output\n",
    "\n",
    "items[\"mp3_output\"]=Output()\n",
    "\n",
    "def play_html_modify(mp3file,items={}):\n",
    "#     out=items[\"mp3_output\"]\n",
    "#     displayed=display(HTML(\"<audio controls  loop autoplay><source src={} type='audio/mpeg'></audio>\".format(mp3file)))\n",
    "    displayed=display(HTML(\"<audio controls  loop><source src={} type='audio/mpeg'></audio>\".format(mp3file)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_y_true(humanresults,tag_set):\n",
    "    y_true={tag: [None]*len(humanresults) for tag in tag_set}\n",
    "    for i,tags in enumerate(humanresults.values()):\n",
    "        # we  only look for tags in tag_set\n",
    "        for tag in tag_set:\n",
    "            if tag in tags:\n",
    "                y_true[tag][i] = 1\n",
    "            else:\n",
    "                y_true[tag][i] = 0 \n",
    "    return y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_dict=vectorized_y_true(humanresults,tag_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,filename in enumerate(humanresults.keys()):\n",
    "#     orig,audioop = modelresults[filename]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_path=Path('/scratch/enis/data/nna/labeling/split_embeddings/')\n",
    "# filter by username\n",
    "split_embeds=[i for i in listdir(split_path) ]\n",
    "raw_embeds =  [i for i in split_embeds if \"rawembed\" in i]\n",
    "proc_embeds = [i for i in split_embeds if \"_embed\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10439, 10439, 20878)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(proc_embeds),len(raw_embeds),len(split_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "names = [\"Nearest Neighbors\", \n",
    "#          \"Linear SVM\", \n",
    "         \"RBF SVM\",\n",
    "#          \"Gaussian Process\",\n",
    "         \"Decision Tree\",\n",
    "         \"Random Forest\", \n",
    "         \"Neural Net\",\n",
    "         \"AdaBoost\",\n",
    "         \"Naive Bayes\",\n",
    "         \"QDA\"]\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "    \n",
    "short_names=['N. Neighbors',\n",
    "#  'Linear SVM',\n",
    " 'RBF SVM',\n",
    "#  'Gaussian P.',\n",
    " 'Decision T.',\n",
    " 'Random F.',\n",
    " 'NN',\n",
    " 'AdaBoost',\n",
    " 'Naive B.',\n",
    " 'QDA']\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "#     SVC(probability=True,kernel=\"linear\", C=0.025),\n",
    "    SVC(probability=True,gamma=2, C=1),\n",
    "#     GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def print_result(results):\n",
    "    headers= [\"Tag\",]+short_names\n",
    "    table=[]\n",
    "#     sample_count=len(next(iter(y_true_dict.values())))\n",
    "#     print(\"Total sample:\",sample_count,\"And threshold is\",prob_threshold)\n",
    "    for tag in (tag_set):\n",
    "#         positive_count=sum(y_true_dict[tag])\n",
    "        table.append([tag,*results[tag]])\n",
    "\n",
    "    print(tabulate(table, headers=headers))\n",
    "\n",
    "def reverse_results(results):\n",
    "    results_clf2={}\n",
    "    for tag,scores_per_Tag2 in results.items():\n",
    "        scores_per_Tag=scores_per_Tag2[:]\n",
    "        maximum=max(scores_per_Tag)\n",
    "        scores_per_Tag=[color.BOLD + x + color.END if x==maximum else x for x in scores_per_Tag]\n",
    "\n",
    "        for i,name in enumerate(names):\n",
    "            score=scores_per_Tag[i]\n",
    "            results_clf2.setdefault(name,[])\n",
    "            results_clf2[name].append(score)      \n",
    "    return results_clf2\n",
    "        \n",
    "\n",
    "def print_result2(results):\n",
    "    results_clf=reverse_results(results)\n",
    "    headers= [\"Tag\",]+list(tag_set)\n",
    "    table=[]\n",
    "#     sample_count=len(next(iter(y_true_dict.values())))\n",
    "#     print(\"Total sample:\",sample_count,\"And threshold is\",prob_threshold)\n",
    "#     for tag in tag_set:\n",
    "#         aresult=[]\n",
    "    for i,name in enumerate(names):\n",
    "#         positive_count=sum(y_true_dict[tag])\n",
    "        table.append([short_names[i],*results_clf[name]])\n",
    "    \n",
    "    print(tabulate(table, headers=headers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(X_input,y_true_dict,classifiers,names,tag_set,logs=False,many2one=False):\n",
    "    results={}\n",
    "\n",
    "        \n",
    "    for tag in (tag_set):\n",
    "        data_start=time.time()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_input, y_true_dict[tag], test_size=0.2, random_state=42)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "        if many2one:\n",
    "        # I modift y_train to be bigger to match X_train \n",
    "        # and I modify y_val_pred to be smaller to match y_val\n",
    "#             if logs : print([len(i) for i in [X_train,X_test,X_val]])\n",
    "            [X_train,X_test,X_val]=[np.reshape(x_array,(-1,128)) for x_array in [X_train,X_test,X_val]]\n",
    "\n",
    "#             if logs : print([len(i) for i in [X_train,X_test,X_val]])\n",
    "\n",
    "#             if logs : print([len(i) for i in [y_train,y_test,y_val]])\n",
    "\n",
    "            for y_array in [y_train]:\n",
    "                new_array=np.zeros((len(y_array)*10))\n",
    "                for i,v in enumerate(y_array):\n",
    "                    new_array[i*10:(i+1)*10]=v\n",
    "                y_array[:]=new_array[:]\n",
    "#             if logs : print([len(i) for i in [y_train,y_test,y_val]])\n",
    "        data_end=time.time()\n",
    "        if logs : print(\"data time\",data_end-data_start)\n",
    "        for name, clf in zip(names, classifiers):\n",
    "            start=time.time()\n",
    "            try:\n",
    "#                 if logs : print(X_train.shape)\n",
    "                clf.fit(X_train, y_train)\n",
    "                #VAL\n",
    "#                 y_val_pred=clf.predict_proba(X_val)\n",
    "\n",
    "                #TEST MODE \n",
    "                y_val_pred=clf.predict_proba(X_test)\n",
    "            \n",
    "#                             #VAL\n",
    "#             #                 y_val_pred=clf.predict_proba(X_val)\n",
    "#             #                 score=roc_auc_score(y_val,y_val_pred[:,1:])\n",
    "\n",
    "#                             # TEST\n",
    "#                             y_test_pred=clf.predict_proba(X_test)\n",
    "#                             score=roc_auc_score(y_test,y_test_pred[:,1:])\n",
    "#                                 if logs :print(X_val.shape,y_val_pred.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "                if many2one:\n",
    "                    excerpt_count=int(y_val_pred[:,1:].shape[0]/10)\n",
    "                    if logs : print(\"excerpt_count\",excerpt_count)\n",
    "                    y_val_pred_new= np.empty((excerpt_count,2))\n",
    "                    for i in range(0,y_val_pred.shape[0],10):\n",
    "                        theslice=y_val_pred[i:i+10,1:]\n",
    "                        value=np.max(theslice)\n",
    "                        y_val_pred_new[int(i/10),1:]=value\n",
    "                    y_val_pred=y_val_pred_new\n",
    "                    #TEST\n",
    "                score=roc_auc_score(y_test,y_val_pred[:,1:])\n",
    "#                   #Validate\n",
    "#                 score=roc_auc_score(y_val,y_val_pred[:,1:])\n",
    "    #             score = clf.score(X_val, y_val)\n",
    "                score=\"{:.2}\".format(score)\n",
    "\n",
    "                results.setdefault(tag,[])\n",
    "\n",
    "                results[tag].append(score)\n",
    "\n",
    "                if logs : print(tag,name,score) \n",
    "            except:\n",
    "                score=\"-1\"\n",
    "\n",
    "                results.setdefault(tag,[])\n",
    "\n",
    "                results[tag].append(score)\n",
    "\n",
    "                if logs : print(tag,name,score) \n",
    "            end=time.time()\n",
    "            if logs :print(\"classifier time\",end-start)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_reduce(X,y_true_dict,func_type):\n",
    "    X_copy=X[:]\n",
    "    y_true_dict_copy=copy.deepcopy(y_true_dict)\n",
    "    if func_type==\"Average\":\n",
    "        return np.mean(X_copy,axis=1),y_true_dict_copy\n",
    "    elif func_type==\"Concat\":\n",
    "        return np.reshape(X_copy,(-1,1280)),y_true_dict_copy\n",
    "    elif func_type==\"many2one\":\n",
    "#         for tag_name in y_true_dict_copy:\n",
    "#             new_array=np.zeros((len(y_true_dict_copy[tag_name])*10))\n",
    "#             for i,v in enumerate(y_true_dict_copy[tag_name]):\n",
    "#                 new_array[i*10:(i+1)*10]=v\n",
    "#             y_true_dict_copy[tag_name]=new_array[:]\n",
    "        # will reverse this inside\n",
    "        return np.reshape(X_copy,(-1,1280)),y_true_dict_copy\n",
    "    else:\n",
    "        raise Exception(\"ERROR with embed type\")\n",
    "\n",
    "def pick_embed(embed_type):\n",
    "    # humanresults[proc_embeds[0].replace(\"_embed.npy\",\".mp3\")]\n",
    "    X=[]\n",
    "    for i in humanresults:\n",
    "        if embed_type==\"Raw\":\n",
    "            file_name=i.replace(\".mp3\",\"_rawembed.npy\")\n",
    "        elif embed_type==\"Normalized\":\n",
    "            file_name=i.replace(\".mp3\",\"_embed.npy\")\n",
    "        else:\n",
    "            raise Exception(\"ERROR with embed type\")\n",
    "        an_x=np.load(split_path / file_name)\n",
    "        X.append(an_x)\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "embed_types=[\"Raw\",\"Normalized\"] # \"Raw\" or \"Normalized\"\n",
    "map_reduce_embeds= [\"many2one\",]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Raw embeddings and merged by many2one \n",
      "Tag             Songbird    Water Bird    Insect    Running Water    Rain    Cable    Wind    Aircraft\n",
      "------------  ----------  ------------  --------  ---------------  ------  -------  ------  ----------\n",
      "N. Neighbors        0.73          0.74      0.76             0.87    0.81     0.82    0.78        0.85\n",
      "RBF SVM             0.79          0.77      0.83             \u001b[1m0.9\u001b[0m     \u001b[1m0.84\u001b[0m     \u001b[1m0.86\u001b[0m    0.88        0.86\n",
      "Decision T.         0.81          0.73      0.82             0.88    0.73     0.82    0.82        0.78\n",
      "Random F.           0.69          0.69      0.81             0.87    0.78     0.83    0.86        0.78\n",
      "NN                  \u001b[1m0.86\u001b[0m          \u001b[1m0.81\u001b[0m      \u001b[1m0.86\u001b[0m             0.89    0.82     \u001b[1m0.86\u001b[0m    \u001b[1m0.91\u001b[0m        0.92\n",
      "AdaBoost            0.83          \u001b[1m0.81\u001b[0m      0.85             0.88    0.83     0.85    \u001b[1m0.91\u001b[0m        \u001b[1m0.93\u001b[0m\n",
      "Naive B.            0.76          0.63      0.72             0.68    0.54     0.74    0.74        0.55\n",
      "QDA                 0.51          0.53      0.53             0.5     0.51     0.51    0.51        0.58\n",
      "\n",
      " Normalized embeddings and merged by many2one \n",
      "Tag             Songbird    Water Bird    Insect    Running Water    Rain    Cable    Wind    Aircraft\n",
      "------------  ----------  ------------  --------  ---------------  ------  -------  ------  ----------\n",
      "N. Neighbors        0.7           0.75      0.73             0.84    0.81     0.8     0.79        0.86\n",
      "RBF SVM             0.5           0.5       0.5              0.5     0.5      0.5     0.5         0.5\n",
      "Decision T.         0.79          0.75      0.8              0.86    0.78     0.79    0.84        0.89\n",
      "Random F.           0.79          0.71      0.83             0.83    0.79     0.82    \u001b[1m0.89\u001b[0m        0.79\n",
      "NN                  0.8           \u001b[1m0.8\u001b[0m       0.78             0.88    0.84     0.83    0.86        0.93\n",
      "AdaBoost            \u001b[1m0.84\u001b[0m          0.79      \u001b[1m0.85\u001b[0m             \u001b[1m0.89\u001b[0m    \u001b[1m0.85\u001b[0m     \u001b[1m0.87\u001b[0m    \u001b[1m0.89\u001b[0m        \u001b[1m0.96\u001b[0m\n",
      "Naive B.            0.77          0.65      0.82             0.8     0.78     0.8     0.85        0.92\n",
      "QDA                 0.61          0.64      0.69             0.85    0.8      0.85    0.88        0.8\n"
     ]
    }
   ],
   "source": [
    "all_results={}\n",
    "for embed_type in embed_types:\n",
    "    for map_reduce_type in map_reduce_embeds:\n",
    "        X=pick_embed(embed_type)\n",
    "        X,y_dict=map_reduce(X,y_true_dict,map_reduce_type)\n",
    "        print(\"\\n {} embeddings and merged by {} \".format(embed_type,map_reduce_type))\n",
    "        many2one= True if map_reduce_type==\"many2one\" else False\n",
    "        results=get_results(X,y_dict,classifiers,names,tag_set,logs=False,many2one=many2one)\n",
    "        all_results[embed_type+\"_\"+map_reduce_type]=results\n",
    "        print_result2(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_true_dict[\"Songbird\"])\n",
    "sum(y_true_dict[\"Songbird\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for embed_type in embed_types:\n",
    "#     for map_reduce_type in map_reduce_embeds:\n",
    "#         results=all_results[embed_type+\"_\"+map_reduce_type]\n",
    "#         print(\"\\n{} embeddings and merged by {} \".format(embed_type,map_reduce_type))\n",
    "#         print_result2(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_dict[\"Songbird\"][0:10]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_dict[\"Songbird\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dict[\"Songbird\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag=\"Songbird\"\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X_mean, y_true_dict[tag], test_size=0.2, random_state=42)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# for name, clf in zip(names, classifiers):\n",
    "# #         ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "#     print(name)\n",
    "\n",
    "#     try:\n",
    "#         clf.fit(X_train, y_train)\n",
    "#         y_val_pred=clf.predict_proba(X_val)\n",
    "#         score=roc_auc_score(y_val,y_val_pred[:,1:])\n",
    "#         print(y_val_pred[:10,1:])\n",
    "#         print(clf.classes_)\n",
    "# #         score = clf.score(X_val, y_val)\n",
    "#     except:\n",
    "#         print(\"ERROR\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechEnv",
   "language": "python",
   "name": "speechenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
