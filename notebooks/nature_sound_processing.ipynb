{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nature_sound_processing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "fmRy4ZA8N85s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "first_run=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "INGW9rmSp5K_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "282c4cc4-fbd6-4894-d4b9-7e17ed14822c"
      },
      "cell_type": "code",
      "source": [
        "if first_run==True:\n",
        "  !pip install numpy scipy\n",
        "  !pip install resampy tensorflow six\n",
        "  !pip install pysoundfile \n",
        "  #from mp3 to wav\n",
        "  !pip install pydub\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: resampy in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.13.0rc2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.6/dist-packages (from resampy) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.13 in /usr/local/lib/python3.6/dist-packages (from resampy) (1.1.0)\n",
            "Requirement already satisfied: numba>=0.32 in /usr/local/lib/python3.6/dist-packages (from resampy) (0.40.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.6.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.0rc0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.1)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.32->resampy) (0.27.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.8.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0rc0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0rc0->tensorflow) (5.1.2)\n",
            "Collecting pysoundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/b3/0b871e5fd31b9a8e54b4ee359384e705a1ca1e2870706d2f081dc7cc1693/PySoundFile-0.9.0.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.6/dist-packages (from pysoundfile) (1.12.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=0.6->pysoundfile) (2.19)\n",
            "Installing collected packages: pysoundfile\n",
            "Successfully installed pysoundfile-0.9.0.post1\n",
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/79/db/eaf620b73a1eec3c8c6f8f5b0b236a50f9da88ad57802154b7ba7664d0b8/pydub-0.23.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.23.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bRNRG6q6p_8l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if first_run==True:\n",
        "  import os\n",
        "  import tensorflow as tf\n",
        "  import numpy as np\n",
        "  from pydub import AudioSegment\n",
        "  from scipy.io.wavfile import read "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "81kzhM8Us7GD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "b9d39b6b-4c09-40f5-a36f-cd214e2ec911"
      },
      "cell_type": "code",
      "source": [
        "if first_run==True:\n",
        "\n",
        "#clone repository\n",
        "  !git clone https://github.com/tensorflow/models.git\n",
        "   # Grab the VGGish model\n",
        "  !curl -O https://storage.googleapis.com/audioset/vggish_model.ckpt\n",
        "  !curl -O https://storage.googleapis.com/audioset/vggish_pca_params.npz\n",
        "\n",
        "  # Copy the source files to the current directory.\n",
        "  !cp models/research/audioset/* .\n",
        "\n",
        "  #smoke test\n",
        "  #from vggish_smoke_test import *"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 24145 (delta 0), reused 1 (delta 0), pack-reused 24136\u001b[K\n",
            "Receiving objects: 100% (24145/24145), 506.86 MiB | 32.34 MiB/s, done.\n",
            "Resolving deltas: 100% (14291/14291), done.\n",
            "Checking out files: 100% (2776/2776), done.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  277M  100  277M    0     0  33.3M      0  0:00:08  0:00:08 --:--:-- 50.2M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 73020  100 73020    0     0   369k      0 --:--:-- --:--:-- --:--:--  369k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9_rx8WNos-Vg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "e4146280-0c6b-4306-beda-c4a82d345662"
      },
      "cell_type": "code",
      "source": [
        "if first_run==True:\n",
        "  import vggish_slim\n",
        "  import vggish_params\n",
        "  import vggish_input\n",
        "  import vggish_postprocess\n",
        "\n",
        "def CreateVGGishNetwork(hop_size=0.96):   # Hop size is in seconds.\n",
        "  \"\"\"Define VGGish model, load the checkpoint, and return a dictionary that points\n",
        "  to the different tensors defined by the model.\n",
        "  \"\"\"\n",
        "  vggish_slim.define_vggish_slim()\n",
        "  checkpoint_path = 'vggish_model.ckpt'\n",
        "  vggish_params.EXAMPLE_HOP_SECONDS = hop_size\n",
        "  \n",
        "  vggish_slim.load_vggish_slim_checkpoint(sess, checkpoint_path)\n",
        "\n",
        "  features_tensor = sess.graph.get_tensor_by_name(\n",
        "      vggish_params.INPUT_TENSOR_NAME)\n",
        "  embedding_tensor = sess.graph.get_tensor_by_name(\n",
        "      vggish_params.OUTPUT_TENSOR_NAME)\n",
        "\n",
        "  layers = {'conv1': 'vggish/conv1/Relu',\n",
        "            'pool1': 'vggish/pool1/MaxPool',\n",
        "            'conv2': 'vggish/conv2/Relu',\n",
        "            'pool2': 'vggish/pool2/MaxPool',\n",
        "            'conv3': 'vggish/conv3/conv3_2/Relu',\n",
        "            'pool3': 'vggish/pool3/MaxPool',\n",
        "            'conv4': 'vggish/conv4/conv4_2/Relu',\n",
        "            'pool4': 'vggish/pool4/MaxPool',\n",
        "            'fc1': 'vggish/fc1/fc1_2/Relu',\n",
        "            'fc2': 'vggish/fc2/Relu',\n",
        "            'embedding': 'vggish/embedding',\n",
        "            'features': 'vggish/input_features',\n",
        "         }\n",
        "  g = tf.get_default_graph()\n",
        "  for k in layers:\n",
        "    layers[k] = g.get_tensor_by_name( layers[k] + ':0')\n",
        "    \n",
        "  return {'features': features_tensor,\n",
        "          'embedding': embedding_tensor,\n",
        "          'layers': layers,\n",
        "         }"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F5_vRndauwyb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def ProcessWithVGGish(vgg, x, sr):\n",
        "#   '''Run the VGGish model, starting with a sound (x) at sample rate\n",
        "#   (sr). Return a whitened version of the embeddings. Sound must be scaled to be\n",
        "#   floats between -1 and +1.'''\n",
        "\n",
        "#   # Produce a batch of log mel spectrogram examples.\n",
        "#   input_batch = vggish_input.waveform_to_examples(x, sr)\n",
        "#   # print('Log Mel Spectrogram example: ', input_batch[0])\n",
        "#   print(input_batch.dtype,\"input_batch\")\n",
        "#   input_batch=input_batch.astype(np.float32)\n",
        "#   print(input_batch.dtype,\"input_batch\")\n",
        "\n",
        "  \n",
        "#   [embedding_batch] = sess.run([vgg['embedding']],\n",
        "#                                feed_dict={vgg['features']: input_batch})\n",
        "\n",
        "#   #Postprocess the results to produce whitened quantized embeddings.\n",
        "#   pca_params_path = 'vggish_pca_params.npz'\n",
        "\n",
        "#   pproc = vggish_postprocess.Postprocessor(pca_params_path)\n",
        "#   postprocessed_batch = pproc.postprocess(embedding_batch)\n",
        "#   print('Postprocessed VGGish embedding: ', postprocessed_batch[0])\n",
        "#   return postprocessed_batch[0],embedding_batch\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lAZbkAYbqJlc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "98d7ad7c-320c-4384-f69d-33768ffe0e8f"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "if first_run==True:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "\n",
        "if not wav_files_exist:\n",
        "\n",
        "  "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://deep_learning_enis/speech_audio_understanding/data.tar.gz...\n",
            "Exception in UIThread: \n",
            "^C\n",
            "tar (child): data.tar.gz: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hP6hCJ_HWPce",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OxSKzEojFqoX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5610dbca-4ba2-4ce7-81ba-3644d3a0089a"
      },
      "cell_type": "code",
      "source": [
        "# do we have wav version of files\n",
        "wav_files_exist=True\n",
        "\n",
        "!rm -rf ./data/split_00\\:10_wav/\n",
        "!mkdir -p \"./data/split_00:10_wav/\"\n",
        "\n",
        "if first_run==True and not wav_files_exist:\n",
        "  # Download the file from a given Google Cloud Storage bucket.\n",
        "  !gsutil cp gs://deep_learning_enis/speech_audio_understanding/data.tar.gz ./\n",
        "\n",
        "  !tar xzf data.tar.gz\n",
        "  \n",
        "\n",
        "  mp3_data_files=os.listdir(\"./data/split_00:10/\")\n",
        "  error_file=mp3_data_files.index(\"._FSHCK1_20160726_190204_1440m_00s__1500m_00s_52m_00s__54m_00s_00m_20s__00m_30s.mp3\")\n",
        "  del mp3_data_files[error_file]\n",
        "  \n",
        "  for i,mp3_file in enumerate(mp3_data_files):\n",
        "    sound = AudioSegment.from_mp3(\"./data/split_00:10/\"+mp3_file)\n",
        "    mp3_file_name=mp3_file.split(\".\")[0]\n",
        "    sound.export(\"./data/split_00:10_wav/\"+mp3_file_name+\".wav\", format=\"wav\")\n",
        "    if i%500==0:\n",
        "      print(i/len(mp3_data_files))\n",
        "  # upload wav files\n",
        "  !tar -zcvf data_wav.tar.gz \"./data/split_00:10_wav\"\n",
        "  !gsutil cp data_wav.tar.gz gs://deep_learning_enis/speech_audio_understanding\n",
        "\n",
        "\n",
        "elif wav_files_exist:\n",
        "    # Download the file from a given Google Cloud Storage bucket.\n",
        "  !gsutil cp gs://deep_learning_enis/speech_audio_understanding/data_wav.tar.gz ./\n",
        "\n",
        "  !tar xzf data_wav.tar.gz\n",
        "\n",
        "wav_data_files=os.listdir(\"./data/split_00:10_wav/\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://deep_learning_enis/speech_audio_understanding/data_wav.tar.gz...\n",
            "| [1 files][ 10.3 GiB/ 10.3 GiB]   73.6 MiB/s                                   \n",
            "Operation completed over 1 objects/10.3 GiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FiC2x7N4TFf0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cd1f8a0-009e-487d-9fc9-a2a070c32b98"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "xfsyfBgzuv2B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "eca3a341-9e22-45f7-e977-a943c64e5cec"
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "sess = tf.Session()\n",
        "\n",
        "vgg = CreateVGGishNetwork()\n",
        "\n",
        "pca_params_path = 'vggish_pca_params.npz'\n",
        "pproc = vggish_postprocess.Postprocessor(pca_params_path)\n",
        "\n",
        "\n",
        "batch_size=128\n",
        "sr=44100\n",
        "\n",
        "# OPTION 1 STORE ALL OUTPUTS:\n",
        "# all_data = np.array([], dtype=np.float64).reshape(0,96,64)\n",
        "\n",
        "# data_file_indexes=[]\n",
        "# counter=0\n",
        "\n",
        "# wav_data_files=os.listdir(\"./data/split_00:10_wav/\")\n",
        "\n",
        "# for i,wav_file in enumerate(wav_data_files):\n",
        "#   rate,sound = read(\"./data/split_00:10_wav/\"+wav_file)\n",
        "#   sound=np.array(sound,dtype=float)\n",
        "\n",
        "#   sound = vggish_input.waveform_to_examples(sound, sr)\n",
        "#   data_file_indexes.append((counter,counter+len(sound)))\n",
        "#   counter+=len(sound)\n",
        "#   all_data=np.concatenate((all_data,sound))\n",
        "\n",
        "#   if i%500==0:\n",
        "#     print(i/len(wav_data_files))\n",
        "\n",
        "# # all_data=np.load('all_data.npy')\n",
        "\n",
        "# embeddings = np.array([], dtype=np.float32).reshape(0,128)\n",
        "# postprocessed = np.array([], dtype=np.float32).reshape(0,128)\n",
        "\n",
        "\n",
        "# for batch_index in range(0,all_data.shape[0],batch_size):\n",
        "#   if (batch_index+batch_size) <all_data.shape[0]:\n",
        "#     input_batch = all_data[batch_index:batch_index+batch_size]\n",
        "    \n",
        "#     [embedding_batch] = sess.run([vgg['embedding']],\n",
        "#                              feed_dict={vgg['features']: input_batch})\n",
        "#     embeddings=np.concatenate((embeddings,embedding_batch))\n",
        "    \n",
        "#     postprocessed_batch = pproc.postprocess(embedding_batch)\n",
        "#     postprocessed=np.concatenate((postprocessed,postprocessed_batch))\n",
        "#     if batch_index%(batch_size*20)==0:\n",
        "#       print(batch_index/all_data.shape[0])\n",
        "\n",
        "# np.save(\"all_data2.npy\",all_data)\n",
        "# np.save(\"data_file_indexes2.npy\",data_file_indexes)\n",
        "# np.save(\"embeddings2.npy\",embeddings)\n",
        "# np.save(\"postprocessed2.npy\",postprocessed)\n",
        "\n",
        "# !gsutil cp all_data2.npy gs://deep_learning_enis/speech_audio_understanding\n",
        "# !gsutil cp embeddings2.npy gs://deep_learning_enis/speech_audio_understanding\n",
        "# !gsutil cp postprocessed2.npy gs://deep_learning_enis/speech_audio_understanding\n",
        "# !gsutil cp data_file_indexes2.npy gs://deep_learning_enis/speech_audio_understanding\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BLK9pUVj8s3D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6f22066a-ea26-439a-a6a4-201582e5b3d1"
      },
      "cell_type": "code",
      "source": [
        "#wav file: indexes of signal that it generated (10,22) means embeddings[10,22] belong to that wav file\n",
        "data_file_indexes={}\n",
        "counter=0\n",
        "\n",
        "embeddings = np.array([], dtype=np.float32).reshape(0,128)\n",
        "postprocessed = np.array([], dtype=np.float32).reshape(0,128)\n",
        "\n",
        "\n",
        "\n",
        "for batch_index in range(0,len(wav_data_files),batch_size):\n",
        "  if (batch_index+batch_size) <len(wav_data_files):\n",
        "    a_batch=wav_data_files[batch_index:batch_index+batch_size]\n",
        "  else:\n",
        "    a_batch=wav_data_files[batch_index:]\n",
        "  \n",
        "  # wav to one second signals\n",
        "  batch_processed = np.array([], dtype=np.float64).reshape(0,96,64)\n",
        "  for i,wav_file in enumerate(a_batch):\n",
        "      rate,sound = read(\"./data/split_00:10_wav/\"+wav_file)\n",
        "      sound=np.array(sound,dtype=float)\n",
        "\n",
        "      sound = vggish_input.waveform_to_examples(sound, sr)\n",
        "      data_file_indexes[wav_file]=(counter,counter+len(sound))\n",
        "      counter+=len(sound)\n",
        "      batch_processed=np.concatenate((batch_processed,sound))\n",
        "  # signals to tensors\n",
        "  [embedding_batch] = sess.run([vgg['embedding']],\n",
        "                           feed_dict={vgg['features']: batch_processed})\n",
        "  \n",
        "  embeddings=np.concatenate((embeddings,embedding_batch))\n",
        "  postprocessed_batch = pproc.postprocess(embedding_batch)\n",
        "  postprocessed=np.concatenate((postprocessed,postprocessed_batch))\n",
        "  if batch_index%(batch_size*20)==0:\n",
        "    print(batch_index/len(wav_data_files))\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "0.26666666666666666\n",
            "0.5333333333333333\n",
            "0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9c9cvqXc9YFY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "8cc42b14-bb41-4f7a-c483-2cd45c2f3024"
      },
      "cell_type": "code",
      "source": [
        "np.save(\"data_file_indexes2.npy\",data_file_indexes)\n",
        "np.save(\"embeddings2.npy\",embeddings)\n",
        "np.save(\"postprocessed2.npy\",postprocessed)\n",
        "\n",
        "!gsutil cp embeddings2.npy gs://deep_learning_enis/speech_audio_understanding\n",
        "!gsutil cp postprocessed2.npy gs://deep_learning_enis/speech_audio_understanding\n",
        "!gsutil cp data_file_indexes2.npy gs://deep_learning_enis/speech_audio_understanding\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://embeddings2.npy [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/46.9 MiB.                                     \n",
            "Copying file://postprocessed2.npy [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/46.9 MiB.                                     \n",
            "Copying file://data_file_indexes2.npy [Content-Type=application/octet-stream]...\n",
            "/ [1 files][973.2 KiB/973.2 KiB]                                                \n",
            "Operation completed over 1 objects/973.2 KiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vf_HqsxTFHc3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A2bVbHSOqJmI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ebr7Tq27qujW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "first_run=False\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Y3m_FaGqwBj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gXdJbQxXsJlP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YUPb50rtsK7W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zNP5Qh-04c59",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l121DgP5sL01",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # dates=[]\n",
        "# all_files=[]\n",
        "# for name in data_files:\n",
        "#   file_id=name\n",
        "#   name=name.split(\"_\")\n",
        "# #   if len(name)!=18:\n",
        "# #     print(name)\n",
        "#   site_name=name[0]\n",
        "#   date=name[1]\n",
        "#   year=date[0:4]\n",
        "#   month=date[4:6]\n",
        "#   day=date[6:8]\n",
        "  \n",
        "#   site_id=name[2]\n",
        "\n",
        "# #   if year==\"2013\" and site_name==\"UMIAT\":\n",
        "# #     print(name)\n",
        "#   all_files.append(name)\n",
        "# #   if len(date)!=len(\"20160809\"):\n",
        "# #     print(name)\n",
        "# #   dates.append((year,month,day))\n",
        "# # site_name,date(YYYY,MM,DD),hour(HHMMSS),total_running_time_start(M,S),total_running_time_end(M,S), start-end(M,S,) start-end (M,S),start-end(M,S,) start-end (M,S)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-UZMoPdMsxkM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K53kfnmSwZke",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fb6hdsNEweLg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nAF2JCVQw7PJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}