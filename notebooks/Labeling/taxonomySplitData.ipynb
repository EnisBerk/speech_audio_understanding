{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ortools.linear_solver import pywraplp\n",
    "\n",
    "from scipy.stats import entropy as kl_div\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# sheetOrg=\"/Users/berk/Desktop/NNA/downloads/Sheet1.csv\"\n",
    "# sheetMine=\"/Users/berk/Desktop/NNA/downloads/Sheet1(1).csv\"\n",
    "\n",
    "resources_folder = ('/scratch/enis/archive/' +\n",
    "                    'forks/cramer2020icassp/resources/')\n",
    "src_path = '/scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite/'\n",
    "megan_labeled_files_info_path = src_path + 'meganLabeledFiles_wlenV1.txt'\n",
    "\n",
    "# csv4megan_excell = (resources_folder + 'Sheet1.csv')\n",
    "csv4megan_excell_clenaed = (resources_folder + 'Sheet1(1).csv')\n",
    "csv4megan_excell = (resources_folder + 'Sheet1.csv')\n",
    "\n",
    "\n",
    "with open(csv4megan_excell_clenaed) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    reader= list(reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reader[0]\n",
    "\n",
    "from typing import Dict, Union, Optional, Type\n",
    "from nna import dataimport\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_taxo_code2dataset(megan_data_sheet, audio_dataset):\n",
    "    '''Go through rows of the excell and store taxonomy info into audio_dataset\n",
    "    '''\n",
    "    codest_dict = {}\n",
    "    \n",
    "    for row in megan_data_sheet:\n",
    "        try:\n",
    "            taxonomy_code = dataimport.megan_excell_row2yaml_code(row, None)\n",
    "            site_id=row['Site ID'].strip()\n",
    "            codest_dict.setdefault(taxonomy_code,Counter({}))\n",
    "\n",
    "            codest_dict[taxonomy_code]=codest_dict[taxonomy_code]+Counter({site_id:1})\n",
    "        except:\n",
    "            print(row)\n",
    "    return codest_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(70, 42.0, 42.0), (71, 20, 20), (88, 15.0, 15.0), (79, 23.0, 23.0), (78, 34.0, 34.0), (75, 29.0, 29.0), (76, 26.0, 26.0), (82, 27.0, 27.0), (69, 34.0, 34.0), (68, 44.0, 44.0), (78, 24.0, 24.0), (70, 38.0, 38.0), (87, 24.0, 24.0), (84, 20.0, 20.0), (74, 38.0, 38.0), (68, 22, 22), (74, 23.0, 23.0), (71, 36.0, 36.0), (82, 30.0, 30.0), (75, 36.0, 36.0), (75, 26.0, 26.0), (73, 23.0, 23.0), (88, 20.0, 20.0), (72, 24.0, 24.0), (75, 33.0, 33.0), (72, 40.0, 40.0), (79, 20.0, 20.0), (69, 30.0, 30.0), (67, 27.0, 27.0), (68, 40.0, 40.0), (80, 29.0, 29.0), (67, 36.0, 36.0), (84, 26.0, 26.0), (77, 24.0, 24.0), (88, 14.0, 14.0), (88, 16.0, 16.0), (66, 44.0, 44.0), (86, 24.0, 24.0), (74, 35.0, 35.0), (84, 23.0, 23.0), (83, 23.0, 23.0), (76, 22.0, 22.0), (85, 13, 13), (83, 26.0, 26.0), (72, 28.0, 28.0), (78, 28.0, 28.0), (86, 13, 13), (68, 36.0, 36.0), (80, 23.0, 23.0), (73, 19, 19), (87, 20.0, 20.0), (85, 19.0, 19.0), (74, 19, 19), (71, 32.0, 32.0), (85, 24.0, 24.0), (84, 28.0, 28.0), (68, 31.0, 31.0), (78, 17, 17), (69, 26.0, 26.0), (79, 16, 16), (67, 31.0, 31.0), (83, 20.0, 20.0), (72, 32.0, 32.0), (66, 31.0, 31.0), (69, 21, 21), (67, 40.0, 40.0), (88, 18.0, 18.0), (66, 40.0, 40.0), (70, 21, 21), (71, 28.0, 28.0), (76, 36.0, 36.0), (73, 27.0, 27.0), (88, 24.0, 24.0), (78, 31.0, 31.0), (76, 18, 18), (69, 42.0, 42.0), (79, 26.0, 26.0), (79, 32.0, 32.0), (83, 14, 14), (70, 26.0, 26.0), (76, 33.0, 33.0), (70, 30.0, 30.0), (81, 30.0, 30.0), (80, 16, 16), (80, 32.0, 32.0), (74, 31.0, 31.0), (77, 21.0, 21.0), (88, 17.0, 17.0), (75, 18, 18), (73, 31.0, 31.0), (82, 18.0, 18.0), (88, 12, 12), (68, 27.0, 27.0), (78, 21.0, 21.0), (77, 31.0, 31.0), (87, 15.0, 15.0), (66, 27.0, 27.0), (67, 22, 22), (67, 44.0, 44.0), (70, 34.0, 34.0), (88, 22.0, 22.0), (66, 36.0, 36.0), (86, 16.0, 16.0), (71, 24.0, 24.0), (87, 17.0, 17.0), (88, 11, 11), (85, 26.0, 26.0), (83, 17.0, 17.0), (86, 26.0, 26.0), (73, 35.0, 35.0), (82, 15, 15), (69, 38.0, 38.0), (85, 21.0, 21.0), (80, 26.0, 26.0), (81, 27.0, 27.0), (73, 38.0, 38.0), (72, 20, 20), (72, 36.0, 36.0), (81, 15, 15), (82, 24.0, 24.0), (86, 21.0, 21.0), (87, 12, 12), (81, 18.0, 18.0), (74, 27.0, 27.0), (84, 17.0, 17.0), (77, 17, 17), (71, 40.0, 40.0), (75, 22.0, 22.0), (81, 21.0, 21.0), (85, 16.0, 16.0), (82, 21.0, 21.0), (83, 28.0, 28.0), (79, 29.0, 29.0), (66, 22, 22), (76, 29.0, 29.0), (86, 19.0, 19.0), (84, 14, 14), (77, 28.0, 28.0), (77, 34.0, 34.0), (87, 22.0, 22.0), (81, 24.0, 24.0), (80, 20.0, 20.0)}\n"
     ]
    }
   ],
   "source": [
    "# [0.6,0.2,0.2]\n",
    "# [0.7,0.15,0.15]\n",
    "# [0.8,0.1,0.1]\n",
    "def getCombinations(total):\n",
    "    combinations=set()\n",
    "    for i in range(100,201,1):\n",
    "        test_val_dist=i/1000\n",
    "        train_dist=1-(test_val_dist*2)\n",
    "        dist=np.array([train_dist,test_val_dist,test_val_dist])\n",
    "        bin_capacities=tuple(np.ceil(total*dist).astype(\"int\"))\n",
    "        combinations.add(bin_capacities)\n",
    "\n",
    "    #add some combinations that are test and valid are bigger so that small number of elements can be handled\n",
    "    combinations2=combinations.copy()\n",
    "    for comb in combinations2:\n",
    "        for rate in [1.2,1.4,1.6,1.8,2.0]:\n",
    "            newComb=(comb[0],np.ceil(comb[1]*rate),np.ceil(comb[1]*rate))\n",
    "            combinations.add(newComb)\n",
    "\n",
    "    return combinations\n",
    "\n",
    "# test\n",
    "total=110\n",
    "# dist = np.array([0.6,0.2,0.2])\n",
    "print(getCombinations(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def JSD(P, Q):\n",
    "    _P = P / norm(P, ord=1)\n",
    "    _Q = Q / norm(Q, ord=1)\n",
    "    _M = 0.5 * (_P + _Q)\n",
    "    return 0.5 * (kl_div(_P, _M) + kl_div(_Q, _M))\n",
    "\n",
    "def create_data_model(weights,values,bin_capacities):\n",
    "    \"\"\"Create the data for the example.\"\"\"\n",
    "    data = {}\n",
    "    data['weights'] = weights\n",
    "    data['values'] = values\n",
    "    data['items'] = list(range(len(weights)))\n",
    "    data['num_items'] = len(weights)\n",
    "    num_bins = 5\n",
    "    data['bins'] = list(range(3))\n",
    "    total=sum(weights)\n",
    "#     print(total)\n",
    "#     bin_capacities = np.ceil(total*dist).astype(\"int\")\n",
    "    data['bin_capacities'] = bin_capacities\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [(k,v) for (k,v) in codesDict.items() if sum(v.values())<25]\n",
    "\n",
    "def main(codesDict,dist):\n",
    "    total=0\n",
    "    solutionPerTaxonomy={}\n",
    "    for k in codesDict.keys():\n",
    "        \n",
    "        weights=list(codesDict[k].values())\n",
    "        values = list(codesDict[k].values())\n",
    "        if sum(weights)<10:\n",
    "            print(k)\n",
    "            print(\"Error, too small\", weights)\n",
    "            continue\n",
    "        if len(weights)<3:\n",
    "            print(k)\n",
    "            print(\"Error, number of elements less than 3\", weights)\n",
    "            continue\n",
    "        \n",
    "        total=sum(weights)\n",
    "        \n",
    "\n",
    "        combinations=getCombinations(total,dist)\n",
    "        \n",
    "#         solutionPerCombination=[]\n",
    "        solutionPerTaxonomy.setdefault(k,[])\n",
    "        for bin_capacities in combinations:\n",
    "            \n",
    "            data = create_data_model(weights,values,bin_capacities)\n",
    "            # old version of ortools\n",
    "            # Create the mip solver with the CBC backend.\n",
    "#             solver = pywraplp.Solver.CreateSolver('multiple_knapsack_mip', 'CBC')\n",
    "            # new version of ortools=>8.1\n",
    "            solver = pywraplp.Solver.CreateSolver('SCIP')\n",
    "\n",
    "            # Variables\n",
    "            # x[i, j] = 1 if item i is packed in bin j.\n",
    "            x = {}\n",
    "            for i in data['items']:\n",
    "                for j in data['bins']:\n",
    "                    x[(i, j)] = solver.IntVar(0, 1, 'x_%i_%i' % (i, j))\n",
    "\n",
    "            # Constraints\n",
    "            # Each item can be in at most one bin.\n",
    "            for i in data['items']:\n",
    "                solver.Add(sum(x[i, j] for j in data['bins']) <= 1)\n",
    "            # The amount packed in each bin cannot exceed its capacity.\n",
    "            for j in data['bins']:\n",
    "                solver.Add(\n",
    "                    sum(x[(i, j)] * data['weights'][i]\n",
    "                        for i in data['items']) <= data['bin_capacities'][j])\n",
    "\n",
    "            # Objective\n",
    "            objective = solver.Objective()\n",
    "\n",
    "            for i in data['items']:\n",
    "                for j in data['bins']:\n",
    "                    objective.SetCoefficient(x[(i, j)], data['values'][i])\n",
    "            objective.SetMaximization()\n",
    "\n",
    "            status = solver.Solve()\n",
    "\n",
    "            if status == pywraplp.Solver.OPTIMAL:\n",
    "#                 if objective.Value()/sum(data['bin_capacities'])>0.90:\n",
    "#                     continue\n",
    "\n",
    "                total+=sum(data['weights'])\n",
    "\n",
    "#                 print(codesDict[k])\n",
    "#                 print(\"------------\",k,\"--------------\")\n",
    "#                 print('Total packed value:', objective.Value(),\"/\",sum(data['bin_capacities']))\n",
    "\n",
    "    #             print()\n",
    "                total_weight = 0\n",
    "                solution=[list() for i in range(len(data['bins']))]\n",
    "                for binIndex,j in enumerate(data['bins']):\n",
    "                    bin_weight = 0\n",
    "                    bin_value = 0\n",
    "#                     print('Bin ', j, '\\n')\n",
    "                    for i in data['items']:\n",
    "                        if x[i, j].solution_value() > 0:\n",
    "                            solution[j].append(data['weights'][i])\n",
    "#                             print('Item', i, '- weight:', data['weights'][i], ' value:',\n",
    "#                                   data['values'][i])\n",
    "                            bin_weight += data['weights'][i]\n",
    "                            bin_value += data['values'][i]\n",
    "                            \n",
    "#                     print('Packed bin weight:', bin_weight,\"/\",data['bin_capacities'][binIndex])\n",
    "    #                 print('bin capacity:',)\n",
    "    #                 print('Packed bin value:', bin_value)\n",
    "                    total_weight += bin_weight\n",
    "#                 print('Total packed weight:', total_weight)\n",
    "                solutionPerTaxonomy[k].append((bin_capacities,solution[:]))\n",
    "            else:\n",
    "                print('The problem does not have an optimal solution.')\n",
    "#             print(\"total\",total)\n",
    "    return solutionPerTaxonomy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(codesDict):\n",
    "    expectedDist=[0.6,0.2,0.2]\n",
    "    results=[]\n",
    "    BestSolutionPerTaxonomy={}\n",
    "\n",
    "    for taxoKey in solutionPerTaxonomy:\n",
    "        found=False\n",
    "        total=sum(codesDict[taxoKey].values())\n",
    "\n",
    "        for i in solutionPerTaxonomy[taxoKey]:\n",
    "            if total==sum([sum(m) for m in i[1]]):\n",
    "                found=True\n",
    "        if found is False:\n",
    "            print(codesDict[taxoKey].values())\n",
    "            print(total)\n",
    "\n",
    "    #         for i in solutionPerTaxonomy[taxoKey]:\n",
    "    #             print(i[0],,sum([sum(m) for m in i[1]]))\n",
    "\n",
    "        costPerDist=[]\n",
    "        smallest=999999\n",
    "        bestComp=None\n",
    "        bestDist=None\n",
    "        for i in solutionPerTaxonomy[taxoKey]:\n",
    "    #         print(dist=[sum(m) for m in i[1]])\n",
    "            dist=[sum(m) for m in i[1]]\n",
    "            cost=JSD(expectedDist,dist)\n",
    "            if cost<smallest and total-sum(dist)==0:\n",
    "                smallest=cost\n",
    "                bestComp=i[1]\n",
    "                bestDist=[sum(m) for m in i[1]]\n",
    "\n",
    "        combinedSorted=sorted(list(zip(bestDist,bestComp)),reverse=True)\n",
    "        a,b=[],[]\n",
    "        for m in combinedSorted:\n",
    "            a.append(m[0])\n",
    "            b.append(m[1])\n",
    "        bestDist,bestComp=a,b\n",
    "\n",
    "        results.append([cost,bestDist,bestComp])\n",
    "\n",
    "        BestSolutionPerTaxonomy[taxoKey] = [cost,bestDist,bestComp]\n",
    "    return results,BestSolutionPerTaxonomy\n",
    "\n",
    "    #     if total-sum(bestDist)!=0:\n",
    "    #         print(\"BAD\")\n",
    "    #     print(taxoKey)\n",
    "    #     print(codesDict[taxoKey].values())\n",
    "    #     print(\"total\",total,sum(bestDist),bestDist)\n",
    "\n",
    "    #     print(bestComp)\n",
    "    # #         costPerDist.append()\n",
    "    #     for i in solutionPerTaxonomy[taxoKey]:\n",
    "    #         dist=[sum(m) for m in i[1]]\n",
    "    #         print(dist,sum(dist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BestSolutionPerTaxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func2(codesDict,BestSolutionPerTaxonomy):\n",
    "    solReverse={i:{} for i in codesDict.keys()}\n",
    "    for taxo, counter in codesDict.items():\n",
    "        counter=dict(counter)\n",
    "        for x,y in counter.items():\n",
    "            solReverse[taxo].setdefault(y, []).append(x)\n",
    "\n",
    "    BestSolutionPerTaxonomyLocation={i:None for i in BestSolutionPerTaxonomy.keys()}\n",
    "    for taxo, data in BestSolutionPerTaxonomy.items():\n",
    "    #     print(taxo,data)\n",
    "        comb=data[2]\n",
    "        train,test,val=comb[:]\n",
    "        combLocation=[[] for i in range(len(comb))]\n",
    "        for i,dataSet in enumerate(comb):\n",
    "            for v in dataSet:\n",
    "                location=solReverse[taxo][v].pop()\n",
    "                combLocation[i].append(location)\n",
    "        BestSolutionPerTaxonomyLocation[taxo]=combLocation\n",
    "    return BestSolutionPerTaxonomyLocation\n",
    "    #     print(combLocation)\n",
    "    #     break\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excellNames2code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def func3(BestSolutionPerTaxonomyLocation,excellNames2code=None,):\n",
    "    # train test valid\n",
    "    # BestSolutionPerTaxonomyLocation\n",
    "    if excellNames2code is None:\n",
    "        excell_names2code = {\n",
    "                'anth': '0.0.0',\n",
    "                'auto': '0.1.0',\n",
    "                'bio': '1.0.0',\n",
    "                'bird': '1.1.0',\n",
    "                'bug': '1.3.0',\n",
    "                'dgs': '1.1.7',\n",
    "                'flare': '0.4.0',\n",
    "                'fox': '1.2.4',\n",
    "                'geo': '2.0.0',\n",
    "                'grouse': '1.1.8',\n",
    "                'loon': '1.1.3',\n",
    "                'mam': '1.2.0',\n",
    "                'plane': '0.2.0',\n",
    "                'ptarm': '1.1.8',\n",
    "                'rain': '2.1.0',\n",
    "                'seab': '1.1.5',\n",
    "                'silence': '3.0.0',\n",
    "                'songbird': '1.1.10',\n",
    "                'unknown': 'X.X.X',\n",
    "                'water': '2.2.0',\n",
    "                'x': 'X.X.X',\n",
    "            }\n",
    "    for yamlCode, data in BestSolutionPerTaxonomyLocation.items():\n",
    "    #     print(yamlCode)\n",
    "        fileCode=yamlCode.replace(\".\",\"-\")\n",
    "        for dataSet in data:\n",
    "            for loc in dataSet:\n",
    "                fileName=(\"_\".join([\"site-\"+str(loc),fileCode,\"original.h5\"]))\n",
    "                pathFile=\"./resources/myDatasets/megan/\"+fileName\n",
    "#                 print(pathFile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# birdvox-cls-test\n",
    "# birdvox-cls-train\n",
    "# birdvox-cls-valid\n",
    "# load files with librosa, sample to \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('Site ID', '12'), ('Anthro/Bio', 'Bio/Anth'), ('Category', 'Bird/Plane'), ('Specific Category', ''), ('Comments', 'raven, songbirds, long tailed ducks with aircraft in background'), ('', ''), ('File Name', 'S4A10268_20190610_103000_bio_anth.wav'), ('Could not decice', 'FALSE'), ('Songbird', 'FALSE'), ('Water Bird', 'FALSE'), ('Insect', 'FALSE'), ('Running Water', 'FALSE'), ('Rain', 'FALSE'), ('Cable', 'FALSE'), ('Wind', 'FALSE'), ('Vehicle', 'FALSE'), ('Aircraft', 'FALSE'), ('Date dd/mm/yy)', '6/6/2019'), ('Start Time', '1:05:22'), ('End Time', '1:05:53'), ('#VALUE!', '0:00:31')])\n",
      "1.2.4\n",
      "Error, too small [2]\n",
      "1.1.5\n",
      "Error, too small [1, 2]\n",
      "1.2.0\n",
      "Error, too small [1]\n",
      "0.4.0\n",
      "Error, too small [5, 3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "codest_dict2 = add_taxo_code2dataset(reader,[])\n",
    "total2=110\n",
    "dist2 = np.array([0.6,0.2,0.2])\n",
    "#test\n",
    "# np.ceil(total*dist).astype(\"int\")\n",
    "solutionPerTaxonomy=main(codest_dict2,dist2)\n",
    "results2,BestSolutionPerTaxonomy2 =func(codest_dict2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results2=sorted(results2,reverse=True)\n",
    "[i[1] for i in results2]\n",
    "# len(results),len(codesDict.keys())\n",
    "\n",
    "BestSolutionPerTaxonomyLocation2 = func2(codest_dict2,BestSolutionPerTaxonomy2)\n",
    "# BestSolutionPerTaxonomyLocation\n",
    "func3(BestSolutionPerTaxonomyLocation2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.0.0': [['44', '46', '17', '14'],\n",
       "  ['11', '34', '27'],\n",
       "  ['31', '50', '18', '12', '30', '39', '48', '45']],\n",
       " '3.0.0': [['40', '20', '14', '17', '13', '36', '25', '33'],\n",
       "  ['18', '38', '39'],\n",
       "  ['32', '45']],\n",
       " 'X.X.X': [['45', '14', '27', '25', '34', '46', '29', '18', '38'],\n",
       "  ['36'],\n",
       "  ['32', '20', '21']],\n",
       " '1.1.10': [['49', '48', '19', '16', '22', '37', '29', '25', '31', '27'],\n",
       "  ['46', '20', '11', '33', '24'],\n",
       "  ['17', '21', '39', '30', '38', '18', '47', '50', '14']],\n",
       " '1.1.0': [['12',\n",
       "   '37',\n",
       "   '11',\n",
       "   '22',\n",
       "   '18',\n",
       "   '44',\n",
       "   '29',\n",
       "   '46',\n",
       "   '13',\n",
       "   '34',\n",
       "   '25',\n",
       "   '24',\n",
       "   '17',\n",
       "   '40',\n",
       "   '31',\n",
       "   '27',\n",
       "   '14'],\n",
       "  ['19', '16', '39', '30', '38', '41'],\n",
       "  ['50', '20', '47', '49', '48', '21', '15', '36']],\n",
       " '1.3.0': [['21', '40', '32', '39', '41', '44'],\n",
       "  ['50', '20', '38', '11'],\n",
       "  ['24', '19', '27', '14']],\n",
       " '1.1.8': [['20', '16', '11', '37', '15', '25', '31'],\n",
       "  ['21', '49', '38'],\n",
       "  ['22', '40']],\n",
       " '1.1.7': [['16', '30', '15', '46', '27'],\n",
       "  ['49', '25', '24'],\n",
       "  ['20', '39', '48', '19', '38', '22', '29', '11', '40']],\n",
       " '0.2.0': [['17'], ['24', '27'], ['19', '15']],\n",
       " '0.0.0': [['29'], ['24'], ['12', '27']],\n",
       " '1.1.3': [['46', '25'], ['24'], ['27', '22', '38']],\n",
       " '2.1.0': [['34', '33'], ['36'], ['46']],\n",
       " '0.1.0': [['29'], ['25'], ['24']]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BestSolutionPerTaxonomyLocation2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('Site ID', '12'), ('Anthro/Bio', 'Bio/Anth'), ('Category', 'Bird/Plane'), ('Specific Category', ''), ('Comments', 'raven, songbirds, long tailed ducks with aircraft in background'), ('', ''), ('File Name', 'S4A10268_20190610_103000_bio_anth.wav'), ('Could not decice', 'FALSE'), ('Songbird', 'FALSE'), ('Water Bird', 'FALSE'), ('Insect', 'FALSE'), ('Running Water', 'FALSE'), ('Rain', 'FALSE'), ('Cable', 'FALSE'), ('Wind', 'FALSE'), ('Vehicle', 'FALSE'), ('Aircraft', 'FALSE'), ('Date dd/mm/yy)', '6/6/2019'), ('Start Time', '1:05:22'), ('End Time', '1:05:53'), ('#VALUE!', '0:00:31')])\n",
      "1.2.4\n",
      "Error, too small [2]\n",
      "1.1.5\n",
      "Error, too small [1, 2]\n",
      "1.2.0\n",
      "Error, too small [1]\n",
      "0.4.0\n",
      "Error, too small [5, 3]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soundenv3",
   "language": "python",
   "name": "soundenv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
