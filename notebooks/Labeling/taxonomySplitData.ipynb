{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheetOrg=\"/Users/berk/Desktop/NNA/downloads/Sheet1.csv\"\n",
    "sheetMine=\"/Users/berk/Desktop/NNA/downloads/Sheet1(1).csv\"\n",
    "\n",
    "import csv\n",
    "\n",
    "with open(sheetOrg) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    reader= list(reader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meganLabeledFiles_len[\"S4A10275_20190806_043000_bio_bird21.wav\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meganLabeledFiles_len={}\n",
    "meganLabeledFiles_path={}\n",
    "with open(\"/Users/berk/Documents/research/scratch/meganLabeledFiles_wlenV1.txt\",\"r\") as f:\n",
    "    lines=f.readlines()\n",
    "    lines=[i.strip().split(\",\") for i in lines ]\n",
    "#     meganLabeledFiles_path={i[0].split(\"/\")[-1]:i[0] for i in lines}\n",
    "    for i in lines:\n",
    "#         meganLabeledFiles_path.setdefault(i[0].split(\"/\")[-1],)\n",
    "        meganLabeledFiles_path[i[0].split(\"/\")[-1]]=(i[0])\n",
    "    lines=[(i[0].split(\"/\")[-1],i[1]) for i in lines]\n",
    "    meganLabeledFiles_len={i[0]:i[1] for i in lines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(list(meganLabeledFiles_len.items()),key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S4A10275_20190806_043000_bio_bird21.wav', 'S4A10275_20190806_043000_bio_bird22.wav', 'S4A10268_20190606_091602_Anth01_airc.wav', 'S4A10270_20190720_023000_Bio_Bird22.wav']\n"
     ]
    }
   ],
   "source": [
    "missingAudioFiles=[]\n",
    "for row in reader:\n",
    "    a=meganLabeledFiles_len.get(row['File Name'],None)\n",
    "    if a:\n",
    "        pass\n",
    "#         print(a)\n",
    "        \n",
    "    else:\n",
    "#         print(row['File Name'])\n",
    "        missingAudioFiles.append(row['File Name'])\n",
    "\n",
    "print(missingAudioFiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "excellNames2code={'anth':\"0.0.0\",\n",
    " 'auto':\"0.1.0\",\n",
    " 'bio':\"1.0.0\",\n",
    " 'bird':\"1.1.0\",\n",
    " 'bug':\"1.3.0\",\n",
    " 'dgs':\"1.1.7\",\n",
    " 'flare':\"0.4.0\",\n",
    " 'fox':\"1.2.4\",\n",
    " 'geo':\"X.X.X\",\n",
    " 'grouse':\"1.1.8\",\n",
    " 'loon':'1.1.3',\n",
    " 'mam':\"1.2.0\",\n",
    " 'plane':\"0.2.0\",\n",
    " 'ptarm':'1.1.8',\n",
    " 'rain':\"X.X.X\",\n",
    " 'seab':'1.1.5',\n",
    " 'silence':\"X.X.X\",\n",
    " 'songbird':\"X.X.X\",\n",
    " 'unknown':\"X.X.X\",\n",
    " 'water':\"X.X.X\",\n",
    " 'x':\"X.X.X\"}\n",
    "\n",
    "# a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Site ID': '22',\n",
       " 'File Name': 'S4A10275_20190806_043000_bio_bird_DGS1.wav',\n",
       " 'Date dd/mm/yy)': '6/8/2019',\n",
       " 'Start Time': '0:30:48',\n",
       " 'End Time': '0:30:58',\n",
       " 'Anthro/Bio': 'Bio',\n",
       " 'Category': 'Bird',\n",
       " 'Specific Category': 'DGS',\n",
       " 'Comments': ''}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheetOrg=\"/Users/berk/Desktop/NNA/downloads/Sheet1.csv\"\n",
    "sheetMine=\"/Users/berk/Desktop/NNA/downloads/Sheet1(1).csv\"\n",
    "\n",
    "import csv\n",
    "\n",
    "with open(sheetOrg) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    reader= list(reader)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "missingAudioFiles=['S4A10275_20190806_043000_bio_bird21.wav', 'S4A10275_20190806_043000_bio_bird22.wav', 'S4A10268_20190606_091602_Anth01_airc.wav', 'S4A10270_20190720_023000_Bio_Bird22.wav']\n",
    "\n",
    "\n",
    "\n",
    "meganLabeledFiles_len={}\n",
    "meganLabeledFiles_path={}\n",
    "with open(\"/Users/berk/Documents/research/scratch/meganLabeledFiles_wlenV1.txt\",\"r\") as f:\n",
    "    lines=f.readlines()\n",
    "    lines=[i.strip().split(\",\") for i in lines ]\n",
    "#     meganLabeledFiles_path={i[0].split(\"/\")[-1]:i[0] for i in lines}\n",
    "    for i in lines:\n",
    "#         meganLabeledFiles_path.setdefault(i[0].split(\"/\")[-1],)\n",
    "        meganLabeledFiles_path[i[0].split(\"/\")[-1]]=(i[0])\n",
    "    lines=[(i[0].split(\"/\")[-1],i[1]) for i in lines]\n",
    "    meganLabeledFiles_len={i[0]:i[1] for i in lines}\n",
    "\n",
    "    \n",
    "missingAudioFiles=[]\n",
    "for row in reader:\n",
    "    a=meganLabeledFiles_len.get(row['File Name'],None)\n",
    "    if a:\n",
    "        pass\n",
    "#         print(a)\n",
    "        \n",
    "    else:\n",
    "#         print(row['File Name'])\n",
    "        missingAudioFiles.append(row['File Name'])\n",
    "\n",
    "    \n",
    "excellNames2code={'anth':\"0.0.0\",\n",
    " 'auto':\"0.1.0\",\n",
    " 'bio':\"1.0.0\",\n",
    " 'bird':\"1.1.0\",\n",
    " 'bug':\"1.3.0\",\n",
    " 'dgs':\"1.1.7\",\n",
    " 'flare':\"0.4.0\",\n",
    " 'fox':\"1.2.4\",\n",
    " 'geo':\"X.X.X\",\n",
    " 'grouse':\"1.1.8\",\n",
    " 'loon':'1.1.3',\n",
    " 'mam':\"1.2.0\",\n",
    " 'plane':\"0.2.0\",\n",
    " 'ptarm':'1.1.8',\n",
    " 'rain':\"X.X.X\",\n",
    " 'seab':'1.1.5',\n",
    " 'silence':\"X.X.X\",\n",
    " 'songbird':\"1.1.10\",\n",
    " 'unknown':\"X.X.X\",\n",
    " 'water':\"X.X.X\",\n",
    " 'x':\"X.X.X\"}\n",
    "\n",
    "# a\n",
    "\n",
    "    \n",
    "Anthro_Bio=[]\n",
    "category=[]\n",
    "Specific_Category=[]\n",
    "comments=[]\n",
    "SiteIDs=[]\n",
    "codes=[]\n",
    "output_files={}\n",
    "\n",
    "for row in reader:\n",
    "    SiteID=row['Site ID'].strip()\n",
    "    SiteIDs.append(SiteID)\n",
    "\n",
    "sitesDict={siteID:Counter({}) for siteID in SiteIDs}\n",
    "sitesDictFileList = {siteID:list() for siteID in SiteIDs}\n",
    "for row in reader:\n",
    "    if row['File Name'] in missingAudioFiles:\n",
    "        continue\n",
    "    \n",
    "    SiteID=row['Site ID'].strip()\n",
    "\n",
    "    row={r:row[r].strip() for r in row}\n",
    "    if row[\"Specific Category\"] in [\"Songb\",\"SongB\"]:\n",
    "        row[\"Specific Category\"]=\"Songbird\"\n",
    "    \n",
    "    if row[\"Category\"] in [\"Mamm\"]:\n",
    "        row[\"Category\"]=\"Mam\"\n",
    "    \n",
    "    \n",
    "    code=[row[\"Anthro/Bio\"],row[\"Category\"],row[\"Specific Category\"]]\n",
    "    \n",
    "    # \"0\" is reserved for \"other\" and the code \"X\" refers to unknown\n",
    "    code= [i if i!=\"\" else \"X\" for i in code ]\n",
    "#     if \"X\" in code[:2]:\n",
    "#         print(row)\n",
    "\n",
    "    \n",
    "    code = \".\".join(code)\n",
    "    if \"/\" not in code:\n",
    "        codes.append(code)\n",
    "        a=meganLabeledFiles_len.get(row['File Name'],None)\n",
    "        if a:\n",
    "            sampleCount = (float(a)//10)+1\n",
    "        else:\n",
    "            sampleCount=1\n",
    "\n",
    "        sitesDict[SiteID]=sitesDict[SiteID]+Counter({code:sampleCount})\n",
    "        sitesDictFileList[SiteID].append(meganLabeledFiles_path[row['File Name']])\n",
    "\n",
    "        code=code.split(\".\")\n",
    "        if code[2]!=\"X\":\n",
    "            yamlCode=excellNames2code[code[2].lower()]\n",
    "        elif code[1]!=\"X\":\n",
    "            yamlCode=excellNames2code[code[1].lower()]\n",
    "        elif code[0]!=\"X\":\n",
    "            yamlCode=excellNames2code[code[0].lower()]\n",
    "        else:\n",
    "            print(code)\n",
    "        outputFileName=\"_\".join([SiteID,yamlCode,\"original\"])\n",
    "        output_files.setdefault(outputFileName,[])\n",
    "        output_files[outputFileName].append(meganLabeledFiles_path[row['File Name']])\n",
    "#         print(code)\n",
    "    Anthro_Bio.append(row[\"Anthro/Bio\"].strip())\n",
    "    category.append(row[\"Category\"].strip())\n",
    "    Specific_Category.append(row[\"Specific Category\"])\n",
    "    comments.append(row[\"Comments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(output_files.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anth': '0.0.0',\n",
       " 'auto': '0.1.0',\n",
       " 'bio': '1.0.0',\n",
       " 'bird': '1.1.0',\n",
       " 'bug': '1.3.0',\n",
       " 'dgs': '1.1.7',\n",
       " 'flare': '0.4.0',\n",
       " 'fox': '1.2.4',\n",
       " 'geo': 'X.X.X',\n",
       " 'grouse': '1.1.8',\n",
       " 'loon': '1.1.3',\n",
       " 'mam': '1.2.0',\n",
       " 'plane': '0.2.0',\n",
       " 'ptarm': '1.1.8',\n",
       " 'rain': 'X.X.X',\n",
       " 'seab': '1.1.5',\n",
       " 'silence': 'X.X.X',\n",
       " 'songbird': '1.1.10',\n",
       " 'unknown': 'X.X.X',\n",
       " 'water': 'X.X.X',\n",
       " 'x': 'X.X.X'}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excellNames2code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anth',\n",
       " 'auto',\n",
       " 'bio',\n",
       " 'bird',\n",
       " 'bug',\n",
       " 'dgs',\n",
       " 'flare',\n",
       " 'fox',\n",
       " 'geo',\n",
       " 'grouse',\n",
       " 'loon',\n",
       " 'mam',\n",
       " 'plane',\n",
       " 'ptarm',\n",
       " 'rain',\n",
       " 'seab',\n",
       " 'silence',\n",
       " 'songbird',\n",
       " 'unknown',\n",
       " 'water',\n",
       " 'x'}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sitesDictFileList\n",
    "# flat_list = [item for sublist in l for item in sublist]\n",
    "# [i for i in c.split(\",\") for c in codes]\n",
    "# [c.split(\",\") for c in codes for ]\n",
    "kk=[]\n",
    "for c in codes:\n",
    "    for i in c.split(\".\"):\n",
    "        kk.append(i.lower())\n",
    "        \n",
    "set(kk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-204-9acec2725001>:4: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  taxonomy_codes = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import oyaml as yaml\n",
    "def load_taxonomy_codes(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        taxonomy_codes = yaml.load(f)\n",
    "\n",
    "    return taxonomy_codes\n",
    "a=load_taxonomy_codes(\"/Users/berk/Desktop/NNA/downloads/taxonomy.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse dict\n",
    "codesDict={c:Counter() for c in codes}\n",
    "for site,siteCounter in sitesDict.items():\n",
    "    for c in siteCounter.keys():\n",
    "        codesDict[c]=codesDict[c]+Counter({site:siteCounter[c]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bio.Bird.Grouse', Counter({'22': 1.0})),\n",
       " ('Bio.Mam.X', Counter({'12': 1.0})),\n",
       " ('Bio.Mam.Fox', Counter({'20': 3.0})),\n",
       " ('Bio.Loon.X', Counter({'38': 1.0})),\n",
       " ('Geo.Water.X', Counter({'28': 19.0}))]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k,v) for (k,v) in codesDict.items() if len(v)>3 and len(v)<5]\n",
    "[(k,v) for (k,v) in codesDict.items() if len(v)>0 and len(v)<3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bio.Bird.Grouse', Counter({'22': 1.0})),\n",
       " ('Bio.Mam.X', Counter({'12': 1.0})),\n",
       " ('Bio.Mam.Fox', Counter({'20': 3.0})),\n",
       " ('Bio.Loon.X', Counter({'38': 1.0})),\n",
       " ('Geo.Water.X', Counter({'28': 19.0}))]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k,v) for (k,v) in codesDict.items() if sum(v.values())<25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bio.Bird.Grouse', 1.0),\n",
       " ('Bio.Mam.X', 1.0),\n",
       " ('Bio.Loon.X', 1.0),\n",
       " ('Bio.Mam.Fox', 3.0),\n",
       " ('Geo.Water.X', 19.0),\n",
       " ('Unknown.X.X', 28.0),\n",
       " ('Geo.Rain.X', 39.0),\n",
       " ('Anth.Flare.X', 42.0),\n",
       " ('Bio.Bird.Loon', 60.0),\n",
       " ('Bio.Bird.SeaB', 60.0),\n",
       " ('Silence.X.X', 86.0),\n",
       " ('Bio.X.X', 108.0),\n",
       " ('Anth.X.X', 123.0),\n",
       " ('Anth.Plane.X', 142.0),\n",
       " ('Bio.Bird.Ptarm', 162.0),\n",
       " ('Anth.Auto.X', 177.0),\n",
       " ('Bio.Bug.X', 310.0),\n",
       " ('Bio.Bird.DGS', 367.0),\n",
       " ('Bio.Bird.Songbird', 1039.0),\n",
       " ('Bio.Bird.X', 1550.0)]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(k,sum(v.values())) for (k,v) in codesDict.items()],key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bio.Bird.Grouse', 1.0),\n",
       " ('Bio.Mam.X', 1.0),\n",
       " ('Bio.Loon.X', 1.0),\n",
       " ('Bio.Mam.Fox', 3.0),\n",
       " ('Geo.Water.X', 19.0),\n",
       " ('Unknown.X.X', 28.0),\n",
       " ('Geo.Rain.X', 39.0),\n",
       " ('Anth.Flare.X', 42.0),\n",
       " ('Bio.Bird.Loon', 60.0),\n",
       " ('Bio.Bird.SeaB', 60.0),\n",
       " ('Silence.X.X', 86.0),\n",
       " ('Bio.X.X', 108.0),\n",
       " ('Anth.X.X', 123.0),\n",
       " ('Anth.Plane.X', 142.0),\n",
       " ('Bio.Bird.Ptarm', 162.0),\n",
       " ('Anth.Auto.X', 177.0),\n",
       " ('Bio.Bug.X', 310.0),\n",
       " ('Bio.Bird.DGS', 367.0),\n",
       " ('Bio.Bird.Songbird', 1039.0),\n",
       " ('Bio.Bird.X', 1550.0)]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(k,sum(v.values())) for (k,v) in codesDict.items()],key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anth.Auto.X',\n",
       " 'Anth.Flare.X',\n",
       " 'Anth.Plane.X',\n",
       " 'Anth.X.X',\n",
       " 'Bio.Bird.DGS',\n",
       " 'Bio.Bird.Grouse',\n",
       " 'Bio.Bird.Loon',\n",
       " 'Bio.Bird.Ptarm',\n",
       " 'Bio.Bird.SeaB',\n",
       " 'Bio.Bird.Songbird',\n",
       " 'Bio.Bird.X',\n",
       " 'Bio.Bug.X',\n",
       " 'Bio.Loon.X',\n",
       " 'Bio.Mam.Fox',\n",
       " 'Bio.Mam.X',\n",
       " 'Bio.X.X',\n",
       " 'Geo.Rain.X',\n",
       " 'Geo.Water.X',\n",
       " 'Silence.X.X',\n",
       " 'Unknown.X.X']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(Counter(codes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This file seems way too short, probably throw it out\n",
      "Birds calling back and forth\n",
      "subtle background noise of aircraft, birds in foreground\n",
      "very distant aircraft\n",
      "Animal messing with the recorder, likely a raven (you hear it fly away at the end); songbirds in background\n",
      "birdsong with some insect noise in the beginning\n",
      "animal moving through grass, probably bird\n",
      "animal moving through grass, probably bird\n",
      "; animal moving through grass, probably bird\n",
      "; soft tweets hard to hear\n",
      "; multiple birds\n"
     ]
    }
   ],
   "source": [
    "for c in comments[:100]:\n",
    "    if c!=\"\":\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for m in zip(SiteID,category):\n",
    "#     if m[1]==\"Bug\":\n",
    "#         print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'Auto',\n",
       " 'Bird',\n",
       " 'Bird/Plane',\n",
       " 'Bug',\n",
       " 'Flare',\n",
       " 'Loon',\n",
       " 'Mam',\n",
       " 'Plane',\n",
       " 'Rain',\n",
       " 'Water']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(Counter(category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'DGS', 'Fox', 'Grouse', 'Loon', 'Ptarm', 'SeaB', 'Songbird']"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(Counter(Specific_Category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments2=Counter(comments)\n",
    "comments2=list(comments2.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "819"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments2.sort(key=lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'22': 8.0,\n",
       "         '11': 2.0,\n",
       "         '49': 33.0,\n",
       "         '48': 5.0,\n",
       "         '40': 5.0,\n",
       "         '27': 20.0,\n",
       "         '39': 1.0,\n",
       "         '46': 53.0,\n",
       "         '16': 6.0,\n",
       "         '19': 1.0,\n",
       "         '20': 3.0,\n",
       "         '15': 82.0,\n",
       "         '24': 37.0,\n",
       "         '30': 52.0,\n",
       "         '38': 30.0,\n",
       "         '25': 3.0,\n",
       "         '29': 2.0,\n",
       "         '26': 1.0,\n",
       "         '28': 1.0,\n",
       "         '42': 5.0,\n",
       "         '43': 17.0})"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codesDict['Bio.Bird.DGS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66, 22, 22])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total=110\n",
    "import numpy as np\n",
    "import math\n",
    "dist=np.array([0.6,0.2,0.2])\n",
    "np.ceil(total*dist).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.ceil(total*dist).astype(\"int\"))\n",
    "dist=np.array([0.6,0.2,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(79, 23.0, 23.0), (76, 29.0, 29.0), (72, 28.0, 28.0), (66, 36.0, 36.0), (88, 22.0, 22.0), (66, 31.0, 31.0), (82, 18.0, 18.0), (73, 38.0, 38.0), (85, 24.0, 24.0), (74, 35.0, 35.0), (77, 17, 17), (66, 27.0, 27.0), (86, 26.0, 26.0), (76, 26.0, 26.0), (82, 15, 15), (81, 15, 15), (77, 24.0, 24.0), (78, 28.0, 28.0), (75, 18, 18), (78, 24.0, 24.0), (78, 34.0, 34.0), (88, 11, 11), (69, 26.0, 26.0), (70, 30.0, 30.0), (82, 21.0, 21.0), (85, 13, 13), (76, 33.0, 33.0), (67, 36.0, 36.0), (83, 23.0, 23.0), (70, 26.0, 26.0), (84, 20.0, 20.0), (72, 36.0, 36.0), (71, 28.0, 28.0), (80, 20.0, 20.0), (77, 21.0, 21.0), (77, 31.0, 31.0), (79, 32.0, 32.0), (71, 24.0, 24.0), (81, 18.0, 18.0), (78, 31.0, 31.0), (68, 31.0, 31.0), (84, 17.0, 17.0), (71, 20, 20), (68, 36.0, 36.0), (68, 22, 22), (83, 20.0, 20.0), (79, 29.0, 29.0), (75, 22.0, 22.0), (82, 24.0, 24.0), (77, 28.0, 28.0), (70, 34.0, 34.0), (83, 17.0, 17.0), (69, 34.0, 34.0), (80, 23.0, 23.0), (84, 14, 14), (81, 30.0, 30.0), (67, 44.0, 44.0), (72, 40.0, 40.0), (74, 19, 19), (69, 30.0, 30.0), (80, 29.0, 29.0), (82, 30.0, 30.0), (67, 40.0, 40.0), (88, 16.0, 16.0), (79, 26.0, 26.0), (81, 21.0, 21.0), (75, 29.0, 29.0), (87, 15.0, 15.0), (77, 34.0, 34.0), (88, 12, 12), (71, 32.0, 32.0), (83, 28.0, 28.0), (73, 23.0, 23.0), (82, 27.0, 27.0), (68, 44.0, 44.0), (87, 20.0, 20.0), (81, 27.0, 27.0), (73, 19, 19), (68, 40.0, 40.0), (80, 26.0, 26.0), (75, 26.0, 26.0), (87, 12, 12), (87, 22.0, 22.0), (69, 38.0, 38.0), (72, 20, 20), (70, 42.0, 42.0), (87, 17.0, 17.0), (81, 24.0, 24.0), (88, 14.0, 14.0), (70, 38.0, 38.0), (88, 15.0, 15.0), (85, 16.0, 16.0), (74, 27.0, 27.0), (71, 40.0, 40.0), (86, 13, 13), (76, 36.0, 36.0), (83, 26.0, 26.0), (84, 28.0, 28.0), (80, 32.0, 32.0), (84, 23.0, 23.0), (74, 23.0, 23.0), (71, 36.0, 36.0), (86, 19.0, 19.0), (67, 22, 22), (88, 20.0, 20.0), (75, 33.0, 33.0), (87, 24.0, 24.0), (78, 21.0, 21.0), (73, 27.0, 27.0), (88, 17.0, 17.0), (78, 17, 17), (85, 19.0, 19.0), (72, 24.0, 24.0), (66, 22, 22), (86, 16.0, 16.0), (86, 21.0, 21.0), (84, 26.0, 26.0), (74, 31.0, 31.0), (69, 42.0, 42.0), (68, 27.0, 27.0), (88, 18.0, 18.0), (75, 36.0, 36.0), (79, 20.0, 20.0), (88, 24.0, 24.0), (79, 16, 16), (76, 22.0, 22.0), (73, 35.0, 35.0), (85, 26.0, 26.0), (85, 21.0, 21.0), (69, 21, 21), (76, 18, 18), (73, 31.0, 31.0), (67, 31.0, 31.0), (70, 21, 21), (74, 38.0, 38.0), (86, 24.0, 24.0), (67, 27.0, 27.0), (83, 14, 14), (66, 44.0, 44.0), (72, 32.0, 32.0), (80, 16, 16), (66, 40.0, 40.0)}\n"
     ]
    }
   ],
   "source": [
    "# [0.6,0.2,0.2]\n",
    "# [0.7,0.15,0.15]\n",
    "# [0.8,0.1,0.1]\n",
    "def getCombinations(total,dist):\n",
    "    combinations=set()\n",
    "    for i in range(100,201,1):\n",
    "        test_val_dist=i/1000\n",
    "        train_dist=1-(test_val_dist*2)\n",
    "        dist=np.array([train_dist,test_val_dist,test_val_dist])\n",
    "        bin_capacities=tuple(np.ceil(total*dist).astype(\"int\"))\n",
    "        combinations.add(bin_capacities)\n",
    "\n",
    "    #add some combinations that are test and valid are bigger so that small number of elements can be handled\n",
    "    combinations2=combinations.copy()\n",
    "    for comb in combinations2:\n",
    "        for rate in [1.2,1.4,1.6,1.8,2.0]:\n",
    "            newComb=(comb[0],np.ceil(comb[1]*rate),np.ceil(comb[1]*rate))\n",
    "            combinations.add(newComb)\n",
    "\n",
    "    return combinations\n",
    "\n",
    "print(getCombinations(total,dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy as kl_div\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def JSD(P, Q):\n",
    "    _P = P / norm(P, ord=1)\n",
    "    _Q = Q / norm(Q, ord=1)\n",
    "    _M = 0.5 * (_P + _Q)\n",
    "    return 0.5 * (kl_div(_P, _M) + kl_div(_Q, _M))\n",
    "\n",
    "def create_data_model(weights,values,bin_capacities):\n",
    "    \"\"\"Create the data for the example.\"\"\"\n",
    "    data = {}\n",
    "    data['weights'] = weights\n",
    "    data['values'] = values\n",
    "    data['items'] = list(range(len(weights)))\n",
    "    data['num_items'] = len(weights)\n",
    "    num_bins = 5\n",
    "    data['bins'] = list(range(3))\n",
    "    total=sum(weights)\n",
    "#     print(total)\n",
    "#     bin_capacities = np.ceil(total*dist).astype(\"int\")\n",
    "    data['bin_capacities'] = bin_capacities\n",
    "    \n",
    "    return data\n",
    "\n",
    "from __future__ import print_function\n",
    "from ortools.linear_solver import pywraplp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error, too small [1.0]\n",
      "Error, too small [1.0]\n",
      "Error, too small [3.0]\n",
      "Error, too small [1.0]\n",
      "Error, number of elements less than 3 [19.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# [(k,v) for (k,v) in codesDict.items() if sum(v.values())<25]\n",
    "\n",
    "def main():\n",
    "    total=0\n",
    "    solutionPerTaxonomy={}\n",
    "    for k in codesDict.keys():\n",
    "        \n",
    "        weights=list(codesDict[k].values())\n",
    "        values = list(codesDict[k].values())\n",
    "        if sum(weights)<10:\n",
    "            print(\"Error, too small\", weights)\n",
    "            continue\n",
    "        if len(weights)<3:\n",
    "            print(\"Error, number of elements less than 3\", weights)\n",
    "            continue\n",
    "        \n",
    "        total=sum(weights)\n",
    "        \n",
    "\n",
    "        combinations=getCombinations(total,dist)\n",
    "            \n",
    "#         solutionPerCombination=[]\n",
    "        solutionPerTaxonomy.setdefault(k,[])\n",
    "        for bin_capacities in combinations:\n",
    "            \n",
    "            data = create_data_model(weights,values,bin_capacities)\n",
    "            # Create the mip solver with the CBC backend.\n",
    "            solver = pywraplp.Solver.CreateSolver('multiple_knapsack_mip', 'CBC')\n",
    "\n",
    "            # Variables\n",
    "            # x[i, j] = 1 if item i is packed in bin j.\n",
    "            x = {}\n",
    "            for i in data['items']:\n",
    "                for j in data['bins']:\n",
    "                    x[(i, j)] = solver.IntVar(0, 1, 'x_%i_%i' % (i, j))\n",
    "\n",
    "            # Constraints\n",
    "            # Each item can be in at most one bin.\n",
    "            for i in data['items']:\n",
    "                solver.Add(sum(x[i, j] for j in data['bins']) <= 1)\n",
    "            # The amount packed in each bin cannot exceed its capacity.\n",
    "            for j in data['bins']:\n",
    "                solver.Add(\n",
    "                    sum(x[(i, j)] * data['weights'][i]\n",
    "                        for i in data['items']) <= data['bin_capacities'][j])\n",
    "\n",
    "            # Objective\n",
    "            objective = solver.Objective()\n",
    "\n",
    "            for i in data['items']:\n",
    "                for j in data['bins']:\n",
    "                    objective.SetCoefficient(x[(i, j)], data['values'][i])\n",
    "            objective.SetMaximization()\n",
    "\n",
    "            status = solver.Solve()\n",
    "\n",
    "            if status == pywraplp.Solver.OPTIMAL:\n",
    "#                 if objective.Value()/sum(data['bin_capacities'])>0.90:\n",
    "#                     continue\n",
    "\n",
    "                total+=sum(data['weights'])\n",
    "\n",
    "#                 print(codesDict[k])\n",
    "#                 print(\"------------\",k,\"--------------\")\n",
    "#                 print('Total packed value:', objective.Value(),\"/\",sum(data['bin_capacities']))\n",
    "\n",
    "    #             print()\n",
    "                total_weight = 0\n",
    "                solution=[list() for i in range(len(data['bins']))]\n",
    "                for binIndex,j in enumerate(data['bins']):\n",
    "                    bin_weight = 0\n",
    "                    bin_value = 0\n",
    "#                     print('Bin ', j, '\\n')\n",
    "                    for i in data['items']:\n",
    "                        if x[i, j].solution_value() > 0:\n",
    "                            solution[j].append(data['weights'][i])\n",
    "#                             print('Item', i, '- weight:', data['weights'][i], ' value:',\n",
    "#                                   data['values'][i])\n",
    "                            bin_weight += data['weights'][i]\n",
    "                            bin_value += data['values'][i]\n",
    "                            \n",
    "#                     print('Packed bin weight:', bin_weight,\"/\",data['bin_capacities'][binIndex])\n",
    "    #                 print('bin capacity:',)\n",
    "    #                 print('Packed bin value:', bin_value)\n",
    "                    total_weight += bin_weight\n",
    "#                 print('Total packed weight:', total_weight)\n",
    "                solutionPerTaxonomy[k].append((bin_capacities,solution[:]))\n",
    "            else:\n",
    "                print('The problem does not have an optimal solution.')\n",
    "#             print(\"total\",total)\n",
    "    return solutionPerTaxonomy\n",
    "\n",
    "solutionPerTaxonomy=main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "expectedDist=[0.6,0.2,0.2]\n",
    "results=[]\n",
    "BestSolutionPerTaxonomy={}\n",
    "\n",
    "for taxoKey in solutionPerTaxonomy:\n",
    "    found=False\n",
    "    total=sum(codesDict[taxoKey].values())\n",
    "    \n",
    "    for i in solutionPerTaxonomy[taxoKey]:\n",
    "        if total==sum([sum(m) for m in i[1]]):\n",
    "            found=True\n",
    "    if found is False:\n",
    "        print(codesDict[taxoKey].values())\n",
    "        print(total)\n",
    "\n",
    "#         for i in solutionPerTaxonomy[taxoKey]:\n",
    "#             print(i[0],,sum([sum(m) for m in i[1]]))\n",
    "            \n",
    "    costPerDist=[]\n",
    "    smallest=999999\n",
    "    bestComp=None\n",
    "    bestDist=None\n",
    "    for i in solutionPerTaxonomy[taxoKey]:\n",
    "#         print(dist=[sum(m) for m in i[1]])\n",
    "        dist=[sum(m) for m in i[1]]\n",
    "        cost=JSD(expectedDist,dist)\n",
    "        if cost<smallest and total-sum(dist)==0:\n",
    "            smallest=cost\n",
    "            bestComp=i[1]\n",
    "            bestDist=[sum(m) for m in i[1]]\n",
    "\n",
    "    combinedSorted=sorted(list(zip(bestDist,bestComp)),reverse=True)\n",
    "    a,b=[],[]\n",
    "    for m in combinedSorted:\n",
    "        a.append(m[0])\n",
    "        b.append(m[1])\n",
    "    bestDist,bestComp=a,b\n",
    "    \n",
    "    results.append([cost,bestDist,bestComp])\n",
    "\n",
    "    BestSolutionPerTaxonomy[taxoKey] = [cost,bestDist,bestComp]\n",
    "    \n",
    "#     if total-sum(bestDist)!=0:\n",
    "#         print(\"BAD\")\n",
    "#     print(taxoKey)\n",
    "#     print(codesDict[taxoKey].values())\n",
    "#     print(\"total\",total,sum(bestDist),bestDist)\n",
    "\n",
    "#     print(bestComp)\n",
    "# #         costPerDist.append()\n",
    "#     for i in solutionPerTaxonomy[taxoKey]:\n",
    "#         dist=[sum(m) for m in i[1]]\n",
    "#         print(dist,sum(dist))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[121.0, 50.0, 6.0],\n",
       " [24.0, 18.0, 18.0],\n",
       " [77.0, 37.0, 9.0],\n",
       " [46.0, 10.0, 4.0],\n",
       " [219.0, 74.0, 74.0],\n",
       " [51.0, 18.0, 17.0],\n",
       " [23.0, 12.0, 7.0],\n",
       " [930.0, 310.0, 310.0],\n",
       " [16.0, 6.0, 6.0],\n",
       " [64.0, 22.0, 22.0],\n",
       " [25.0, 8.0, 6.0],\n",
       " [98.0, 32.0, 32.0],\n",
       " [90.0, 27.0, 25.0],\n",
       " [623.0, 208.0, 208.0],\n",
       " [186.0, 62.0, 62.0]]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=sorted(results,reverse=True)\n",
    "[i[1] for i in results]\n",
    "# len(results),len(codesDict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "solReverse={i:{} for i in codesDict.keys()}\n",
    "for taxo, counter in codesDict.items():\n",
    "    counter=dict(counter)\n",
    "    for x,y in counter.items():\n",
    "        solReverse[taxo].setdefault(y, []).append(x)\n",
    "\n",
    "BestSolutionPerTaxonomyLocation={i:None for i in BestSolutionPerTaxonomy.keys()}\n",
    "for taxo, data in BestSolutionPerTaxonomy.items():\n",
    "#     print(taxo,data)\n",
    "    comb=data[2]\n",
    "    train,test,val=comb[:]\n",
    "    combLocation=[[] for i in range(len(comb))]\n",
    "    for i,dataSet in enumerate(comb):\n",
    "        for v in dataSet:\n",
    "            location=solReverse[taxo][v].pop()\n",
    "            combLocation[i].append(location)\n",
    "    BestSolutionPerTaxonomyLocation[taxo]=combLocation\n",
    "#     print(combLocation)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excellNames2code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test valid\n",
    "# BestSolutionPerTaxonomyLocation\n",
    "\n",
    "for taxo, data in BestSolutionPerTaxonomyLocation.items():\n",
    "\n",
    "    code=taxo.split(\".\")\n",
    "#     print(code)\n",
    "    if code[2]!=\"X\":\n",
    "        yamlCode=excellNames2code[code[2].lower()]\n",
    "    elif code[1]!=\"X\":\n",
    "        yamlCode=excellNames2code[code[1].lower()]\n",
    "    elif code[0]!=\"X\":\n",
    "        yamlCode=excellNames2code[code[0].lower()]\n",
    "    else:\n",
    "        print(code)\n",
    "#     print(yamlCode)\n",
    "    fileCode=yamlCode.replace(\".\",\"-\")\n",
    "    for dataSet in data:\n",
    "        for loc in dataSet:\n",
    "            fileName=(\"_\".join([\"site-\"+str(loc),fileCode,\"original.h5\"]))\n",
    "            pathFile=\"./resources/myDatasets/megan/\"+fileName\n",
    "#             print(pathFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# birdvox-cls-test\n",
    "# birdvox-cls-train\n",
    "# birdvox-cls-valid\n",
    "# load files with librosa, sample to \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSD([0.6,0.2,0.2],[0.8,0.1,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSD([0.6,0.2,0.2],[0.6,0.2,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soundEnv",
   "language": "python",
   "name": "soundenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
