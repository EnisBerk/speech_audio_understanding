{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "\n",
    "# module_path = os.path.abspath(os.path.join('../../src'))\n",
    "# print(module_path)\n",
    "# if module_path not in sys.path:\n",
    "#     sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nna.fileUtils import list_files,getLength,read_file_properties_v2\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "\n",
    "# where to save txt file storing length info\n",
    "data_folder=\"/home/enis/projects/nna/data/\"\n",
    "\n",
    "# path to search for audio files\n",
    "# where\n",
    "# ignore_folders=['/tank/data/nna/real/stinchcomb/']\n",
    "ignore_folders=[]\n",
    "search_path=\"/tank/data/nna/real/\"\n",
    "\n",
    "ignore_folders=[\"/tank/data/nna/real/stinchcomb/dups/\",\"/tank/data/nna/real/stinchcomb/excerpts/\"]\n",
    "# search_path=\"/tank/data/nna/real/stinchcomb/\"\n",
    "\n",
    "# if we already have a list of files we can load them \n",
    "# files_list_path=data_folder+\"stinchcomb_files_pathV1.txt\"\n",
    "files_list_path=data_folder+\"allFields_pathV4.txt\"\n",
    "\n",
    "# if we calculated audio lengths and saved them into text file, \n",
    "# we can load them\n",
    "fileswlen_path = data_folder+\"allFields_wlenV4.txt\"\n",
    "filesWError = data_folder+\"allFields_wERRORV4.txt\"\n",
    "\n",
    "# do NOT add pkl at the end\n",
    "pkl_file_name=\"allFields_dataV4\"\n",
    "\n",
    "\n",
    "# this is the current info we have so we can check if we already processed a file before\n",
    "current_pkl_file = \"/home/enis/projects/nna/data/allFields_dataV3.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find files\n",
    "# in given search path ignoring given directories\n",
    "if not Path(fileswlen_path).exists():\n",
    "    files_path_list=list_files(search_path,ignore_folders)\n",
    "else:\n",
    "    with open(files_list_path,\"r\") as f:\n",
    "        lines=f.readlines()\n",
    "        files_path_list=[line.strip() for line in lines]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tank/data/nna/real/anwr/31/2019/S4A10297_20190504_000000.flac'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_path_list[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'.flac': 112053, '.aac': 9101, '.mp3': 420, '.flac~': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# a  = Counter()\n",
    "files_suffixes=[]\n",
    "files_path_list_filtered=[]\n",
    "for m in files_path_list:\n",
    "    m=Path(m)\n",
    "    mSuffix = m.suffix.lower()\n",
    "    \n",
    "    files_suffixes.append(mSuffix)\n",
    "    if \"~\" in str(m):\n",
    "        continue\n",
    "\n",
    "#     if mSuffix!=\".flac\" and mSuffix!=\".aac\" and mSuffix!=\".mp3\":\n",
    "#         print(m)\n",
    "#         break\n",
    "    files_path_list_filtered.append((m))\n",
    "        \n",
    "print(Counter(files_suffixes))\n",
    "files_path_list = files_path_list_filtered[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previous data\n",
    "current_file_properties_df=pd.read_pickle(str(current_pkl_file))\n",
    "\n",
    "# remove files we already know about\n",
    "currentFileSet = set(current_file_properties_df.index)\n",
    "foundFileSet = set(files_path_list)\n",
    "foundFileSet = foundFileSet.difference(currentFileSet)\n",
    "New_files_path_list = list(foundFileSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('new', 76594, 'previously', 44980, 'total', 121574)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"new\",len(New_files_path_list),\"previously\",len(currentFileSet),\"total\",len(files_path_list),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or calculate Audio length\n",
    "import subprocess\n",
    "\n",
    "filesWError = []\n",
    "\n",
    "# learn length of each audio and store in a text file, \n",
    "# if file already exists, it tries to get data from there\n",
    "if not Path(fileswlen_path).exists():\n",
    "    length_dict={}\n",
    "    for f in New_files_path_list:\n",
    "#         length=float(getLength(f))\n",
    "##################\n",
    "        input_video = f\n",
    "        ffprobe_path = '/scratch/enis/conda/envs/speechEnv/bin/ffprobe'\n",
    "        cmd=[]\n",
    "        cmd.extend( [ffprobe_path, '-i', '{}'.format(input_video), '-show_entries' ,'format=duration', '-v', 'quiet' ])\n",
    "        result = subprocess.Popen(cmd, stdout=subprocess.PIPE,stderr=subprocess.PIPE,)\n",
    "        output = result.communicate(b'\\n')\n",
    "        output = [i.decode('ascii') for i in output]\n",
    "        if output[0]==\"\":\n",
    "            length = -1\n",
    "            print(\"ERROR file is too short {}\".format(input_video))\n",
    "            print(\"command run with ERROR: {}\".format(cmd))\n",
    "            filesWError.append(input_video)\n",
    "        else:\n",
    "            length = output[0].split(\"\\n\")[1].split(\"=\")[1]\n",
    "###############\n",
    "        length_dict[f]=length\n",
    "\n",
    "    length_list=list(length_dict.items())\n",
    "    with open(fileswlen_path,\"w\") as f:\n",
    "        for line in length_list:\n",
    "            f.write(\",\".join([line[0],str(line[1])])+\"\\n\")\n",
    "\n",
    "with open(fileswlen_path,\"r\") as f:\n",
    "    lines=f.readlines()\n",
    "    fileswlen=[line.strip().split(\",\") for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n"
     ]
    }
   ],
   "source": [
    "# print and save files with errors\n",
    "\n",
    "print(len(filesWError))\n",
    "with open(filesWError_path,\"w\") as f:\n",
    "    for line in length_list:\n",
    "        f.write(\",\".join([line[0],str(line[1])])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn results into a dict\n",
    "fileswlen=dict([(i[0],float(i[1])) for i in fileswlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_properties,exceptions = read_file_properties_v2(New_files_path_list,debug=0)\n",
    "for f,lengthSeconds in fileswlen.items():\n",
    "    if file_properties.get(Path(f)) is not None:\n",
    "        file_properties[Path(f)][\"durationSec\"] = lengthSeconds\n",
    "        file_properties[Path(f)][\"timestampEnd\"] = file_properties[Path(f)][\"timestamp\"] + datetime.timedelta(seconds=lengthSeconds)\n",
    "file_properties_df=pd.DataFrame(file_properties).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2timestamp(fileinfo_dict):\n",
    "    # x=file_properties[file]\n",
    "#         print(x)\n",
    "    hour_min_sec=fileinfo_dict[\"hour_min_sec\"]\n",
    "    hour=int(hour_min_sec[:2])\n",
    "    minute=int(hour_min_sec[2:4])\n",
    "    second=int(hour_min_sec[4:6])\n",
    "    year = int(fileinfo_dict[\"year\"])\n",
    "\n",
    "    timestamp=datetime.datetime(year, int(fileinfo_dict[\"month\"]), int(fileinfo_dict[\"day\"]),\n",
    "                hour=hour, minute=minute, second=second, microsecond=0)\n",
    "    fileinfo_dict[\"timestamp\"]=timestamp\n",
    "    return fileinfo_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with previous file properties\n",
    "merged_file_properties_df = pd.concat([file_properties_df,current_file_properties_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_file_properties_df.to_pickle(data_folder+pkl_file_name+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "nnaProjectDataFolder = Path(\"/home/enis/projects/nna/data/\")\n",
    "# audio files information\n",
    "file_properties_df_FilePath = nnaProjectDataFolder / \"allFields_dataV3.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_properties_df=pd.read_pickle(str(file_properties_df_FilePath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region_locId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load datasets\n",
    "pathDatasets = \"/home/enis/projects/similarSoundsApp/resources/TimeLapse_Databases/\"\n",
    "datasetList=[[m for m in i.glob(\"*\") if \".ddb\" in str(m) ][0] for i in (Path(pathDatasets).glob(\"*\"))]\n",
    "# datasetList[0].parent.stem\n",
    "labeledImgLocations = [m.parent.stem for m in datasetList]\n",
    "\n",
    "realFolderPath=\"/tank/data/nna/real/\"\n",
    "region_locId=[[m for m in i.glob(\"*\") if m.is_dir() ] for i in (Path(realFolderPath).glob(\"*\")) if i.is_dir()]\n",
    "\n",
    "allLocations=[]\n",
    "for m in region_locId:\n",
    "    for n in m:\n",
    "        if n.stem in labeledImgLocations:\n",
    "            allLocations.append(n)\n",
    "\n",
    "\n",
    "# filenamePattern=\"*\"\n",
    "# all_embeddings=[]\n",
    "# for loc in allLocations:\n",
    "#     # find all files\n",
    "#     search_path=loc\n",
    "#     all_embeddings+=list_files(str(search_path),filename=filenamePattern)\n",
    "\n",
    "# print(len(all_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeledImgLocations.sort()\n",
    "# labeledImgLocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeledImgLocations==sorted([i.stem for i in allLocations[:-9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/tank/data/nna/real/prudhoe/17'),\n",
       " PosixPath('/tank/data/nna/real/prudhoe/22'),\n",
       " PosixPath('/tank/data/nna/real/prudhoe/26'),\n",
       " PosixPath('/tank/data/nna/real/prudhoe/14'),\n",
       " PosixPath('/tank/data/nna/real/prudhoe/19'),\n",
       " PosixPath('/tank/data/nna/real/prudhoe/13'),\n",
       " PosixPath('/tank/data/nna/real/prudhoe/11'),\n",
       " PosixPath('/tank/data/nna/real/prudhoe/29'),\n",
       " PosixPath('/tank/data/nna/real/prudhoe/24'),\n",
       " PosixPath('/tank/data/nna/real/prudhoe/16'),\n",
       " PosixPath('/tank/data/nna/real/prudhoe/12'),\n",
       " PosixPath('/tank/data/nna/real/prudhoe/27'),\n",
       " PosixPath('/tank/data/nna/real/prudhoe/15'),\n",
       " PosixPath('/tank/data/nna/real/anwr/36'),\n",
       " PosixPath('/tank/data/nna/real/anwr/46'),\n",
       " PosixPath('/tank/data/nna/real/anwr/31'),\n",
       " PosixPath('/tank/data/nna/real/anwr/48'),\n",
       " PosixPath('/tank/data/nna/real/anwr/42'),\n",
       " PosixPath('/tank/data/nna/real/anwr/35'),\n",
       " PosixPath('/tank/data/nna/real/anwr/38'),\n",
       " PosixPath('/tank/data/nna/real/anwr/32'),\n",
       " PosixPath('/tank/data/nna/real/anwr/45'),\n",
       " PosixPath('/tank/data/nna/real/anwr/40'),\n",
       " PosixPath('/tank/data/nna/real/anwr/37'),\n",
       " PosixPath('/tank/data/nna/real/anwr/33'),\n",
       " PosixPath('/tank/data/nna/real/anwr/50'),\n",
       " PosixPath('/tank/data/nna/real/anwr/34')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allLocations[:-9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenamePattern=\"*.*\"\n",
    "all_embeddings=[]\n",
    "#only prudhoe and anwr\n",
    "for loc in allLocations[:-9]:\n",
    "    # find all files\n",
    "    search_path=loc\n",
    "    all_embeddings+=list_files(str(search_path),filename=filenamePattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20032"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes=[str(i) for i in file_properties_df.index]\n",
    "missing=[]\n",
    "for m in all_embeddings:\n",
    "    if m not in indexes:\n",
    "        missing.append(m)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tank/data/nna/real/prudhoe/17/2019/S4A10307_20190707_054602.flac'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechEnv",
   "language": "python",
   "name": "speechenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
