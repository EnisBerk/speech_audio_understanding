{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Collects data for file_properties_df.\n",
    "\n",
    "file_properties_df holds metadata about data in our dataset, \n",
    "details of metadata can be seen at src/nna/tests/mock_data.py::mock_file_properties_df\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nna.fileUtils import list_files,getLength,read_file_properties_v2\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "\n",
    "# where to save txt file storing length info\n",
    "data_folder=\"/home/enis/projects/nna/data/\"\n",
    "\n",
    "# path to search for audio files\n",
    "# where\n",
    "# ignore_folders=['/tank/data/nna/real/stinchcomb/']\n",
    "ignore_folders=[]\n",
    "search_path=\"/tank/data/nna/real/\"\n",
    "\n",
    "ignore_folders=[\"/tank/data/nna/real/stinchcomb/dups/\",\"/tank/data/nna/real/stinchcomb/excerpts/\"]\n",
    "# search_path=\"/tank/data/nna/real/stinchcomb/\"\n",
    "\n",
    "# if we already have a list of files we can load them \n",
    "# files_list_path=data_folder+\"stinchcomb_files_pathV1.txt\"\n",
    "files_list_path=data_folder+\"allFields_pathV4.txt\"\n",
    "\n",
    "# if we calculated audio lengths and saved them into text file, \n",
    "# we can load them\n",
    "fileswlen_path = data_folder+\"allFields_wlenV4.txt\"\n",
    "filesWError = data_folder+\"allFields_wERRORV4.txt\"\n",
    "\n",
    "# do NOT add pkl at the end\n",
    "pkl_file_name=\"allFields_dataV4\"\n",
    "\n",
    "\n",
    "# this is the current info we have so we can check if we already processed a file before\n",
    "current_pkl_file = \"/home/enis/projects/nna/data/allFields_dataV3.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find files\n",
    "# in given search path ignoring given directories\n",
    "if not Path(fileswlen_path).exists():\n",
    "    files_path_list=list_files(search_path,ignore_folders)\n",
    "else:\n",
    "    with open(files_list_path,\"r\") as f:\n",
    "        lines=f.readlines()\n",
    "        files_path_list=[line.strip() for line in lines]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tank/data/nna/real/anwr/31/2019/S4A10297_20190504_000000.flac'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_path_list[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'.flac': 112053, '.aac': 9101, '.mp3': 420, '.flac~': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# a  = Counter()\n",
    "files_suffixes=[]\n",
    "files_path_list_filtered=[]\n",
    "for m in files_path_list:\n",
    "    m=Path(m)\n",
    "    mSuffix = m.suffix.lower()\n",
    "    \n",
    "    files_suffixes.append(mSuffix)\n",
    "    if \"~\" in str(m):\n",
    "        continue\n",
    "\n",
    "#     if mSuffix!=\".flac\" and mSuffix!=\".aac\" and mSuffix!=\".mp3\":\n",
    "#         print(m)\n",
    "#         break\n",
    "    files_path_list_filtered.append((m))\n",
    "        \n",
    "print(Counter(files_suffixes))\n",
    "files_path_list = files_path_list_filtered[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previous data\n",
    "current_file_properties_df=pd.read_pickle(str(current_pkl_file))\n",
    "\n",
    "# remove files we already know about\n",
    "currentFileSet = set(current_file_properties_df.index)\n",
    "foundFileSet = set(files_path_list)\n",
    "foundFileSet = foundFileSet.difference(currentFileSet)\n",
    "New_files_path_list = list(foundFileSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('new', 76594, 'previously', 44980, 'total', 121574)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"new\",len(New_files_path_list),\"previously\",len(currentFileSet),\"total\",len(files_path_list),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/tank/data/nna/real/dempster/13/2019/S4A10324_20190330_100431.flac')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or calculate Audio length\n",
    "import subprocess\n",
    "\n",
    "filesWError = []\n",
    "\n",
    "# learn length of each audio and store in a text file, \n",
    "# if file already exists, it tries to get data from there\n",
    "if not Path(fileswlen_path).exists():\n",
    "    length_dict={}\n",
    "    for f in New_files_path_list:\n",
    "#         length=float(getLength(f))\n",
    "##################\n",
    "        input_video = f\n",
    "        ffprobe_path = '/scratch/enis/conda/envs/speechEnv/bin/ffprobe'\n",
    "        cmd=[]\n",
    "        cmd.extend( [ffprobe_path, '-i', '{}'.format(input_video), '-show_entries' ,'format=duration', '-v', 'quiet' ])\n",
    "        result = subprocess.Popen(cmd, stdout=subprocess.PIPE,stderr=subprocess.PIPE,)\n",
    "        output = result.communicate(b'\\n')\n",
    "        output = [i.decode('ascii') for i in output]\n",
    "        if output[0]==\"\":\n",
    "            length = -1\n",
    "            print(\"ERROR file is too short {}\".format(input_video))\n",
    "            print(\"command run with ERROR: {}\".format(cmd))\n",
    "            filesWError.append(input_video)\n",
    "        else:\n",
    "            length = output[0].split(\"\\n\")[1].split(\"=\")[1]\n",
    "###############\n",
    "        length_dict[f]=length\n",
    "\n",
    "    length_list=list(length_dict.items())\n",
    "    with open(fileswlen_path,\"w\") as f:\n",
    "        for line in length_list:\n",
    "            f.write(\",\".join([line[0],str(line[1])])+\"\\n\")\n",
    "\n",
    "with open(fileswlen_path,\"r\") as f:\n",
    "    lines=f.readlines()\n",
    "    fileswlen=[line.strip().split(\",\") for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n"
     ]
    }
   ],
   "source": [
    "# print and save files with errors\n",
    "\n",
    "print(len(filesWError))\n",
    "with open(filesWError_path,\"w\") as f:\n",
    "    for line in length_list:\n",
    "        f.write(\",\".join([line[0],str(line[1])])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn results into a dict\n",
    "fileswlen=dict([(i[0],float(i[1])) for i in fileswlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_properties,exceptions = read_file_properties_v2(New_files_path_list,debug=0)\n",
    "for f,lengthSeconds in fileswlen.items():\n",
    "    if file_properties.get(Path(f)) is not None:\n",
    "        file_properties[Path(f)][\"durationSec\"] = lengthSeconds\n",
    "        file_properties[Path(f)][\"timestampEnd\"] = file_properties[Path(f)][\"timestamp\"] + datetime.timedelta(seconds=lengthSeconds)\n",
    "file_properties_df=pd.DataFrame(file_properties).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2timestamp(fileinfo_dict):\n",
    "    # x=file_properties[file]\n",
    "#         print(x)\n",
    "    hour_min_sec=fileinfo_dict[\"hour_min_sec\"]\n",
    "    hour=int(hour_min_sec[:2])\n",
    "    minute=int(hour_min_sec[2:4])\n",
    "    second=int(hour_min_sec[4:6])\n",
    "    year = int(fileinfo_dict[\"year\"])\n",
    "\n",
    "    timestamp=datetime.datetime(year, int(fileinfo_dict[\"month\"]), int(fileinfo_dict[\"day\"]),\n",
    "                hour=hour, minute=minute, second=second, microsecond=0)\n",
    "    fileinfo_dict[\"timestamp\"]=timestamp\n",
    "    return fileinfo_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with previous file properties\n",
    "merged_file_properties_df = pd.concat([file_properties_df,current_file_properties_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_file_properties_df.to_pickle(data_folder+pkl_file_name+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep only prudhoe and anwr filter others\n",
    "##### since they are only ones with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_properties_df = pd.read_pickle(str(file_properties_df_FilePath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121541"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_file_properties_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2(df, key, value):\n",
    "    return df[df[key] == value]\n",
    "pd.DataFrame.mask2 = mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "prudhoe = merged_file_properties_df.mask2(\"region\",'prudhoe')\n",
    "anwr = merged_file_properties_df.mask2(\"region\",'anwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15778"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prudhoe),len(anwr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prudhoeAndAnwr4photoExp = pd.concat([prudhoe,anwr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30466"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prudhoeAndAnwr4photoExp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "prudhoeAndAnwr4photoExp.to_pickle(data_folder+\"prudhoeAndAnwr4photoExp_dataV1\"+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/enis/projects/nna/data/prudhoeAndAnwr4photoExp_dataV1.pkl'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_folder+\"prudhoeAndAnwr4photoExp_dataV1\"+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechEnv",
   "language": "python",
   "name": "speechenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
