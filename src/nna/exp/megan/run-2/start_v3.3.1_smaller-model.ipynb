{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make model smaller, \n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir('/home/enis/projects/nna/src/nna/exp/megan/run-2/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "# import run\n",
    "# import nna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchaudio\n",
    "torchaudio.set_audio_backend(\"sox_io\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_per_set = [['45',\n",
    "  '38',\n",
    "  '48',\n",
    "  '39',\n",
    "  '11',\n",
    "  '44',\n",
    "  '46',\n",
    "  '17',\n",
    "  '20',\n",
    "  '50',\n",
    "  '13',\n",
    "  '25',\n",
    "  '21',\n",
    "  '29',\n",
    "  '19',\n",
    "  '16',\n",
    "  '24',\n",
    "  '37'],\n",
    " ['18', '31', '34', '27', '32', '33', '47', '41', '22', '15'],\n",
    " ['30', '12', '14', '36', '40', '49']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import runconfigs\n",
    "import wandb\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.contrib.metrics import ROC_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nna.exp import augmentations,\n",
    "from nna.exp import modelArchs,runutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(config=runconfigs.default_config, project=runconfigs.PROJECT_NAME)\n",
    "# config = wandb.config\n",
    "config = runconfigs.default_config\n",
    "# wandb.config.update(args) # adds all of the arguments as config variables\n",
    "config['batch_size'] = 64\n",
    "params = {\n",
    "    'batch_size': config['batch_size'],\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    f\"cuda:{config['device']}\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# labelsbyhumanpath = Path('/scratch/enis/data/nna/labeling/results/')\n",
    "# sourcePath = Path(\"/scratch/enis/data/nna/labeling/splits/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY_COUNT = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_logs\t\t\t   start_v3.2.2_smaller-model.ipynb\n",
      "__pycache__\t\t\t   start_v3.2_smaller-model.ipynb\n",
      "runconfigs.py\t\t\t   start_v3.3.1_smaller-model.ipynb\n",
      "run.py\t\t\t\t   start_v3.3_smaller-model.ipynb\n",
      "start_v3.1_negative-samples.ipynb  start_v3_split-loc.ipynb\n",
      "start_v3.2.1_smaller-model.ipynb   wandb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite/meganLabeledFiles_wlenV1.txt\n",
      "/scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite\n",
      "4 files are missing corresponding to excell entries\n",
      "'-> 5 number of samples are DELETED due to ignore_files and missing_audio_files'\n",
      "-> 415 samples DELETED because they are not in the excell\n",
      "\n",
      "-> 0 samples DELETED because they do not have the taxo info coming from excell\n",
      "\n",
      "-> classes that do not have enough data:\n",
      "[REMOVED!]\n",
      "['other-mammal'] 0.0\n",
      "['other-silence'] 20.0\n",
      "['unknown-sound'] 2.0\n",
      "['seabirds'] 1.0\n",
      "['canids'] 1.0\n",
      "['other-flare'] 11.0\n",
      "['other-rain'] 20.0\n",
      "\n",
      "-> classes that have enough data:\n",
      "['other-biophony'] 56.0\n",
      "['other-insect'] 140.0\n",
      "['other-bird'] 661.0\n",
      "['songbirds'] 392.0\n",
      "['duck-goose-swan'] 183.0\n",
      "['grouse-ptarmigan'] 59.0\n",
      "['other-anthrophony'] 66.0\n",
      "['other-aircraft'] 107.0\n",
      "['loons'] 29.0\n",
      "['other-car'] 37.0\n",
      "('-> 102 number of samples are deleted because their taxonomy category does '\n",
      " 'not have enough data.')\n",
      "-> classes that do not have enough data\n",
      "will be REMOVED!\n",
      "-> 97 number of samples are deleted because their length is not long enough.\n",
      "loading from cache at /scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite/files_as_np_filtered_v3_int16.pkl\n"
     ]
    }
   ],
   "source": [
    "## Load real data rather than mock \n",
    "    # MVP1: delete parts longer than 10 seconds\n",
    "import run\n",
    "audio_dataset,_ = run.prepare_dataset()\n",
    "\n",
    "output_file_path = '/scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite/files_as_np_filtered_v3_int16.pkl'\n",
    "audio_dataset.load_audio_files(output_file_path)\n",
    "audio_dataset.pick_channel_by_clipping()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_samples(sound_ins,excerpt_len):\n",
    "    excerpt_sample_size = excerpt_len * sound_ins.sr\n",
    "\n",
    "    data_len_sec = sound_ins.length\n",
    "    if data_len_sec<10:\n",
    "        tile_reps = (excerpt_len / (sound_ins.length) + 1)\n",
    "        repeated_data = np.tile(sound_ins.data, int(tile_reps))\n",
    "        repeated_data = repeated_data[:excerpt_len * sound_ins.sr]\n",
    "        sound_ins.samples = [repeated_data]\n",
    "        \n",
    "    elif data_len_sec==10:\n",
    "        sound_ins.samples = [sound_ins.data]\n",
    "    else:\n",
    "        excerpt_count = data_len_sec//10\n",
    "        data_trim_point = excerpt_count*excerpt_len*sound_ins.sr\n",
    "        samples = sound_ins.data[:int(data_trim_point)].reshape(-1,int(excerpt_sample_size))\n",
    "        sample_list = []\n",
    "        for sample in samples:\n",
    "            sample_list.append(sample)\n",
    "        \n",
    "        sound_ins.samples = sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_taxo = ['1.1.10', '1.1.7']\n",
    "other_taxo = ['1.0.0', '2.1.0', '1.3.0', '1.1.8']\n",
    "# expected_len = 10\n",
    "excerpt_len = 10\n",
    "audio_lengths= []\n",
    "for sound_ins in audio_dataset.values():\n",
    "#     data_to_samples(sound_ins,excerpt_len)\n",
    "#     if len(sound_ins.samples)==1:\n",
    "#         print(len(sound_ins.samples[0]))\n",
    "    audio_lengths.append(sound_ins.length)\n",
    "\n",
    "\n",
    "# print(c,data_excerpt_count,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(audio_lengths,'o')\n",
    "# plt.ylabel('some numbers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.193625"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(audio_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/enis/projects/nna/src/nna/exp/megan/run-2\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# np.random.seed(42)\n",
    "# x = np.random.normal(size=1000)\n",
    "fig=plt.figure(figsize=(20,10))\n",
    "# (n, bins, patches) =plt.hist(audio_lengths[audio_lengths<=20], density=False, bins=20,histtype='step')  # density=False would make counts\n",
    "counts,bins=np.histogram(audio_lengths, bins=range(0,30))\n",
    "\n",
    "bb=plt.hist(bins[:-1], bins, weights=counts,density=False)\n",
    "\n",
    "plt.xticks(bins);\n",
    "plt.ylabel('Counts')\n",
    "plt.xlabel('Seconds');\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.margins(x=0)\n",
    "plt.subplots_adjust(top=0.90)\n",
    "fig.savefig('asd.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_lengths=np.array(audio_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.193625"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(audio_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09927089175546831"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_lengths[audio_lengths>30].size/audio_lengths.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1783"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_lengths.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1783"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.]\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "for i in np.ones((2,3)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1045414"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sound_ins.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=0\n",
    "for m in audio_lengths:\n",
    "    if m>10 and m//10>5:\n",
    "        c+=1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sound_ins=next(iter(audio_dataset.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sound_ins[1].location_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sound_ins[1].taxo_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(832, 832)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sound_ins[1].taxo_code\n",
    "# classA = 1.1.7 #'duck-goose-swan']\n",
    "# classB = 0.2.0 # other-aircraft\n",
    "# 3.0.0 : 0.48, 0.26, 0.26, 46 # silence\n",
    "# 2.1.0 : 0.22, 0.56, 0.22, 18 # rain\n",
    "# 1.3.0 1.3.0 : 0.52, 0.4, 0.087, 161 # insect\n",
    "# 1.1.8 : 0.49, 0.19, 0.32, 88 # grouse-ptarmigan\n",
    "\n",
    "other_taxo = ['3.0.0','2.1.0','1.3.0','1.1.8']\n",
    "\n",
    "sampleTest= []\n",
    "y=[]\n",
    "location_id_info = []\n",
    "expected_len=10\n",
    "for sound_ins in audio_dataset.values():\n",
    "    if sound_ins.taxo_code in ['1.1.10','1.1.7'] + other_taxo:\n",
    "        y.append(sound_ins.taxo_code)\n",
    "        location_id_info.append(sound_ins.location_id)\n",
    "        if sound_ins.length<10:\n",
    "            tile_reps = (expected_len/(sound_ins.length)+1)\n",
    "            repeated_data = np.tile(sound_ins.data,int(tile_reps))\n",
    "            repeated_data = repeated_data[:expected_len*sound_ins.sr]\n",
    "            sampleTest.append(repeated_data)\n",
    "        else:\n",
    "            sampleTest.append(sound_ins.data[:expected_len*sound_ins.sr])\n",
    "\n",
    "len(sampleTest),len(y)\n",
    "\n",
    "# sampleTest=np.array(sampleTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(902, 0.5314091680814941)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "313+589,(46+18+161+88)/589 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "# define input string\n",
    "# define universe of possible input values\n",
    "alphabet = ['1.1.10','1.1.7']\n",
    "# define a mapping of chars to integers\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "# integer encode input data\n",
    "integer_encoded = [char_to_int.get(char,None) for char in y]\n",
    "# print(integer_encoded)\n",
    "# one hot encode\n",
    "onehot_encoded = list()\n",
    "for value in integer_encoded:\n",
    "\tletter = [0 for _ in range(len(alphabet))]\n",
    "\tif value is not None:\n",
    "\t\tletter[value] = 1\n",
    "\tonehot_encoded.append(letter)\n",
    "# print(onehot_encoded)\n",
    "# invert encoding\n",
    "inverted = int_to_char[argmax(onehot_encoded[0])]\n",
    "# print(inverted)\n",
    "onehot_encoded=np.array(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, X_val, y_train, y_test,y_val  = [],[],[],[],[],[]\n",
    "loc_id_train=[]\n",
    "loc_id_test=[]\n",
    "loc_id_valid=[]\n",
    "\n",
    "for sample,y_val_ins,loc_id in  zip(sampleTest,onehot_encoded,location_id_info):\n",
    "    if loc_id in loc_per_set[0]:\n",
    "        X_train.append(sample)\n",
    "        y_train.append(y_val_ins)\n",
    "        loc_id_train.append(loc_id)\n",
    "    elif loc_id in loc_per_set[1]:\n",
    "        X_test.append(sample)\n",
    "        y_test.append(y_val_ins)\n",
    "        loc_id_test.append(loc_id)\n",
    "    elif loc_id in loc_per_set[2]:\n",
    "        X_val.append(sample)\n",
    "        y_val.append(y_val_ins)\n",
    "        loc_id_valid.append(loc_id)\n",
    "    else:\n",
    "        print('error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'11',\n",
       "  '16',\n",
       "  '17',\n",
       "  '19',\n",
       "  '20',\n",
       "  '21',\n",
       "  '24',\n",
       "  '25',\n",
       "  '29',\n",
       "  '37',\n",
       "  '38',\n",
       "  '39',\n",
       "  '44',\n",
       "  '46',\n",
       "  '48',\n",
       "  '50'},\n",
       " {'15', '18', '22', '27', '31', '32', '33', '41', '47'},\n",
       " {'14', '30', '40', '49'})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(loc_id_train),set(loc_id_test),set(loc_id_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "832"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sampleTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,X_val=np.array(X_train),np.array(X_test),np.array(X_val)\n",
    "y_train,y_test,y_val=np.array(y_train),np.array(y_test),np.array(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#                 sampleTest, onehot_encoded, test_size=0.2, random_state=42)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#                 X_train, y_train, test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,X_val=torch.from_numpy(X_train).float(),torch.from_numpy(X_test).float(),torch.from_numpy(X_val).float()\n",
    "y_train,y_test,y_val=torch.from_numpy(y_train).float(),torch.from_numpy(y_test).float(),torch.from_numpy(y_val).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([459, 480000]),\n",
       " torch.Size([216, 480000]),\n",
       " torch.Size([157, 480000]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([459, 2]), torch.Size([216, 2]), torch.Size([157, 2]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,y_test.shape,y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_val[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train,X_test,X_val,y_train,y_test,y_val = load_raw_data('labelsbyhumanpath','sourcePath')\n",
    "# X_train,X_test,X_val,y_train,y_test,y_val = mock_raw_data(4,CATEGORY_COUNT)\n",
    "# X_train,X_test,X_val=torch.from_numpy(X_train).float(),torch.from_numpy(X_test).float(),torch.from_numpy(X_val).float()\n",
    "# y_train,y_test,y_val=torch.from_numpy(y_train).float(),torch.from_numpy(y_test).float(),torch.from_numpy(y_val).float()\n",
    "\n",
    "# # labelsbyhumanpath = Path('/scratch/enis/data/nna/labeling/results/')\n",
    "# # with open(labelsbyhumanpath/\"np_array_Ymatrix.npy\", 'rb') as f:\n",
    "# #     y_true = np.load(f)\n",
    "\n",
    "# Counter(np.argmax(y_train,axis=1).tolist()),Counter(np.argmax(y_val,axis=1).tolist()),Counter(np.argmax(y_test,axis=1).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train2=np.interp(X_train, (X_train.min(), X_train.max()), (-32768 , 32767))\n",
    "# torch.from_numpy(X_train2).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaple_index=10\n",
    "# X_train[smaple_index,:],y_train[smaple_index,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply(torch.ones((1,2)),torch.ones((1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __init__(self, maxMelLen, sampling_rate):\n",
    "        # sr = 44100 etc\n",
    "        self.maxMelLen = maxMelLen\n",
    "        self.sampling_rate = sampling_rate\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        x, y = sample\n",
    "        #https://github.com/PCerles/audio/blob/3803d0b27a4e13efa760227ef6c71d0f3753aa98/test/test_transforms.py#L262\n",
    "        #librosa defaults\n",
    "        n_fft = 2048\n",
    "        hop_length = 512\n",
    "        power = 2.0\n",
    "        n_mels = 128\n",
    "        n_mfcc = 40\n",
    "        # htk is false in librosa, no setting in torchaudio -?\n",
    "        # norm is 1 in librosa, no setting in torchaudio -?\n",
    "        melspect_transform = torchaudio.transforms.MelSpectrogram(sample_rate=self.sampling_rate, window_fn=torch.hann_window,\n",
    "                                                                  hop_length=hop_length, n_mels=n_mels, n_fft=n_fft)\n",
    "\n",
    "    \n",
    "        db_transform = torchaudio.transforms.AmplitudeToDB(\"power\", 80.)\n",
    "        mel = melspect_transform(x.reshape(-1))\n",
    "        an_x = db_transform(mel)\n",
    "        #librosa version\n",
    "#         mel = librosa.feature.melspectrogram(y=x.reshape(-1),\n",
    "#                                              sr=self.sampling_rate)\n",
    "#         an_x = librosa.power_to_db(mel, ref=np.max)\n",
    "#         an_x = an_x.astype(\"float32\")\n",
    "#         y = y.astype('float32')\n",
    "#         print(an_x.shape)\n",
    "        an_x = an_x[:, :self.maxMelLen]\n",
    "        # 2-d conv\n",
    "#         x = an_x.reshape(1, *an_x.shape[:])\n",
    "        # 1-d conv\n",
    "        x = an_x.reshape(1, an_x.shape[0]*an_x.shape[1])\n",
    "\n",
    "        \n",
    "        return x,y\n",
    "\n",
    "# #test\n",
    "# maxMelLen_test = 850\n",
    "# SAMPLING_RATE_test = 48000\n",
    "# sample_len_seconds = 10\n",
    "# # to_tensor works on single sample\n",
    "# sample_count = 1\n",
    "# xx_test = torch.ones((sample_count,SAMPLING_RATE_test*sample_len_seconds))\n",
    "# y_values = torch.ones(sample_count)\n",
    "# \n",
    "# toTensor = ToTensor(maxMelLen_test,SAMPLING_RATE_test)\n",
    "# x_out,y_out=toTensor((xx_test,y_values))\n",
    "# x_out.shape,y_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([459, 480000])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train,X_test,X_val,y_train,y_test,y_val\n",
    "X_train[:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toTensor = ToTensor(maxMelLen_test,SAMPLING_RATE_test)\n",
    "# x_out2,y_out=toTensor((X_train[1:2,:],y_train))\n",
    "# x_out.shape,y_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.mean(x_out[0]),torch.mean(x_out2[0])\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pitch = augmentations.pitch_shift_n_stepsClass(\n",
    "#     runconfigs.SAMPLING_RATE, config['pitch_shift_n_steps'])\n",
    "# noise = augmentations.addNoiseClass(config['noise_factor'])\n",
    "# strech = augmentations.time_stretchClass(runconfigs.SAMPLING_RATE*runconfigs.EXCERPT_LENGTH,\n",
    "#                                             config['time_stretch_factor'],\n",
    "#                                             isRandom=True)\n",
    "# shift = augmentations.shiftClass(config['roll_rate'], isRandom=True)\n",
    "maxMelLen = 938 # old 850\n",
    "# toTensor = augmentations.ToTensor(maxMelLen,runconfigs.SAMPLING_RATE)\n",
    "toTensor = ToTensor(maxMelLen,runconfigs.SAMPLING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.metrics import EpochMetric\n",
    "\n",
    "\n",
    "def roc_auc_perClass_compute_fn(y_preds, y_targets):\n",
    "    try:\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "    except ImportError:\n",
    "        raise RuntimeError(\n",
    "            \"This contrib module requires sklearn to be installed.\")\n",
    "\n",
    "    y_true = y_targets.numpy()\n",
    "    y_pred = y_preds.numpy()\n",
    "#     print(y_pred,y_true)\n",
    "#     res = []\n",
    "#     for y_true_perClass_Index in y_true.shape[1]:\n",
    "#         res.append(\n",
    "#             roc_auc_score(y_true[:, y_true_perClass_Index],\n",
    "#                           y_pred[:, y_true_perClass_Index]))\n",
    "    res = roc_auc_score(y_true, y_pred, average=None)\n",
    "    return res\n",
    "\n",
    "\n",
    "#[docs]\n",
    "class ROC_AUC_perClass(EpochMetric):\n",
    "    \"\"\"Computes Area Under the Receiver Operating Characteristic Curve (ROC AUC)\n",
    "  accumulating predictions and the ground-truth during an epoch and applying\n",
    "  `sklearn.metrics.roc_auc_score <http://scikit-learn.org/stable/modules/generated/\n",
    "  sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score>`_ .\n",
    "\n",
    "  Args:\n",
    "      output_transform (callable, optional): a callable that is used to transform the\n",
    "          :class:`~ignite.engine.engine.Engine`'s ``process_function``'s output into the\n",
    "          form expected by the metric. This can be useful if, for example, you have a multi-output model and\n",
    "          you want to compute the metric with respect to one of the outputs.\n",
    "      check_compute_fn (bool): Optional default False. If True, `roc_curve\n",
    "          <http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#\n",
    "          sklearn.metrics.roc_auc_score>`_ is run on the first batch of data to ensure there are\n",
    "          no issues. User will be warned in case there are any issues computing the function.\n",
    "\n",
    "  ROC_AUC expects y to be comprised of 0's and 1's. y_pred must either be probability estimates or confidence\n",
    "  values. To apply an activation to y_pred, use output_transform as shown below:\n",
    "\n",
    "  .. code-block:: python\n",
    "\n",
    "      def activated_output_transform(output):\n",
    "          y_pred, y = output\n",
    "          y_pred = torch.sigmoid(y_pred)\n",
    "          return y_pred, y\n",
    "\n",
    "      roc_auc = ROC_AUC(activated_output_transform)\n",
    "\n",
    "  \"\"\"\n",
    "    def __init__(self,\n",
    "                 output_transform=lambda x: x,\n",
    "                 check_compute_fn: bool = False):\n",
    "#         print(output_transform)\n",
    "        super(ROC_AUC_perClass,\n",
    "              self).__init__(roc_auc_perClass_compute_fn,\n",
    "                             output_transform=output_transform,\n",
    "                             check_compute_fn=check_compute_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_output_shape(h_w, kernel_size=1, stride=1, pad=0, dilation=1):\n",
    "    \"\"\"\n",
    "  Utility function for computing output of convolutions\n",
    "  takes a tuple of (h,w) and returns a tuple of (h,w)\n",
    "  \"\"\"\n",
    "    from math import floor\n",
    "    if type(kernel_size) is not tuple:\n",
    "        kernel_size = (kernel_size, kernel_size)\n",
    "    h = floor(((h_w[0] + (2 * pad) - (dilation *\n",
    "                                      (kernel_size[0] - 1)) - 1) / stride) + 1)\n",
    "    w = floor(((h_w[1] + (2 * pad) - (dilation *\n",
    "                                      (kernel_size[1] - 1)) - 1) / stride) + 1)\n",
    "    return h, w\n",
    "\n",
    "# mel.shape,an_x.shape,X_train.shape\n",
    "class testModel(nn.Module):\n",
    "    '''A simple model for testing by overfitting.\n",
    "    '''\n",
    "    def __init__(self, out_channels, h_w, kernel_size, FLAT=False,output_shape=(10,)):\n",
    "        # h_w: height will be always one since we use 1d convolution \n",
    "        super(testModel, self).__init__()\n",
    "        self.out_channels = out_channels\n",
    "        #### CONV\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, # depth of image == depth of filters\n",
    "                               out_channels=self.out_channels, # number of filters \n",
    "                               kernel_size=kernel_size, # size of the filters/kernels\n",
    "                               padding=1)\n",
    "\n",
    "        self.conv1_shape = conv_output_shape(h_w, kernel_size=kernel_size, stride=1, pad=1, dilation=1)\n",
    "        # conv is 1d\n",
    "        self.conv1_shape = (1,self.conv1_shape[1])\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.out_channels * self.conv1_shape[0] *self.conv1_shape[1], 64)  # 100\n",
    "\n",
    "        self.fc2 = nn.Linear(64,output_shape[0])\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         x = x.reshape(1,)\n",
    "#         print(x.shape) #  50,1,108800 (850*128)\n",
    "        x = F.relu(self.conv1(x))\n",
    "#         x = self.pool(x)\n",
    "        # x = self.drop(x)\n",
    "#         print(x.shape)# 58, 2, 108801\n",
    "#         print(self.conv1_shape)\n",
    "#         print(x.shape)\n",
    "        x = x.view(-1, self.out_channels * self.conv1_shape[0] *self.conv1_shape[1])\n",
    "        # batch_norm is missing\n",
    "        x = F.relu((self.fc1(x)))\n",
    "        x = (self.fc2(x))\n",
    "\n",
    "#         x = self.drop(x)\n",
    "\n",
    "#         x = self.fc4(x)\n",
    "#         x = torch.sigmoid(x)\n",
    "#                 x = F.log_softmax(x,dim=1)\n",
    "        return x\n",
    "\n",
    "# test\n",
    "# input_shape=(1,(938*128))\n",
    "# output_shape=(10,)\n",
    "# testModel_ins=adam(out_channels=2,h_w=input_shape,kernel_size=2,output_shape=output_shape)\n",
    "# # a.conv1.weight\n",
    "# a_out=testModel_ins(torch.ones((3,1,input_shape[1])))\n",
    "\n",
    "# a_out_correct=torch.zeros(a_out.shape)\n",
    "# a_out_correct[0][:]=1\n",
    "# a_out_correct\n",
    "# a_out.detach().numpy()\n",
    "\n",
    "# torch.exp(a_out),a_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for y_true_perClass_Index in a_out_correct.shape[1]:\n",
    "#     print(y_true_perClass_Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ignite.contrib.metrics import ROC_AUC\n",
    "# from nna.exp.metrics import ROC_AUC_perClass\n",
    "def activated_output_transform(output):\n",
    "    y_pred, y = output\n",
    "#     y_pred = torch.exp(y_pred)\n",
    "    return y_pred, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asd=ROC_AUC_perClass(activated_output_transform)\n",
    "# asd.update((a_out,a_out_correct))\n",
    "# asd.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformCompose = transforms.Compose([\n",
    "#     pitch,\n",
    "#     strech,\n",
    "#     shift,\n",
    "#     noise,\n",
    "    toTensor,\n",
    "])\n",
    "\n",
    "\n",
    "sound_datasets = {\n",
    "    phase: runutils.audioDataset(XY[0], XY[1], transform=transformCompose)\n",
    "    for phase, XY in\n",
    "    zip(['train', 'val', 'test'],\n",
    "        [[X_train, y_train], [X_val, y_val], [X_test, y_test]])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(sound_datasets[x], **params)\n",
    "    for x in ['train', 'val', 'test']\n",
    "}\n",
    "\n",
    "# this will change\n",
    "h_w = [128, 938]\n",
    "kernel_size = (3, 3)\n",
    "# if config['CNNLayer_count'] == 1:\n",
    "#     model = modelArchs.NetCNN1(config['CNN_filters_1'], h_w,\n",
    "#                                 kernel_size).float().to(device)\n",
    "\n",
    "# if config['CNNLayer_count'] == 2:\n",
    "#     model = modelArchs.NetCNN2(config['CNN_filters_1'], config.CNN_filters_2,\n",
    "#                                 h_w, kernel_size,\n",
    "#                                 kernel_size).float().to(device)\n",
    "\n",
    "#simpler model\n",
    "\n",
    "output_shape=(CATEGORY_COUNT,)\n",
    "model = testModel(out_channels=2,h_w=(1,h_w[0]*h_w[1]),kernel_size=kernel_size[0]*kernel_size[0],output_shape=output_shape)\n",
    "model.float().to(device)\n",
    "\n",
    "# device is defined before\n",
    "\n",
    "model.float().to(device)  # Move model before creating optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "#                                 weight_decay=config['weight_decay'],\n",
    "                             )\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# statHistory={'valLoss':[],'trainLoss':[],'trainAUC':[],'valAUC':[]}\n",
    "\n",
    "metrics = {\n",
    "    'loss': Loss(criterion),  # 'accuracy': Accuracy(),\n",
    "#     'ROC_AUC': ROC_AUC(runutils.activated_output_transform),\n",
    "    'ROC_AUC': ROC_AUC_perClass(activated_output_transform),\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "testModel(\n",
       "  (conv1): Conv1d(1, 2, kernel_size=(9,), stride=(1,), padding=(1,))\n",
       "  (fc1): Linear(in_features=240116, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[ 0.2548,  0.2767, -0.0781,  0.3062, -0.0730,  0.0673, -0.1623,\n",
       "           0.1958,  0.2938]],\n",
       "\n",
       "        [[-0.2445,  0.2897,  0.0624,  0.2463,  0.0451,  0.1607, -0.0471,\n",
       "           0.2570,  0.0493]]], device='cuda:1', requires_grad=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1d(1, 2, kernel_size=(9,), stride=(1,), padding=(1,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-9.4025e-04, -2.3932e-04, -8.2887e-04,  ..., -1.1343e-03,\n",
       "          1.7488e-04, -2.2776e-05],\n",
       "        [-1.3098e-03, -1.8676e-03, -6.3240e-04,  ...,  2.8130e-04,\n",
       "          1.6656e-03, -4.6616e-04],\n",
       "        [-1.9303e-03, -7.0706e-04,  1.8977e-03,  ..., -8.3026e-04,\n",
       "          2.5134e-04, -7.0575e-04],\n",
       "        ...,\n",
       "        [-2.0255e-03, -1.0723e-03,  5.2723e-04,  ..., -3.9869e-04,\n",
       "          1.9361e-03, -1.1633e-03],\n",
       "        [ 4.8982e-04, -1.2842e-03,  9.8855e-04,  ...,  7.6381e-04,\n",
       "         -8.6123e-04,  6.6515e-04],\n",
       "        [ 1.8723e-04,  8.9811e-04, -1.4482e-03,  ..., -5.3925e-04,\n",
       "          5.5443e-04,  1.4453e-03]], device='cuda:1', requires_grad=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33menisberk\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.15 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">hopeful-fire-162</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/enisberk/megan\" target=\"_blank\">https://wandb.ai/enisberk/megan</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/enisberk/megan/runs/n5e327t3\" target=\"_blank\">https://wandb.ai/enisberk/megan/runs/n5e327t3</a><br/>\n",
       "                Run data is saved locally in <code>/home/enis/projects/nna/src/nna/exp/megan/run-2/wandb/run-20210126_094304-n5e327t3</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:43:06,520 Trainer INFO: Engine run starting with max_epochs=2000.\n",
      "/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370141920/work/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
      "  normalized, onesided, return_complex)\n",
      "/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370141920/work/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
      "  normalized, onesided, return_complex)\n",
      "2021-01-26 09:43:28,600 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:43:52,150 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:24\n",
      "2021-01-26 09:43:52,154 Train Evaluator INFO: Engine run complete. Time taken: 00:00:24\n",
      "2021-01-26 09:43:52,155 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:43:59,840 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:08\n",
      "2021-01-26 09:44:00,165 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1 < 8; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:44:00,177 Trainer INFO: Epoch[1] Complete. Time taken: 00:00:54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1685.1240657232945\n",
      "val loss 1209.0644663428045\n",
      "validation roc auc [0.65373134 0.61582569] 1\n",
      "train roc auc [0.49208553 0.5599308 ] 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:44:23,664 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:44:44,870 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:21\n",
      "2021-01-26 09:44:44,873 Train Evaluator INFO: Engine run complete. Time taken: 00:00:21\n",
      "2021-01-26 09:44:44,883 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:44:51,804 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 09:44:52,122 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2 < 16; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:44:52,137 Trainer INFO: Epoch[2] Complete. Time taken: 00:00:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1082.7270795036766\n",
      "val loss 1865.0308394705414\n",
      "validation roc auc [0.35903814 0.40711009] 2\n",
      "train roc auc [0.51305193 0.46268226] 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:45:13,037 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:45:34,504 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:21\n",
      "2021-01-26 09:45:34,507 Train Evaluator INFO: Engine run complete. Time taken: 00:00:21\n",
      "2021-01-26 09:45:34,508 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:45:41,940 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 09:45:42,260 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3 < 24; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:45:42,278 Trainer INFO: Epoch[3] Complete. Time taken: 00:00:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 554.012551301445\n",
      "val loss 470.3751634731414\n",
      "validation roc auc [0.65936982 0.47610856] 3\n",
      "train roc auc [0.49611219 0.56054864] 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:46:04,108 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:46:24,683 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:21\n",
      "2021-01-26 09:46:24,686 Train Evaluator INFO: Engine run complete. Time taken: 00:00:21\n",
      "2021-01-26 09:46:24,687 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:46:32,501 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:08\n",
      "2021-01-26 09:46:32,811 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4 < 32; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:46:32,824 Trainer INFO: Epoch[4] Complete. Time taken: 00:00:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 141.12315119325726\n",
      "val loss 265.08667769705414\n",
      "validation roc auc [0.45887231 0.46368502] 4\n",
      "train roc auc [0.60285833 0.51569322] 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:46:53,611 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:47:16,586 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:23\n",
      "2021-01-26 09:47:16,588 Train Evaluator INFO: Engine run complete. Time taken: 00:00:23\n",
      "2021-01-26 09:47:16,589 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:47:24,284 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:08\n",
      "2021-01-26 09:47:24,589 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 5 < 40; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:47:24,599 Trainer INFO: Epoch[5] Complete. Time taken: 00:00:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 66.10263043447257\n",
      "val loss 96.27349037121816\n",
      "validation roc auc [0.44825871 0.7360474 ] 5\n",
      "train roc auc [0.61439283 0.63423676] 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:47:48,969 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:48:11,158 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:22\n",
      "2021-01-26 09:48:11,160 Train Evaluator INFO: Engine run complete. Time taken: 00:00:22\n",
      "2021-01-26 09:48:11,161 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:48:18,436 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 09:48:18,759 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 6 < 48; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:48:18,771 Trainer INFO: Epoch[6] Complete. Time taken: 00:00:54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 81.80038668231506\n",
      "val loss 153.37002378816058\n",
      "validation roc auc [0.54311774 0.46406728] 6\n",
      "train roc auc [0.62577855 0.55490568] 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:48:42,077 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:49:03,238 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:21\n",
      "2021-01-26 09:49:03,240 Train Evaluator INFO: Engine run complete. Time taken: 00:00:21\n",
      "2021-01-26 09:49:03,241 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:49:09,556 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:06\n",
      "2021-01-26 09:49:09,886 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 7 < 56; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:49:09,907 Trainer INFO: Epoch[7] Complete. Time taken: 00:00:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 52.996103344919376\n",
      "val loss 51.61265967302262\n",
      "validation roc auc [0.56467662 0.75382263] 7\n",
      "train roc auc [0.60748007 0.65207183] 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:49:32,301 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:49:53,552 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:21\n",
      "2021-01-26 09:49:53,555 Train Evaluator INFO: Engine run complete. Time taken: 00:00:21\n",
      "2021-01-26 09:49:53,556 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:50:00,946 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 09:50:01,221 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 8 < 64; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:50:01,232 Trainer INFO: Epoch[8] Complete. Time taken: 00:00:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 39.96793232504319\n",
      "val loss 90.8324608286475\n",
      "validation roc auc [0.45190713 0.48853211] 8\n",
      "train roc auc [0.67382076 0.65450202] 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:50:21,715 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:50:42,968 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:21\n",
      "2021-01-26 09:50:42,970 Train Evaluator INFO: Engine run complete. Time taken: 00:00:21\n",
      "2021-01-26 09:50:42,972 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:50:50,996 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:08\n",
      "2021-01-26 09:50:51,335 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 9 < 72; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:50:51,344 Trainer INFO: Epoch[9] Complete. Time taken: 00:00:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 51.808635337679995\n",
      "val loss 102.03630547007178\n",
      "validation roc auc [0.45008292 0.48413609] 9\n",
      "train roc auc [0.67233308 0.64210396] 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:51:12,059 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:51:34,718 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:23\n",
      "2021-01-26 09:51:34,720 Train Evaluator INFO: Engine run complete. Time taken: 00:00:23\n",
      "2021-01-26 09:51:34,721 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:51:41,341 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 09:51:41,686 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 10 < 80; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:51:41,694 Trainer INFO: Epoch[10] Complete. Time taken: 00:00:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 18.676960232470808\n",
      "val loss 23.769011758694983\n",
      "validation roc auc [0.44212272 0.75344037] 10\n",
      "train roc auc [0.67106359 0.64675838] 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:52:03,915 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:52:26,282 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:22\n",
      "2021-01-26 09:52:26,284 Train Evaluator INFO: Engine run complete. Time taken: 00:00:22\n",
      "2021-01-26 09:52:26,286 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:52:36,238 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:10\n",
      "2021-01-26 09:52:36,512 Val Evaluator INFO: Engine run complete. Time taken: 00:00:10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 11 < 88; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:52:36,519 Trainer INFO: Epoch[11] Complete. Time taken: 00:00:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 182.57796117578977\n",
      "val loss 173.0313544789697\n",
      "validation roc auc [0.58855721 0.53306575] 11\n",
      "train roc auc [0.56711429 0.66595271] 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:52:56,757 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:53:20,510 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:24\n",
      "2021-01-26 09:53:20,513 Train Evaluator INFO: Engine run complete. Time taken: 00:00:24\n",
      "2021-01-26 09:53:20,515 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:53:28,156 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:08\n",
      "2021-01-26 09:53:28,432 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 12 < 96; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:53:28,447 Trainer INFO: Epoch[12] Complete. Time taken: 00:00:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 128.91522113741874\n",
      "val loss 98.83933734286363\n",
      "validation roc auc [0.55323383 0.74560398] 12\n",
      "train roc auc [0.62121633 0.63357772] 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:53:48,773 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:54:10,077 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:21\n",
      "2021-01-26 09:54:10,081 Train Evaluator INFO: Engine run complete. Time taken: 00:00:21\n",
      "2021-01-26 09:54:10,082 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:54:17,128 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 09:54:17,442 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 13 < 104; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:54:17,453 Trainer INFO: Epoch[13] Complete. Time taken: 00:00:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 195.10423597946667\n",
      "val loss 154.37532325307276\n",
      "validation roc auc [0.59568823 0.67507645] 13\n",
      "train roc auc [0.56470425 0.66059807] 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:54:41,934 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:55:03,925 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:22\n",
      "2021-01-26 09:55:03,927 Train Evaluator INFO: Engine run complete. Time taken: 00:00:22\n",
      "2021-01-26 09:55:03,929 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:55:11,447 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:08\n",
      "2021-01-26 09:55:11,751 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 14 < 112; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:55:11,760 Trainer INFO: Epoch[14] Complete. Time taken: 00:00:54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 69.14773511367166\n",
      "val loss 104.62772102112983\n",
      "validation roc auc [0.43880597 0.61219419] 14\n",
      "train roc auc [0.63343516 0.65827086] 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:55:33,234 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:55:53,431 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:20\n",
      "2021-01-26 09:55:53,434 Train Evaluator INFO: Engine run complete. Time taken: 00:00:20\n",
      "2021-01-26 09:55:53,435 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:55:59,852 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:06\n",
      "2021-01-26 09:55:59,856 Val Evaluator INFO: Engine run complete. Time taken: 00:00:06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 15 < 120; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:55:59,866 Trainer INFO: Epoch[15] Complete. Time taken: 00:00:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 120.01176635476239\n",
      "val loss 223.54343195629727\n",
      "validation roc auc [0.44593698 0.46693425] 15\n",
      "train roc auc [0.64295632 0.53323997] 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:56:23,672 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:56:45,293 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:22\n",
      "2021-01-26 09:56:45,296 Train Evaluator INFO: Engine run complete. Time taken: 00:00:22\n",
      "2021-01-26 09:56:45,298 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:56:52,819 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:08\n",
      "2021-01-26 09:56:52,822 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 16 < 128; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:56:52,832 Trainer INFO: Epoch[16] Complete. Time taken: 00:00:53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 32.27186282787448\n",
      "val loss 73.17556646067625\n",
      "validation roc auc [0.46898839 0.51509939] 16\n",
      "train roc auc [0.68266751 0.66142186] 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:57:15,326 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:57:37,351 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:22\n",
      "2021-01-26 09:57:37,353 Train Evaluator INFO: Engine run complete. Time taken: 00:00:22\n",
      "2021-01-26 09:57:37,354 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:57:43,997 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 09:57:44,316 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 17 < 136; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:57:44,331 Trainer INFO: Epoch[17] Complete. Time taken: 00:00:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 64.23298576870255\n",
      "val loss 105.03784029043405\n",
      "validation roc auc [0.46334992 0.57807722] 17\n",
      "train roc auc [0.66828659 0.6813988 ] 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:58:08,053 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:58:29,418 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:21\n",
      "2021-01-26 09:58:29,421 Train Evaluator INFO: Engine run complete. Time taken: 00:00:21\n",
      "2021-01-26 09:58:29,422 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:58:36,636 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 09:58:36,956 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 18 < 144; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:58:36,975 Trainer INFO: Epoch[18] Complete. Time taken: 00:00:53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 39.92912025700987\n",
      "val loss 76.09412957452665\n",
      "validation roc auc [0.48358209 0.56479358] 18\n",
      "train roc auc [0.69107788 0.68485872] 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:58:58,127 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:59:18,231 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:20\n",
      "2021-01-26 09:59:18,234 Train Evaluator INFO: Engine run complete. Time taken: 00:00:20\n",
      "2021-01-26 09:59:18,235 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:59:25,029 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 09:59:25,032 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 19 < 152; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:59:25,040 Trainer INFO: Epoch[19] Complete. Time taken: 00:00:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 140.59166463216147\n",
      "val loss 236.93753304451135\n",
      "validation roc auc [0.45721393 0.4860474 ] 19\n",
      "train roc auc [0.62603642 0.62356866] 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:59:43,799 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:00:03,508 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:20\n",
      "2021-01-26 10:00:03,511 Train Evaluator INFO: Engine run complete. Time taken: 00:00:20\n",
      "2021-01-26 10:00:03,512 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:00:10,837 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 10:00:10,839 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 20 < 160; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:00:10,847 Trainer INFO: Epoch[20] Complete. Time taken: 00:00:46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 147.6485434305694\n",
      "val loss 256.5607793528563\n",
      "validation roc auc [0.4628524  0.47457951] 20\n",
      "train roc auc [0.63438727 0.57545926] 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:00:32,560 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:00:53,352 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:21\n",
      "2021-01-26 10:00:53,356 Train Evaluator INFO: Engine run complete. Time taken: 00:00:21\n",
      "2021-01-26 10:00:53,357 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:01:00,256 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 10:01:00,612 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 21 < 168; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:01:00,620 Trainer INFO: Epoch[21] Complete. Time taken: 00:00:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 33.5142979175177\n",
      "val loss 45.78952456431784\n",
      "validation roc auc [0.54626866 0.76624618] 21\n",
      "train roc auc [0.66995279 0.68675344] 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:01:24,475 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:01:44,956 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:20\n",
      "2021-01-26 10:01:44,959 Train Evaluator INFO: Engine run complete. Time taken: 00:00:20\n",
      "2021-01-26 10:01:44,960 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:01:51,164 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:06\n",
      "2021-01-26 10:01:51,500 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 22 < 176; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:01:51,512 Trainer INFO: Epoch[22] Complete. Time taken: 00:00:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 14.860989880198227\n",
      "val loss 24.16794790280093\n",
      "validation roc auc [0.49054726 0.7742737 ] 22\n",
      "train roc auc [0.69806998 0.67542631] 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:02:14,002 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:02:34,116 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:20\n",
      "2021-01-26 10:02:34,118 Train Evaluator INFO: Engine run complete. Time taken: 00:00:20\n",
      "2021-01-26 10:02:34,119 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:02:42,027 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:08\n",
      "2021-01-26 10:02:42,324 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 23 < 184; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:02:42,333 Trainer INFO: Epoch[23] Complete. Time taken: 00:00:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 29.545853492221543\n",
      "val loss 45.647716157755276\n",
      "validation roc auc [0.48457711 0.7675841 ] 23\n",
      "train roc auc [0.70208672 0.67983359] 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:03:04,610 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:03:25,651 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:21\n",
      "2021-01-26 10:03:25,653 Train Evaluator INFO: Engine run complete. Time taken: 00:00:21\n",
      "2021-01-26 10:03:25,655 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:03:33,101 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 10:03:33,471 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 24 < 192; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:03:33,496 Trainer INFO: Epoch[24] Complete. Time taken: 00:00:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 8.792616327863373\n",
      "val loss 19.832272936584083\n",
      "validation roc auc [0.48175788 0.75076453] 24\n",
      "train roc auc [0.70458603 0.68625916] 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:03:55,292 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:04:14,329 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:19\n",
      "2021-01-26 10:04:14,331 Train Evaluator INFO: Engine run complete. Time taken: 00:00:19\n",
      "2021-01-26 10:04:14,332 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:04:20,149 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:06\n",
      "2021-01-26 10:04:20,539 Val Evaluator INFO: Engine run complete. Time taken: 00:00:06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 25 < 200; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:04:20,550 Trainer INFO: Epoch[25] Complete. Time taken: 00:00:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 55.560586268605746\n",
      "val loss 45.080204277281545\n",
      "validation roc auc [0.53499171 0.75286697] 25\n",
      "train roc auc [0.68215178 0.65907406] 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:04:42,936 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:05:03,400 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:20\n",
      "2021-01-26 10:05:03,404 Train Evaluator INFO: Engine run complete. Time taken: 00:00:20\n",
      "2021-01-26 10:05:03,406 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:05:11,300 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:08\n",
      "2021-01-26 10:05:11,588 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 26 < 208; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:05:11,606 Trainer INFO: Epoch[26] Complete. Time taken: 00:00:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 47.63126764733807\n",
      "val loss 46.71753175091592\n",
      "validation roc auc [0.57810945 0.75420489] 26\n",
      "train roc auc [0.66870314 0.69581514] 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:05:33,536 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:05:55,200 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:22\n",
      "2021-01-26 10:05:55,203 Train Evaluator INFO: Engine run complete. Time taken: 00:00:22\n",
      "2021-01-26 10:05:55,204 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:06:02,306 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 10:06:02,635 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 27 < 216; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:06:02,652 Trainer INFO: Epoch[27] Complete. Time taken: 00:00:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 6.669866115179457\n",
      "val loss 12.08032680924531\n",
      "validation roc auc [0.48043118 0.75764526] 27\n",
      "train roc auc [0.72196215 0.68737128] 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:06:24,310 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:06:44,738 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:20\n",
      "2021-01-26 10:06:44,741 Train Evaluator INFO: Engine run complete. Time taken: 00:00:20\n",
      "2021-01-26 10:06:44,742 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:06:51,875 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 10:06:51,879 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 28 < 224; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:06:51,888 Trainer INFO: Epoch[28] Complete. Time taken: 00:00:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 57.34715929218367\n",
      "val loss 95.24876170553219\n",
      "validation roc auc [0.45887231 0.54816514] 28\n",
      "train roc auc [0.70523069 0.72283549] 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:07:14,189 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:07:34,388 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:20\n",
      "2021-01-26 10:07:34,391 Train Evaluator INFO: Engine run complete. Time taken: 00:00:20\n",
      "2021-01-26 10:07:34,392 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:07:41,243 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 10:07:41,246 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 29 < 232; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:07:41,255 Trainer INFO: Epoch[29] Complete. Time taken: 00:00:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 33.45061052442895\n",
      "val loss 52.602929084923616\n",
      "validation roc auc [0.46119403 0.67851682] 29\n",
      "train roc auc [0.7267029  0.72024055] 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:08:01,630 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:08:23,211 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:22\n",
      "2021-01-26 10:08:23,214 Train Evaluator INFO: Engine run complete. Time taken: 00:00:22\n",
      "2021-01-26 10:08:23,215 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:08:29,514 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:06\n",
      "2021-01-26 10:08:29,517 Val Evaluator INFO: Engine run complete. Time taken: 00:00:06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 30 < 240; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:08:29,525 Trainer INFO: Epoch[30] Complete. Time taken: 00:00:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 16.584534697023614\n",
      "val loss 22.550909929214768\n",
      "validation roc auc [0.47147595 0.71616972] 30\n",
      "train roc auc [0.73695799 0.71743966] 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:08:49,949 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:09:09,748 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:20\n",
      "2021-01-26 10:09:09,750 Train Evaluator INFO: Engine run complete. Time taken: 00:00:20\n",
      "2021-01-26 10:09:09,751 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:09:16,451 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 10:09:16,453 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 31 < 248; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:09:16,461 Trainer INFO: Epoch[31] Complete. Time taken: 00:00:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 13.922211009173092\n",
      "val loss 16.204874804065486\n",
      "validation roc auc [0.47097844 0.73853211] 31\n",
      "train roc auc [0.74171857 0.710561  ] 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:09:38,558 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:09:59,631 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:21\n",
      "2021-01-26 10:09:59,634 Train Evaluator INFO: Engine run complete. Time taken: 00:00:21\n",
      "2021-01-26 10:09:59,635 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:10:07,500 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:08\n",
      "2021-01-26 10:10:07,502 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 32 < 256; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:10:07,510 Trainer INFO: Epoch[32] Complete. Time taken: 00:00:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 2.2534444332122803\n",
      "val loss 4.490767562465304\n",
      "validation roc auc [0.46583748 0.74426606] 32\n",
      "train roc auc [0.75481017 0.70990197] 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:10:30,533 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:10:51,129 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:21\n",
      "2021-01-26 10:10:51,132 Train Evaluator INFO: Engine run complete. Time taken: 00:00:21\n",
      "2021-01-26 10:10:51,133 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:10:58,355 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 10:10:58,358 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 33 < 264; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:10:58,365 Trainer INFO: Epoch[33] Complete. Time taken: 00:00:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 16.206075190458943\n",
      "val loss 24.375899053682947\n",
      "validation roc auc [0.45754561 0.72381498] 33\n",
      "train roc auc [0.75676399 0.73321526] 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:11:18,260 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:11:38,517 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:20\n",
      "2021-01-26 10:11:38,526 Train Evaluator INFO: Engine run complete. Time taken: 00:00:20\n",
      "2021-01-26 10:11:38,528 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:11:46,514 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:08\n",
      "2021-01-26 10:11:46,518 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 34 < 272; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:11:46,534 Trainer INFO: Epoch[34] Complete. Time taken: 00:00:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 8.832844188789917\n",
      "val loss 14.090006214797876\n",
      "validation roc auc [0.46235489 0.71005352] 34\n",
      "train roc auc [0.76665212 0.74029986] 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:12:08,998 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:12:28,988 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:20\n",
      "2021-01-26 10:12:28,991 Train Evaluator INFO: Engine run complete. Time taken: 00:00:20\n",
      "2021-01-26 10:12:28,992 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:12:36,040 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 10:12:36,043 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 35 < 280; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:12:36,050 Trainer INFO: Epoch[35] Complete. Time taken: 00:00:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 6.238651885446121\n",
      "val loss 10.497521667723444\n",
      "validation roc auc [0.46600332 0.71999235] 35\n",
      "train roc auc [0.77877177 0.74816706] 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:12:59,192 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:13:19,864 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:21\n",
      "2021-01-26 10:13:19,870 Train Evaluator INFO: Engine run complete. Time taken: 00:00:21\n",
      "2021-01-26 10:13:19,872 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:13:26,008 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:06\n",
      "2021-01-26 10:13:26,011 Val Evaluator INFO: Engine run complete. Time taken: 00:00:06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 36 < 288; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:13:26,019 Trainer INFO: Epoch[36] Complete. Time taken: 00:00:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 6.8450533112669305\n",
      "val loss 12.512118424579596\n",
      "validation roc auc [0.47131012 0.71961009] 36\n",
      "train roc auc [0.78747967 0.75928824] 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:13:48,156 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:14:10,229 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:22\n",
      "2021-01-26 10:14:10,233 Train Evaluator INFO: Engine run complete. Time taken: 00:00:22\n",
      "2021-01-26 10:14:10,235 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:14:18,574 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:08\n",
      "2021-01-26 10:14:18,577 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 37 < 296; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:14:18,586 Trainer INFO: Epoch[37] Complete. Time taken: 00:00:53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 12.73695004947305\n",
      "val loss 21.43750773873299\n",
      "validation roc auc [0.47313433 0.70470183] 37\n",
      "train roc auc [0.79666363 0.77494028] 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:14:42,314 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:15:04,221 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:22\n",
      "2021-01-26 10:15:04,224 Train Evaluator INFO: Engine run complete. Time taken: 00:00:22\n",
      "2021-01-26 10:15:04,225 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:15:11,091 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 10:15:11,094 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 38 < 304; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:15:11,101 Trainer INFO: Epoch[38] Complete. Time taken: 00:00:53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 2.796477156916475\n",
      "val loss 6.855569219892951\n",
      "validation roc auc [0.4681592  0.72993119] 38\n",
      "train roc auc [0.79662395 0.7646017 ] 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:15:33,661 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:15:55,159 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:21\n",
      "2021-01-26 10:15:55,162 Train Evaluator INFO: Engine run complete. Time taken: 00:00:21\n",
      "2021-01-26 10:15:55,163 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:16:02,133 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 10:16:02,472 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 39 < 312; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:16:02,481 Trainer INFO: Epoch[39] Complete. Time taken: 00:00:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 39.28589312235514\n",
      "val loss 32.067377272684865\n",
      "validation roc auc [0.54875622 0.73451835] 39\n",
      "train roc auc [0.75137859 0.74969108] 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:16:25,153 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:16:45,482 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:20\n",
      "2021-01-26 10:16:45,486 Train Evaluator INFO: Engine run complete. Time taken: 00:00:20\n",
      "2021-01-26 10:16:45,488 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:16:52,998 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:08\n",
      "2021-01-26 10:16:53,000 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 40 < 320; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:16:53,008 Trainer INFO: Epoch[40] Complete. Time taken: 00:00:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 21.467829976466227\n",
      "val loss 19.077892789415493\n",
      "validation roc auc [0.4708126  0.72343272] 40\n",
      "train roc auc [0.78650772 0.76703188] 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:17:15,221 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:17:35,572 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:20\n",
      "2021-01-26 10:17:35,575 Train Evaluator INFO: Engine run complete. Time taken: 00:00:20\n",
      "2021-01-26 10:17:35,577 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:17:43,510 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:08\n",
      "2021-01-26 10:17:43,513 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 41 < 328; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:17:43,520 Trainer INFO: Epoch[41] Complete. Time taken: 00:00:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.3626283840935733\n",
      "val loss 3.6126864563887287\n",
      "validation roc auc [0.45671642 0.71731651] 41\n",
      "train roc auc [0.80469711 0.780748  ] 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:18:03,961 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:18:23,990 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:20\n",
      "2021-01-26 10:18:23,992 Train Evaluator INFO: Engine run complete. Time taken: 00:00:20\n",
      "2021-01-26 10:18:23,994 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:18:30,371 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:06\n",
      "2021-01-26 10:18:30,374 Val Evaluator INFO: Engine run complete. Time taken: 00:00:06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 42 < 336; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:18:30,381 Trainer INFO: Epoch[42] Complete. Time taken: 00:00:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 9.905277206487385\n",
      "val loss 17.713462185707822\n",
      "validation roc auc [0.46318408 0.58256881] 42\n",
      "train roc auc [0.81483318 0.82115496] 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:18:51,335 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:19:10,326 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:19\n",
      "2021-01-26 10:19:10,330 Train Evaluator INFO: Engine run complete. Time taken: 00:00:19\n",
      "2021-01-26 10:19:10,332 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:19:17,614 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 10:19:17,617 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 43 < 344; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:19:17,626 Trainer INFO: Epoch[43] Complete. Time taken: 00:00:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 24.714708789501316\n",
      "val loss 41.882636853843735\n",
      "validation roc auc [0.44859038 0.51930428] 43\n",
      "train roc auc [0.7811719  0.82791004] 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:19:37,302 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:19:58,443 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:21\n",
      "2021-01-26 10:19:58,447 Train Evaluator INFO: Engine run complete. Time taken: 00:00:21\n",
      "2021-01-26 10:19:58,449 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:20:04,690 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:06\n",
      "2021-01-26 10:20:04,693 Val Evaluator INFO: Engine run complete. Time taken: 00:00:06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 44 < 352; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:20:04,702 Trainer INFO: Epoch[44] Complete. Time taken: 00:00:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 4.021565711332692\n",
      "val loss 10.415516312714596\n",
      "validation roc auc [0.45655058 0.58906728] 44\n",
      "train roc auc [0.8215575  0.83252327] 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:20:26,984 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:20:47,181 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:20\n",
      "2021-01-26 10:20:47,185 Train Evaluator INFO: Engine run complete. Time taken: 00:00:20\n",
      "2021-01-26 10:20:47,187 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:20:54,017 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 10:20:54,019 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 45 < 360; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:20:54,028 Trainer INFO: Epoch[45] Complete. Time taken: 00:00:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 7.924403746403381\n",
      "val loss 9.728522489025334\n",
      "validation roc auc [0.45737977 0.71769878] 45\n",
      "train roc auc [0.82627841 0.81250515] 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:21:15,485 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:21:37,429 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:22\n",
      "2021-01-26 10:21:37,431 Train Evaluator INFO: Engine run complete. Time taken: 00:00:22\n",
      "2021-01-26 10:21:37,432 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:21:44,861 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 10:21:44,864 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 46 < 368; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:21:44,871 Trainer INFO: Epoch[46] Complete. Time taken: 00:00:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.9199562342857743\n",
      "val loss 2.8247921603500465\n",
      "validation roc auc [0.45804312 0.69935015] 46\n",
      "train roc auc [0.83332011 0.83404729] 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:22:07,966 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:22:30,579 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:23\n",
      "2021-01-26 10:22:30,582 Train Evaluator INFO: Engine run complete. Time taken: 00:00:23\n",
      "2021-01-26 10:22:30,583 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:22:37,493 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 10:22:37,497 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 47 < 376; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:22:37,513 Trainer INFO: Epoch[47] Complete. Time taken: 00:00:53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 6.627474718363976\n",
      "val loss 11.353757074684095\n",
      "validation roc auc [0.45273632 0.59461009] 47\n",
      "train roc auc [0.83385568 0.85859626] 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:22:58,330 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:23:18,908 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:21\n",
      "2021-01-26 10:23:18,911 Train Evaluator INFO: Engine run complete. Time taken: 00:00:21\n",
      "2021-01-26 10:23:18,913 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:23:26,572 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:08\n",
      "2021-01-26 10:23:26,575 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 48 < 384; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:23:26,582 Trainer INFO: Epoch[48] Complete. Time taken: 00:00:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 5.090356581091621\n",
      "val loss 9.634593921102535\n",
      "validation roc auc [0.45240464 0.56995413] 48\n",
      "train roc auc [0.8411354  0.86938792] 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:23:46,625 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:24:09,608 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:23\n",
      "2021-01-26 10:24:09,611 Train Evaluator INFO: Engine run complete. Time taken: 00:00:23\n",
      "2021-01-26 10:24:09,612 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:24:18,749 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:09\n",
      "2021-01-26 10:24:18,751 Val Evaluator INFO: Engine run complete. Time taken: 00:00:09\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 49 < 392; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:24:18,759 Trainer INFO: Epoch[49] Complete. Time taken: 00:00:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 5.003654156894726\n",
      "val loss 7.329165422233047\n",
      "validation roc auc [0.45572139 0.71636086] 49\n",
      "train roc auc [0.85329472 0.85000824] 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:24:41,434 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:25:00,611 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:19\n",
      "2021-01-26 10:25:00,614 Train Evaluator INFO: Engine run complete. Time taken: 00:00:19\n",
      "2021-01-26 10:25:00,615 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:25:07,880 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 10:25:07,883 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 50 < 400; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:25:07,906 Trainer INFO: Epoch[50] Complete. Time taken: 00:00:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 12.355000435656711\n",
      "val loss 11.412496906936548\n",
      "validation roc auc [0.46484245 0.67775229] 50\n",
      "train roc auc [0.86035625 0.87643134] 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:25:29,379 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:25:52,247 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:23\n",
      "2021-01-26 10:25:52,250 Train Evaluator INFO: Engine run complete. Time taken: 00:00:23\n",
      "2021-01-26 10:25:52,251 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:25:58,511 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:06\n",
      "2021-01-26 10:25:58,514 Val Evaluator INFO: Engine run complete. Time taken: 00:00:06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 51 < 408; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:25:58,524 Trainer INFO: Epoch[51] Complete. Time taken: 00:00:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 2.531456857984622\n",
      "val loss 4.429104325118338\n",
      "validation roc auc [0.45754561 0.71406728] 51\n",
      "train roc auc [0.87537192 0.87869676] 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:26:20,544 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:26:41,496 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:21\n",
      "2021-01-26 10:26:41,498 Train Evaluator INFO: Engine run complete. Time taken: 00:00:21\n",
      "2021-01-26 10:26:41,499 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:26:49,487 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:08\n",
      "2021-01-26 10:26:49,859 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 52 < 416; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:26:49,872 Trainer INFO: Epoch[52] Complete. Time taken: 00:00:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 95.90568763550071\n",
      "val loss 68.06346655195685\n",
      "validation roc auc [0.65439469 0.68100153] 52\n",
      "train roc auc [0.59850438 0.90254551] 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:27:10,791 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:27:32,333 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:22\n",
      "2021-01-26 10:27:32,336 Train Evaluator INFO: Engine run complete. Time taken: 00:00:22\n",
      "2021-01-26 10:27:32,337 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:27:39,819 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 10:27:39,822 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 53 < 424; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:27:39,831 Trainer INFO: Epoch[53] Complete. Time taken: 00:00:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 5.534261435465096\n",
      "val loss 9.644674671683342\n",
      "validation roc auc [0.45124378 0.5764526 ] 53\n",
      "train roc auc [0.89822272 0.93891589] 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:28:00,110 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:28:22,278 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:22\n",
      "2021-01-26 10:28:22,281 Train Evaluator INFO: Engine run complete. Time taken: 00:00:22\n",
      "2021-01-26 10:28:22,282 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:28:29,848 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:08\n",
      "2021-01-26 10:28:29,850 Val Evaluator INFO: Engine run complete. Time taken: 00:00:08\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 54 < 432; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:28:29,858 Trainer INFO: Epoch[54] Complete. Time taken: 00:00:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.6637103069322041\n",
      "val loss 4.792500766219606\n",
      "validation roc auc [0.460199   0.54778287] 54\n",
      "train roc auc [0.94283334 0.95547409] 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 10:28:49,538 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:29:08,659 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:19\n",
      "2021-01-26 10:29:08,662 Train Evaluator INFO: Engine run complete. Time taken: 00:00:19\n",
      "2021-01-26 10:29:08,663 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 10:29:15,775 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07\n",
      "2021-01-26 10:29:15,778 Val Evaluator INFO: Engine run complete. Time taken: 00:00:07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 55 < 440; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 10:29:15,787 Trainer INFO: Epoch[55] Complete. Time taken: 00:00:46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.9955322519107062\n",
      "val loss 4.240103663912245\n",
      "validation roc auc [0.46053068 0.51605505] 55\n",
      "train roc auc [0.96145912 0.96836642] 55\n"
     ]
    }
   ],
   "source": [
    "print('ready ?')\n",
    "runutils.run(model, dataloaders, optimizer, criterion, metrics, device,config, runconfigs.PROJECT_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example_input = (torch.ones((1,1,h_w[0]*h_w[1]))*-32767)\n",
    "example_input = example_input.float().to(device)\n",
    "out=model(example_input)\n",
    "out\n",
    "\n",
    "activated_output_transform((out,out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor([10,10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(model.fc1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "input = torch.tensor([100.0,100,100], requires_grad=True)\n",
    "# target = torch.empty(3).random_(2)\n",
    "target = torch.ones(3)\n",
    "output = loss((input), target)\n",
    "input,target,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Experiment running. Can only be imported from the experiment folder.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from genericpath import exists\n",
    "import os\n",
    "\n",
    "# import run\n",
    "# import nna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import wandb\n",
    "\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.contrib.metrics import ROC_AUC\n",
    "\n",
    "import runconfigs # type: ignore\n",
    "import modelarchs # type: ignore\n",
    "\n",
    "import nna.exp.megan as megan\n",
    "from nna.exp import runutils\n",
    "\n",
    "\n",
    "def prepare_dataset():\n",
    "\n",
    "    taxo_count_limit = runconfigs.TAXO_COUNT_LIMIT\n",
    "    sample_length_limit = runconfigs.SAMPLE_LENGTH_LIMIT\n",
    "    taxonomy_file_path = runconfigs.TAXONOMY_FILE_PATH\n",
    "\n",
    "    megan_labeled_files_info_path = runconfigs.MEGAN_LABELED_FILES_INFO_PATH\n",
    "\n",
    "    csv4megan_excell_clenaed = runconfigs.CSV4MEGAN_EXCELL_CLEANED\n",
    "\n",
    "    ignore_files = runconfigs.IGNORE_FILES\n",
    "\n",
    "    excerpt_length = runconfigs.EXCERPT_LENGTH\n",
    "    excell_names2code = runconfigs.EXCELL_NAMES2CODE\n",
    "    dataset_name_v = runconfigs.DATASET_NAME_V\n",
    "\n",
    "    audio_dataset, deleted_files = megan.preparedataset.run( # type: ignore\n",
    "        megan_labeled_files_info_path,\n",
    "        taxonomy_file_path,\n",
    "        csv4megan_excell_clenaed,\n",
    "        ignore_files,\n",
    "        excerpt_length,\n",
    "        sample_length_limit,\n",
    "        taxo_count_limit,\n",
    "        excell_names2code=excell_names2code,\n",
    "        dataset_name_v=dataset_name_v)\n",
    "\n",
    "    audio_dataset.load_audio_files(runconfigs.AUDIO_DATA_CACHE_PATH)\n",
    "    audio_dataset.pick_channel_by_clipping()\n",
    "\n",
    "    return audio_dataset, deleted_files\n",
    "\n",
    "\n",
    "def setup_config(config, wandb_project_name):\n",
    "\n",
    "    # wandb.init(config=runconfigs.default_config, project=runconfigs.PROJECT_NAME)\n",
    "    # config = wandb.config\n",
    "    config = runconfigs.default_config\n",
    "    # wandb.config.update(args) # adds all of the arguments as config variables\n",
    "    # config['batch_size'] = 64\n",
    "\n",
    "    os.chdir(runconfigs.EXP_DIR)\n",
    "\n",
    "    device = torch.device(\n",
    "        f\"cuda:{config['device']}\" if torch.cuda.is_available() else \"cpu\") # type: ignore\n",
    "    \n",
    "    config['device'] = device\n",
    "\n",
    "    random_seed: int = 42\n",
    "    # stable results\n",
    "    torch.manual_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    torch.backends.cudnn.benchmark = False # type: ignore\n",
    "\n",
    "    # wandb.init(config=config, project=wandb_project_name) # type: ignore\n",
    "    # config = wandb.config # type: ignore\n",
    "\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def dataset_generate_samples(audio_dataset, excerpt_len):\n",
    "    '''divida into chunks by expected_len seconds.\n",
    "        \n",
    "        Repeats data if smaller than expected_len.\n",
    "\n",
    "    TODO move this function to audio_dataset's class\n",
    "    '''\n",
    "    for sound_ins in audio_dataset.values():\n",
    "        data_to_samples(sound_ins,excerpt_len)\n",
    "    return audio_dataset\n",
    "\n",
    "def data_to_samples(sound_ins,excerpt_len):\n",
    "    excerpt_sample_size = excerpt_len * sound_ins.sr\n",
    "\n",
    "    data_len_sec = sound_ins.length\n",
    "    if data_len_sec<10:\n",
    "        tile_reps = (excerpt_len / (sound_ins.length) + 1)\n",
    "        repeated_data = np.tile(sound_ins.data, int(tile_reps))\n",
    "        repeated_data = repeated_data[:excerpt_len * sound_ins.sr]\n",
    "        sound_ins.samples = [repeated_data]\n",
    "        \n",
    "    elif data_len_sec==10:\n",
    "        sound_ins.samples = [sound_ins.data]\n",
    "    else:\n",
    "        excerpt_count = data_len_sec//10\n",
    "        data_trim_point = excerpt_count*excerpt_len*sound_ins.sr\n",
    "        samples = sound_ins.data[:int(data_trim_point)].reshape(-1,int(excerpt_sample_size))\n",
    "        sample_list = []\n",
    "        for sample in samples:\n",
    "            sample_list.append(sample)\n",
    "        \n",
    "        sound_ins.samples = sample_list\n",
    "\n",
    "def put_samples_into_array(target_taxo, other_taxo, audio_dataset):\n",
    "    # sound_ins[1].taxo_code\n",
    "    # classA = 1.1.7 #'duck-goose-swan']\n",
    "    # classB = 0.2.0 # other-aircraft\n",
    "    # 3.0.0 : 0.48, 0.26, 0.26, 46 # silence\n",
    "    # 2.1.0 : 0.22, 0.56, 0.22, 18 # rain\n",
    "    # 1.3.0 1.3.0 : 0.52, 0.4, 0.087, 161 # insect\n",
    "    # 1.1.8 : 0.49, 0.19, 0.32, 88 # grouse-ptarmigan\n",
    "\n",
    "    x_data = []\n",
    "    y = []\n",
    "    location_id_info = []\n",
    "\n",
    "    for sound_ins in audio_dataset.values():\n",
    "        if sound_ins.taxo_code in target_taxo + other_taxo:\n",
    "            for sample in sound_ins.samples:\n",
    "                y.append(sound_ins.taxo_code)\n",
    "                location_id_info.append(sound_ins.location_id)\n",
    "                x_data.append(sample)\n",
    "\n",
    "    return x_data, y, location_id_info\n",
    "\n",
    "\n",
    "def create_one_hot_vector(alphabet, y_data):\n",
    "    # define input string\n",
    "    # define universe of possible input values\n",
    "    # alphabet = ['1.1.10','1.1.7']\n",
    "\n",
    "    # define a mapping of chars to integers\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "    # integer encode input data\n",
    "    integer_encoded = [char_to_int.get(char, None) for char in y_data]\n",
    "    # print(integer_encoded)\n",
    "    # one hot encode\n",
    "    onehot_encoded = list()\n",
    "    for value in integer_encoded:\n",
    "        letter = [0 for _ in range(len(alphabet))]\n",
    "        if value is not None:\n",
    "            letter[value] = 1\n",
    "        onehot_encoded.append(letter)\n",
    "    # print(onehot_encoded)\n",
    "    # invert encoding\n",
    "    inverted = int_to_char[np.argmax(onehot_encoded[0])]\n",
    "    # print(inverted)\n",
    "    onehot_encoded = np.array(onehot_encoded)\n",
    "\n",
    "    return onehot_encoded\n",
    "\n",
    "\n",
    "def split_train_test_val(x_data, location_id_info, onehot_encoded, loc_per_set):\n",
    "    X_train, X_test, X_val, y_train, y_test, y_val = [], [], [], [], [], []\n",
    "    loc_id_train = []\n",
    "    loc_id_test = []\n",
    "    loc_id_valid = []\n",
    "\n",
    "    for sample, y_val_ins, loc_id in zip(x_data, onehot_encoded,\n",
    "                                         location_id_info):\n",
    "        if loc_id in loc_per_set[0]:\n",
    "            X_train.append(sample)\n",
    "            y_train.append(y_val_ins)\n",
    "            loc_id_train.append(loc_id)\n",
    "        elif loc_id in loc_per_set[1]:\n",
    "            X_test.append(sample)\n",
    "            y_test.append(y_val_ins)\n",
    "            loc_id_test.append(loc_id)\n",
    "        elif loc_id in loc_per_set[2]:\n",
    "            X_val.append(sample)\n",
    "            y_val.append(y_val_ins)\n",
    "            loc_id_valid.append(loc_id)\n",
    "        else:\n",
    "            print('error')\n",
    "\n",
    "    X_train, X_test, X_val = np.array(X_train), np.array(X_test), np.array(\n",
    "        X_val)\n",
    "    y_train, y_test, y_val = np.array(y_train), np.array(y_test), np.array(\n",
    "        y_val)\n",
    "\n",
    "    X_train, X_test, X_val = torch.from_numpy(X_train).float(\n",
    "    ), torch.from_numpy(X_test).float(), torch.from_numpy(X_val).float()\n",
    "    y_train, y_test, y_val = torch.from_numpy(y_train).float(\n",
    "    ), torch.from_numpy(y_test).float(), torch.from_numpy(y_val).float()\n",
    "\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val\n",
    "\n",
    "\n",
    "def prepare_run_inputs(config, X_train, X_test, X_val, y_train, y_test, y_val):\n",
    "\n",
    "    \n",
    "    # toTensor = augmentations.ToTensor(maxMelLen,runconfigs.SAMPLING_RATE)\n",
    "    to_tensor = modelarchs.ToTensor(runconfigs.MAX_MEL_LEN,runconfigs.SAMPLING_RATE)\n",
    "\n",
    "    transformCompose = transforms.Compose([\n",
    "        to_tensor,\n",
    "    ])\n",
    "\n",
    "    sound_datasets = {\n",
    "        phase: runutils.audioDataset(XY[0], XY[1], transform=transformCompose)\n",
    "        for phase, XY in\n",
    "        zip(['train', 'val', 'test'],\n",
    "            [[X_train, y_train], [X_val, y_val], [X_test, y_test]])\n",
    "    }\n",
    "\n",
    "    data_loader_params = {\n",
    "        'batch_size': config['batch_size'],\n",
    "        'shuffle': True,\n",
    "        'num_workers': 0\n",
    "    }\n",
    "\n",
    "    dataloaders = {\n",
    "        x: torch.utils.data.DataLoader(sound_datasets[x], **data_loader_params) \n",
    "        for x in ['train', 'val', 'test']\n",
    "    }\n",
    "\n",
    "    # this will change\n",
    "    h_w = [128, 938]\n",
    "    kernel_size = (3, 3)\n",
    "    output_shape = (runconfigs.CATEGORY_COUNT,)\n",
    "    model = modelarchs.singleconv1dModel(out_channels=config['CNN_filters_1'],\n",
    "                                         h_w=(1, h_w[0] * h_w[1]),\n",
    "                                         fc_1_size=config['fc_1_size'],\n",
    "                                         kernel_size=config['CNN_kernel_size'],\n",
    "                                         output_shape=output_shape)\n",
    "    model.float().to(config['device'])\n",
    "\n",
    "    # device is defined before\n",
    "\n",
    "    model.float().to(config['device'])  # Move model before creating optimizer\n",
    "    optimizer = torch.optim.AdamW( # type: ignore\n",
    "        model.parameters(),\n",
    "        #                                 weight_decay=config['weight_decay'],\n",
    "    )\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    # statHistory={'valLoss':[],'trainLoss':[],'trainAUC':[],'valAUC':[]}\n",
    "\n",
    "    metrics = {\n",
    "        'loss':\n",
    "            Loss(criterion),  # 'accuracy': Accuracy(),\n",
    "        #     'ROC_AUC': ROC_AUC(runutils.activated_output_transform),\n",
    "        'ROC_AUC':\n",
    "            megan.metrics.ROC_AUC_perClass(# type: ignore\n",
    "                megan.metrics.activated_output_transform), # type: ignore\n",
    "    }\n",
    "\n",
    "    return model, optimizer, dataloaders, metrics, criterion\n",
    "\n",
    "\n",
    "def run_exp(config):\n",
    "    loc_per_set = [[\n",
    "        '45', '38', '48', '39', '11', '44', '46', '17', '20', '50', '13', '25',\n",
    "        '21', '29', '19', '16', '24', '37'\n",
    "    ], ['18', '31', '34', '27', '32', '33', '47', '41', '22', '15'],\n",
    "                   ['30', '12', '14', '36', '40', '49']]\n",
    "    target_taxo = ['1.1.10', '1.1.7']\n",
    "    other_taxo = ['3.0.0', '2.1.0', '1.3.0', '1.1.8']\n",
    "\n",
    "    audio_dataset, _ = prepare_dataset()\n",
    "    audio_dataset = dataset_generate_samples(audio_dataset,\n",
    "                                             runconfigs.EXCERPT_LENGTH)\n",
    "\n",
    "    x_data, y_data, location_id_info = put_samples_into_array(\n",
    "        target_taxo, other_taxo, audio_dataset)\n",
    "\n",
    "    onehot_encoded = create_one_hot_vector(target_taxo, y_data)\n",
    "\n",
    "    X_train, X_test, X_val, y_train, y_test, y_val = split_train_test_val(\n",
    "        x_data, location_id_info, onehot_encoded, loc_per_set)\n",
    "\n",
    "    model, optimizer, dataloaders, metrics, criterion = prepare_run_inputs(\n",
    "        config, X_train, X_test, X_val, y_train, y_test, y_val)\n",
    "\n",
    "    print('ready ?')\n",
    "    checkpoints_dir = runconfigs.EXP_DIR / 'checkpoints'\n",
    "    checkpoints_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    runutils.run(model, dataloaders, optimizer, criterion, metrics,\n",
    "                 config['device'], config, runconfigs.PROJECT_NAME, checkpoints_dir = checkpoints_dir)\n",
    "\n",
    "\n",
    "# def main():\n",
    "    wandb_project_name = runconfigs.PROJECT_NAME\n",
    "    default_config = runconfigs.default_config\n",
    "    config = setup_config(default_config, wandb_project_name)\n",
    "    run_exp(config)\n",
    "#     # return audio_dataset, config \n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # do not upload model files\n",
    "#     os.environ['WANDB_IGNORE_GLOBS']='*.pt'\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_project_name = runconfigs.PROJECT_NAME\n",
    "default_config = runconfigs.default_config\n",
    "config = setup_config(default_config, wandb_project_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soundenv3",
   "language": "python",
   "name": "soundenv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
