{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make model smaller, \n",
    "#   increased size of batch size to 64 from 32\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir('/home/enis/projects/nna/src/nna/exp/megan/run-2/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "# import run\n",
    "# import nna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchaudio\n",
    "torchaudio.set_audio_backend(\"sox_io\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_per_set = [['45',\n",
    "  '38',\n",
    "  '48',\n",
    "  '39',\n",
    "  '11',\n",
    "  '44',\n",
    "  '46',\n",
    "  '17',\n",
    "  '20',\n",
    "  '50',\n",
    "  '13',\n",
    "  '25',\n",
    "  '21',\n",
    "  '29',\n",
    "  '19',\n",
    "  '16',\n",
    "  '24',\n",
    "  '37'],\n",
    " ['18', '31', '34', '27', '32', '33', '47', '41', '22', '15'],\n",
    " ['30', '12', '14', '36', '40', '49']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import runconfigs\n",
    "import wandb\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.contrib.metrics import ROC_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nna.exp import augmentations,\n",
    "from nna.exp import modelArchs,runutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(config=runconfigs.default_config, project=runconfigs.PROJECT_NAME)\n",
    "# config = wandb.config\n",
    "config = runconfigs.default_config\n",
    "# wandb.config.update(args) # adds all of the arguments as config variables\n",
    "config['batch_size'] = 64\n",
    "params = {\n",
    "    'batch_size': config['batch_size'],\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    f\"cuda:{config['device']}\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# labelsbyhumanpath = Path('/scratch/enis/data/nna/labeling/results/')\n",
    "# sourcePath = Path(\"/scratch/enis/data/nna/labeling/splits/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY_COUNT = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_logs       start_v3.1_negative-samples.ipynb  start_v3_split-loc.ipynb\n",
      "__pycache__    start_v3.2.1_smaller-model.ipynb   wandb\n",
      "runconfigs.py  start_v3.2.2_smaller-model.ipynb\n",
      "run.py\t       start_v3.2_smaller-model.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite/meganLabeledFiles_wlenV1.txt\n",
      "/scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite\n",
      "4 files are missing corresponding to excell entries\n",
      "'-> 5 number of samples are DELETED due to ignore_files and missing_audio_files'\n",
      "-> 415 samples DELETED because they are not in the excell\n",
      "\n",
      "-> 0 samples DELETED because they do not have the taxo info coming from excell\n",
      "\n",
      "-> classes that do not have enough data:\n",
      "[REMOVED!]\n",
      "['other-mammal'] 0.0\n",
      "['other-silence'] 20.0\n",
      "['unknown-sound'] 2.0\n",
      "['seabirds'] 1.0\n",
      "['canids'] 1.0\n",
      "['other-flare'] 11.0\n",
      "['other-rain'] 20.0\n",
      "\n",
      "-> classes that have enough data:\n",
      "['other-biophony'] 56.0\n",
      "['other-insect'] 140.0\n",
      "['other-bird'] 661.0\n",
      "['songbirds'] 392.0\n",
      "['duck-goose-swan'] 183.0\n",
      "['grouse-ptarmigan'] 59.0\n",
      "['other-anthrophony'] 66.0\n",
      "['other-aircraft'] 107.0\n",
      "['loons'] 29.0\n",
      "['other-car'] 37.0\n",
      "('-> 102 number of samples are deleted because their taxonomy category does '\n",
      " 'not have enough data.')\n",
      "-> classes that do not have enough data\n",
      "will be REMOVED!\n",
      "-> 97 number of samples are deleted because their length is not long enough.\n",
      "loading from cache at /scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite/files_as_np_filtered_v3_int16.pkl\n"
     ]
    }
   ],
   "source": [
    "## Load real data rather than mock \n",
    "    # MVP1: delete parts longer than 10 seconds\n",
    "import run\n",
    "audio_dataset,_ = run.prepare_dataset()\n",
    "\n",
    "output_file_path = '/scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite/files_as_np_filtered_v3_int16.pkl'\n",
    "audio_dataset.load_audio_files(output_file_path)\n",
    "audio_dataset.pick_channel_by_clipping()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sound_ins=next(iter(audio_dataset.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sound_ins[1].location_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sound_ins[1].taxo_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(832, 832)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sound_ins[1].taxo_code\n",
    "# classA = 1.1.7 #'duck-goose-swan']\n",
    "# classB = 0.2.0 # other-aircraft\n",
    "# 3.0.0 : 0.48, 0.26, 0.26, 46 # silence\n",
    "# 2.1.0 : 0.22, 0.56, 0.22, 18 # rain\n",
    "# 1.3.0 1.3.0 : 0.52, 0.4, 0.087, 161 # insect\n",
    "# 1.1.8 : 0.49, 0.19, 0.32, 88 # grouse-ptarmigan\n",
    "\n",
    "other_taxo = ['3.0.0','2.1.0','1.3.0','1.1.8']\n",
    "\n",
    "sampleTest= []\n",
    "y=[]\n",
    "location_id_info = []\n",
    "expected_len=10\n",
    "for sound_ins in audio_dataset.values():\n",
    "    if sound_ins.taxo_code in ['1.1.10','1.1.7'] + other_taxo:\n",
    "        y.append(sound_ins.taxo_code)\n",
    "        location_id_info.append(sound_ins.location_id)\n",
    "        if sound_ins.length<10:\n",
    "            tile_reps = (expected_len/(sound_ins.length)+1)\n",
    "            repeated_data = np.tile(sound_ins.data,int(tile_reps))\n",
    "            repeated_data = repeated_data[:expected_len*sound_ins.sr]\n",
    "            sampleTest.append(repeated_data)\n",
    "        else:\n",
    "            sampleTest.append(sound_ins.data[:expected_len*sound_ins.sr])\n",
    "\n",
    "len(sampleTest),len(y)\n",
    "\n",
    "# sampleTest=np.array(sampleTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(902, 0.5314091680814941)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "313+589,(46+18+161+88)/589 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "# define input string\n",
    "# define universe of possible input values\n",
    "alphabet = ['1.1.10','1.1.7']\n",
    "# define a mapping of chars to integers\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "# integer encode input data\n",
    "integer_encoded = [char_to_int.get(char,None) for char in y]\n",
    "# print(integer_encoded)\n",
    "# one hot encode\n",
    "onehot_encoded = list()\n",
    "for value in integer_encoded:\n",
    "\tletter = [0 for _ in range(len(alphabet))]\n",
    "\tif value is not None:\n",
    "\t\tletter[value] = 1\n",
    "\tonehot_encoded.append(letter)\n",
    "# print(onehot_encoded)\n",
    "# invert encoding\n",
    "inverted = int_to_char[argmax(onehot_encoded[0])]\n",
    "# print(inverted)\n",
    "onehot_encoded=np.array(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, X_val, y_train, y_test,y_val  = [],[],[],[],[],[]\n",
    "loc_id_train=[]\n",
    "loc_id_test=[]\n",
    "loc_id_valid=[]\n",
    "\n",
    "for sample,y_val_ins,loc_id in  zip(sampleTest,onehot_encoded,location_id_info):\n",
    "    if loc_id in loc_per_set[0]:\n",
    "        X_train.append(sample)\n",
    "        y_train.append(y_val_ins)\n",
    "        loc_id_train.append(loc_id)\n",
    "    elif loc_id in loc_per_set[1]:\n",
    "        X_test.append(sample)\n",
    "        y_test.append(y_val_ins)\n",
    "        loc_id_test.append(loc_id)\n",
    "    elif loc_id in loc_per_set[2]:\n",
    "        X_val.append(sample)\n",
    "        y_val.append(y_val_ins)\n",
    "        loc_id_valid.append(loc_id)\n",
    "    else:\n",
    "        print('error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'11',\n",
       "  '16',\n",
       "  '17',\n",
       "  '19',\n",
       "  '20',\n",
       "  '21',\n",
       "  '24',\n",
       "  '25',\n",
       "  '29',\n",
       "  '37',\n",
       "  '38',\n",
       "  '39',\n",
       "  '44',\n",
       "  '46',\n",
       "  '48',\n",
       "  '50'},\n",
       " {'15', '18', '22', '27', '31', '32', '33', '41', '47'},\n",
       " {'14', '30', '40', '49'})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(loc_id_train),set(loc_id_test),set(loc_id_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "832"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sampleTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,X_val=np.array(X_train),np.array(X_test),np.array(X_val)\n",
    "y_train,y_test,y_val=np.array(y_train),np.array(y_test),np.array(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#                 sampleTest, onehot_encoded, test_size=0.2, random_state=42)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#                 X_train, y_train, test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,X_val=torch.from_numpy(X_train).float(),torch.from_numpy(X_test).float(),torch.from_numpy(X_val).float()\n",
    "y_train,y_test,y_val=torch.from_numpy(y_train).float(),torch.from_numpy(y_test).float(),torch.from_numpy(y_val).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([459, 480000]),\n",
       " torch.Size([216, 480000]),\n",
       " torch.Size([157, 480000]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([459, 2]), torch.Size([216, 2]), torch.Size([157, 2]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,y_test.shape,y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_val[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train,X_test,X_val,y_train,y_test,y_val = load_raw_data('labelsbyhumanpath','sourcePath')\n",
    "# X_train,X_test,X_val,y_train,y_test,y_val = mock_raw_data(4,CATEGORY_COUNT)\n",
    "# X_train,X_test,X_val=torch.from_numpy(X_train).float(),torch.from_numpy(X_test).float(),torch.from_numpy(X_val).float()\n",
    "# y_train,y_test,y_val=torch.from_numpy(y_train).float(),torch.from_numpy(y_test).float(),torch.from_numpy(y_val).float()\n",
    "\n",
    "# # labelsbyhumanpath = Path('/scratch/enis/data/nna/labeling/results/')\n",
    "# # with open(labelsbyhumanpath/\"np_array_Ymatrix.npy\", 'rb') as f:\n",
    "# #     y_true = np.load(f)\n",
    "\n",
    "# Counter(np.argmax(y_train,axis=1).tolist()),Counter(np.argmax(y_val,axis=1).tolist()),Counter(np.argmax(y_test,axis=1).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train2=np.interp(X_train, (X_train.min(), X_train.max()), (-32768 , 32767))\n",
    "# torch.from_numpy(X_train2).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaple_index=10\n",
    "# X_train[smaple_index,:],y_train[smaple_index,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply(torch.ones((1,2)),torch.ones((1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __init__(self, maxMelLen, sampling_rate):\n",
    "        # sr = 44100 etc\n",
    "        self.maxMelLen = maxMelLen\n",
    "        self.sampling_rate = sampling_rate\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        x, y = sample\n",
    "        #https://github.com/PCerles/audio/blob/3803d0b27a4e13efa760227ef6c71d0f3753aa98/test/test_transforms.py#L262\n",
    "        #librosa defaults\n",
    "        n_fft = 2048\n",
    "        hop_length = 512\n",
    "        power = 2.0\n",
    "        n_mels = 128\n",
    "        n_mfcc = 40\n",
    "        # htk is false in librosa, no setting in torchaudio -?\n",
    "        # norm is 1 in librosa, no setting in torchaudio -?\n",
    "        melspect_transform = torchaudio.transforms.MelSpectrogram(sample_rate=self.sampling_rate, window_fn=torch.hann_window,\n",
    "                                                                  hop_length=hop_length, n_mels=n_mels, n_fft=n_fft)\n",
    "\n",
    "    \n",
    "        db_transform = torchaudio.transforms.AmplitudeToDB(\"power\", 80.)\n",
    "        mel = melspect_transform(x.reshape(-1))\n",
    "        an_x = db_transform(mel)\n",
    "        #librosa version\n",
    "#         mel = librosa.feature.melspectrogram(y=x.reshape(-1),\n",
    "#                                              sr=self.sampling_rate)\n",
    "#         an_x = librosa.power_to_db(mel, ref=np.max)\n",
    "#         an_x = an_x.astype(\"float32\")\n",
    "#         y = y.astype('float32')\n",
    "#         print(an_x.shape)\n",
    "        an_x = an_x[:, :self.maxMelLen]\n",
    "        # 2-d conv\n",
    "#         x = an_x.reshape(1, *an_x.shape[:])\n",
    "        # 1-d conv\n",
    "        x = an_x.reshape(1, an_x.shape[0]*an_x.shape[1])\n",
    "\n",
    "        \n",
    "        return x,y\n",
    "\n",
    "# #test\n",
    "# maxMelLen_test = 850\n",
    "# SAMPLING_RATE_test = 48000\n",
    "# sample_len_seconds = 10\n",
    "# # to_tensor works on single sample\n",
    "# sample_count = 1\n",
    "# xx_test = torch.ones((sample_count,SAMPLING_RATE_test*sample_len_seconds))\n",
    "# y_values = torch.ones(sample_count)\n",
    "# \n",
    "# toTensor = ToTensor(maxMelLen_test,SAMPLING_RATE_test)\n",
    "# x_out,y_out=toTensor((xx_test,y_values))\n",
    "# x_out.shape,y_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([459, 480000])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train,X_test,X_val,y_train,y_test,y_val\n",
    "X_train[:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toTensor = ToTensor(maxMelLen_test,SAMPLING_RATE_test)\n",
    "# x_out2,y_out=toTensor((X_train[1:2,:],y_train))\n",
    "# x_out.shape,y_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.mean(x_out[0]),torch.mean(x_out2[0])\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pitch = augmentations.pitch_shift_n_stepsClass(\n",
    "#     runconfigs.SAMPLING_RATE, config['pitch_shift_n_steps'])\n",
    "# noise = augmentations.addNoiseClass(config['noise_factor'])\n",
    "# strech = augmentations.time_stretchClass(runconfigs.SAMPLING_RATE*runconfigs.EXCERPT_LENGTH,\n",
    "#                                             config['time_stretch_factor'],\n",
    "#                                             isRandom=True)\n",
    "# shift = augmentations.shiftClass(config['roll_rate'], isRandom=True)\n",
    "maxMelLen = 938 # old 850\n",
    "# toTensor = augmentations.ToTensor(maxMelLen,runconfigs.SAMPLING_RATE)\n",
    "toTensor = ToTensor(maxMelLen,runconfigs.SAMPLING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.metrics import EpochMetric\n",
    "\n",
    "\n",
    "def roc_auc_perClass_compute_fn(y_preds, y_targets):\n",
    "    try:\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "    except ImportError:\n",
    "        raise RuntimeError(\n",
    "            \"This contrib module requires sklearn to be installed.\")\n",
    "\n",
    "    y_true = y_targets.numpy()\n",
    "    y_pred = y_preds.numpy()\n",
    "#     print(y_pred,y_true)\n",
    "#     res = []\n",
    "#     for y_true_perClass_Index in y_true.shape[1]:\n",
    "#         res.append(\n",
    "#             roc_auc_score(y_true[:, y_true_perClass_Index],\n",
    "#                           y_pred[:, y_true_perClass_Index]))\n",
    "    res = roc_auc_score(y_true, y_pred, average=None)\n",
    "    return res\n",
    "\n",
    "\n",
    "#[docs]\n",
    "class ROC_AUC_perClass(EpochMetric):\n",
    "    \"\"\"Computes Area Under the Receiver Operating Characteristic Curve (ROC AUC)\n",
    "  accumulating predictions and the ground-truth during an epoch and applying\n",
    "  `sklearn.metrics.roc_auc_score <http://scikit-learn.org/stable/modules/generated/\n",
    "  sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score>`_ .\n",
    "\n",
    "  Args:\n",
    "      output_transform (callable, optional): a callable that is used to transform the\n",
    "          :class:`~ignite.engine.engine.Engine`'s ``process_function``'s output into the\n",
    "          form expected by the metric. This can be useful if, for example, you have a multi-output model and\n",
    "          you want to compute the metric with respect to one of the outputs.\n",
    "      check_compute_fn (bool): Optional default False. If True, `roc_curve\n",
    "          <http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#\n",
    "          sklearn.metrics.roc_auc_score>`_ is run on the first batch of data to ensure there are\n",
    "          no issues. User will be warned in case there are any issues computing the function.\n",
    "\n",
    "  ROC_AUC expects y to be comprised of 0's and 1's. y_pred must either be probability estimates or confidence\n",
    "  values. To apply an activation to y_pred, use output_transform as shown below:\n",
    "\n",
    "  .. code-block:: python\n",
    "\n",
    "      def activated_output_transform(output):\n",
    "          y_pred, y = output\n",
    "          y_pred = torch.sigmoid(y_pred)\n",
    "          return y_pred, y\n",
    "\n",
    "      roc_auc = ROC_AUC(activated_output_transform)\n",
    "\n",
    "  \"\"\"\n",
    "    def __init__(self,\n",
    "                 output_transform=lambda x: x,\n",
    "                 check_compute_fn: bool = False):\n",
    "#         print(output_transform)\n",
    "        super(ROC_AUC_perClass,\n",
    "              self).__init__(roc_auc_perClass_compute_fn,\n",
    "                             output_transform=output_transform,\n",
    "                             check_compute_fn=check_compute_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_output_shape(h_w, kernel_size=1, stride=1, pad=0, dilation=1):\n",
    "    \"\"\"\n",
    "  Utility function for computing output of convolutions\n",
    "  takes a tuple of (h,w) and returns a tuple of (h,w)\n",
    "  \"\"\"\n",
    "    from math import floor\n",
    "    if type(kernel_size) is not tuple:\n",
    "        kernel_size = (kernel_size, kernel_size)\n",
    "    h = floor(((h_w[0] + (2 * pad) - (dilation *\n",
    "                                      (kernel_size[0] - 1)) - 1) / stride) + 1)\n",
    "    w = floor(((h_w[1] + (2 * pad) - (dilation *\n",
    "                                      (kernel_size[1] - 1)) - 1) / stride) + 1)\n",
    "    return h, w\n",
    "\n",
    "# mel.shape,an_x.shape,X_train.shape\n",
    "class testModel(nn.Module):\n",
    "    '''A simple model for testing by overfitting.\n",
    "    '''\n",
    "    def __init__(self, out_channels, h_w, kernel_size, FLAT=False,output_shape=(10,)):\n",
    "        # h_w: height will be always one since we use 1d convolution \n",
    "        super(testModel, self).__init__()\n",
    "        self.out_channels = out_channels\n",
    "        #### CONV\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, # depth of image == depth of filters\n",
    "                               out_channels=self.out_channels, # number of filters \n",
    "                               kernel_size=kernel_size, # size of the filters/kernels\n",
    "                               padding=1)\n",
    "\n",
    "        self.conv1_shape = conv_output_shape(h_w, kernel_size=kernel_size, stride=1, pad=1, dilation=1)\n",
    "        # conv is 1d\n",
    "        self.conv1_shape = (1,self.conv1_shape[1])\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.out_channels * self.conv1_shape[0] *self.conv1_shape[1], 48)  # 100\n",
    "\n",
    "        self.fc2 = nn.Linear(48,output_shape[0])\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         x = x.reshape(1,)\n",
    "#         print(x.shape) #  50,1,108800 (850*128)\n",
    "        x = F.relu(self.conv1(x))\n",
    "#         x = self.pool(x)\n",
    "        # x = self.drop(x)\n",
    "#         print(x.shape)# 58, 2, 108801\n",
    "#         print(self.conv1_shape)\n",
    "#         print(x.shape)\n",
    "        x = x.view(-1, self.out_channels * self.conv1_shape[0] *self.conv1_shape[1])\n",
    "        # batch_norm is missing\n",
    "        x = F.relu((self.fc1(x)))\n",
    "        x = (self.fc2(x))\n",
    "\n",
    "#         x = self.drop(x)\n",
    "\n",
    "#         x = self.fc4(x)\n",
    "#         x = torch.sigmoid(x)\n",
    "#                 x = F.log_softmax(x,dim=1)\n",
    "        return x\n",
    "\n",
    "# test\n",
    "# input_shape=(1,(938*128))\n",
    "# output_shape=(10,)\n",
    "# testModel_ins=adam(out_channels=2,h_w=input_shape,kernel_size=2,output_shape=output_shape)\n",
    "# # a.conv1.weight\n",
    "# a_out=testModel_ins(torch.ones((3,1,input_shape[1])))\n",
    "\n",
    "# a_out_correct=torch.zeros(a_out.shape)\n",
    "# a_out_correct[0][:]=1\n",
    "# a_out_correct\n",
    "# a_out.detach().numpy()\n",
    "\n",
    "# torch.exp(a_out),a_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for y_true_perClass_Index in a_out_correct.shape[1]:\n",
    "#     print(y_true_perClass_Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ignite.contrib.metrics import ROC_AUC\n",
    "# from nna.exp.metrics import ROC_AUC_perClass\n",
    "def activated_output_transform(output):\n",
    "    y_pred, y = output\n",
    "#     y_pred = torch.exp(y_pred)\n",
    "    return y_pred, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asd=ROC_AUC_perClass(activated_output_transform)\n",
    "# asd.update((a_out,a_out_correct))\n",
    "# asd.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformCompose = transforms.Compose([\n",
    "#     pitch,\n",
    "#     strech,\n",
    "#     shift,\n",
    "#     noise,\n",
    "    toTensor,\n",
    "])\n",
    "\n",
    "\n",
    "sound_datasets = {\n",
    "    phase: runutils.audioDataset(XY[0], XY[1], transform=transformCompose)\n",
    "    for phase, XY in\n",
    "    zip(['train', 'val', 'test'],\n",
    "        [[X_train, y_train], [X_val, y_val], [X_test, y_test]])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(sound_datasets[x], **params)\n",
    "    for x in ['train', 'val', 'test']\n",
    "}\n",
    "\n",
    "# this will change\n",
    "h_w = [128, 938]\n",
    "kernel_size = (4, 4)\n",
    "# if config['CNNLayer_count'] == 1:\n",
    "#     model = modelArchs.NetCNN1(config['CNN_filters_1'], h_w,\n",
    "#                                 kernel_size).float().to(device)\n",
    "\n",
    "# if config['CNNLayer_count'] == 2:\n",
    "#     model = modelArchs.NetCNN2(config['CNN_filters_1'], config.CNN_filters_2,\n",
    "#                                 h_w, kernel_size,\n",
    "#                                 kernel_size).float().to(device)\n",
    "\n",
    "#simpler model\n",
    "\n",
    "output_shape=(CATEGORY_COUNT,)\n",
    "model = testModel(out_channels=4,h_w=(1,h_w[0]*h_w[1]),kernel_size=kernel_size[0]*kernel_size[0],output_shape=output_shape)\n",
    "model.float().to(device)\n",
    "\n",
    "# device is defined before\n",
    "\n",
    "model.float().to(device)  # Move model before creating optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "#                                 weight_decay=config['weight_decay'],\n",
    "                             )\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# statHistory={'valLoss':[],'trainLoss':[],'trainAUC':[],'valAUC':[]}\n",
    "\n",
    "metrics = {\n",
    "    'loss': Loss(criterion),  # 'accuracy': Accuracy(),\n",
    "#     'ROC_AUC': ROC_AUC(runutils.activated_output_transform),\n",
    "    'ROC_AUC': ROC_AUC_perClass(activated_output_transform),\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "testModel(\n",
       "  (conv1): Conv1d(1, 4, kernel_size=(16,), stride=(1,), padding=(1,))\n",
       "  (fc1): Linear(in_features=480204, out_features=48, bias=True)\n",
       "  (fc2): Linear(in_features=48, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[ 0.1911,  0.2075, -0.0586,  0.2297, -0.0548,  0.0504, -0.1217,\n",
       "           0.1468,  0.2204, -0.1834,  0.2173,  0.0468,  0.1847,  0.0339,\n",
       "           0.1205, -0.0353]],\n",
       "\n",
       "        [[ 0.1927,  0.0370, -0.1167,  0.0637, -0.1152, -0.0293, -0.1015,\n",
       "           0.1658, -0.1973, -0.1153, -0.0706, -0.1503,  0.0236, -0.2469,\n",
       "           0.2258, -0.2124]],\n",
       "\n",
       "        [[ 0.1930,  0.0416, -0.0812,  0.1545,  0.0390,  0.2020,  0.0273,\n",
       "          -0.0788,  0.0672, -0.0678,  0.1052,  0.2232,  0.1445, -0.1093,\n",
       "           0.1443,  0.0447]],\n",
       "\n",
       "        [[ 0.1270, -0.1524, -0.2475, -0.0966, -0.1918,  0.2051,  0.0720,\n",
       "           0.1036,  0.0791, -0.0043,  0.1957, -0.1776,  0.0157, -0.1706,\n",
       "           0.0771, -0.0861]]], device='cuda:1', requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1d(1, 4, kernel_size=(16,), stride=(1,), padding=(1,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-8.6064e-04, -8.6070e-04,  1.2980e-03,  ..., -7.7689e-05,\n",
       "         -1.4131e-03, -1.3689e-03],\n",
       "        [-1.1643e-03, -3.6086e-04,  3.0062e-04,  ..., -1.3227e-03,\n",
       "          1.1772e-03, -5.4904e-04],\n",
       "        [ 3.4021e-04, -3.7891e-04,  3.4955e-04,  ...,  1.3022e-03,\n",
       "         -8.8017e-04,  2.2887e-04],\n",
       "        ...,\n",
       "        [ 1.1903e-03,  9.6187e-04,  5.3055e-04,  ..., -3.2026e-04,\n",
       "          1.0719e-04, -2.6431e-04],\n",
       "        [-6.8795e-04, -4.0943e-04,  4.7676e-04,  ..., -9.4581e-05,\n",
       "         -2.3082e-04,  9.6146e-04],\n",
       "        [ 1.1462e-03,  3.8416e-04,  9.1008e-05,  ..., -4.8859e-04,\n",
       "         -6.6640e-04, -1.1995e-03]], device='cuda:1', requires_grad=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33menisberk\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.15 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">charmed-durian-159</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/enisberk/megan\" target=\"_blank\">https://wandb.ai/enisberk/megan</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/enisberk/megan/runs/ltnbctcy\" target=\"_blank\">https://wandb.ai/enisberk/megan/runs/ltnbctcy</a><br/>\n",
       "                Run data is saved locally in <code>/home/enis/projects/nna/src/nna/exp/megan/run-2/wandb/run-20210126_075806-ltnbctcy</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 07:58:12,778 Trainer INFO: Engine run starting with max_epochs=2000.\n",
      "/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370141920/work/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
      "  normalized, onesided, return_complex)\n",
      "/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370141920/work/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
      "  normalized, onesided, return_complex)\n",
      "2021-01-26 07:59:33,675 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:00:52,278 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:19\n",
      "2021-01-26 08:00:52,282 Train Evaluator INFO: Engine run complete. Time taken: 00:01:19\n",
      "2021-01-26 08:00:52,283 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:01:19,485 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:27\n",
      "2021-01-26 08:01:21,320 Val Evaluator INFO: Engine run complete. Time taken: 00:00:29\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 1 < 8; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 08:01:21,334 Trainer INFO: Epoch[1] Complete. Time taken: 00:03:09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1130.9338591664964\n",
      "val loss 2354.067175992735\n",
      "validation roc auc [0.35754561 0.39755352] 1\n",
      "train roc auc [0.51338914 0.45638026] 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 08:02:38,384 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:03:55,443 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:17\n",
      "2021-01-26 08:03:55,446 Train Evaluator INFO: Engine run complete. Time taken: 00:01:17\n",
      "2021-01-26 08:03:55,447 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:04:22,165 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:27\n",
      "2021-01-26 08:04:23,951 Val Evaluator INFO: Engine run complete. Time taken: 00:00:29\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 2 < 16; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 08:04:23,958 Trainer INFO: Epoch[2] Complete. Time taken: 00:03:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 554.5150081327018\n",
      "val loss 631.0020903569118\n",
      "validation roc auc [0.66053068 0.40022936] 2\n",
      "train roc auc [0.49361289 0.45833677] 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 08:05:36,855 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:06:54,130 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:17\n",
      "2021-01-26 08:06:54,132 Train Evaluator INFO: Engine run complete. Time taken: 00:01:17\n",
      "2021-01-26 08:06:54,133 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:07:20,469 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:26\n",
      "2021-01-26 08:07:22,592 Val Evaluator INFO: Engine run complete. Time taken: 00:00:28\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3 < 24; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 08:07:22,601 Trainer INFO: Epoch[3] Complete. Time taken: 00:02:59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 292.02569959054586\n",
      "val loss 389.2411603988356\n",
      "validation roc auc [0.38026534 0.65042049] 3\n",
      "train roc auc [0.52344587 0.56956916] 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 08:08:38,344 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:09:52,875 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:15\n",
      "2021-01-26 08:09:52,877 Train Evaluator INFO: Engine run complete. Time taken: 00:01:15\n",
      "2021-01-26 08:09:52,879 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:10:19,318 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:26\n",
      "2021-01-26 08:10:21,563 Val Evaluator INFO: Engine run complete. Time taken: 00:00:29\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 4 < 32; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 08:10:21,574 Trainer INFO: Epoch[4] Complete. Time taken: 00:02:59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 42.440158835683256\n",
      "val loss 81.29055076647715\n",
      "validation roc auc [0.74344942 0.41093272] 4\n",
      "train roc auc [0.67193637 0.46280583] 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 08:11:38,066 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:12:53,618 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:16\n",
      "2021-01-26 08:12:53,620 Train Evaluator INFO: Engine run complete. Time taken: 00:01:16\n",
      "2021-01-26 08:12:53,622 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:13:19,824 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:26\n",
      "2021-01-26 08:13:21,838 Val Evaluator INFO: Engine run complete. Time taken: 00:00:28\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 5 < 40; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 08:13:21,847 Trainer INFO: Epoch[5] Complete. Time taken: 00:03:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 85.38069922420195\n",
      "val loss 143.48710272722184\n",
      "validation roc auc [0.48490879 0.41571101] 5\n",
      "train roc auc [0.61169516 0.46461817] 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 08:14:30,913 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:15:44,937 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:14\n",
      "2021-01-26 08:15:44,941 Train Evaluator INFO: Engine run complete. Time taken: 00:01:14\n",
      "2021-01-26 08:15:44,943 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:16:10,615 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:26\n",
      "2021-01-26 08:16:12,722 Val Evaluator INFO: Engine run complete. Time taken: 00:00:28\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 6 < 48; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 08:16:12,734 Trainer INFO: Epoch[6] Complete. Time taken: 00:02:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 23.909922045040755\n",
      "val loss 35.50274772401069\n",
      "validation roc auc [0.53134328 0.50860092] 6\n",
      "train roc auc [0.70621256 0.6194909 ] 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 08:17:29,978 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:18:47,334 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:17\n",
      "2021-01-26 08:18:47,336 Train Evaluator INFO: Engine run complete. Time taken: 00:01:17\n",
      "2021-01-26 08:18:47,338 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:19:13,593 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:26\n",
      "2021-01-26 08:19:15,541 Val Evaluator INFO: Engine run complete. Time taken: 00:00:28\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 7 < 56; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 08:19:15,549 Trainer INFO: Epoch[7] Complete. Time taken: 00:03:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 25.6585296140517\n",
      "val loss 21.342788076704476\n",
      "validation roc auc [0.65240464 0.20623089] 7\n",
      "train roc auc [0.69064149 0.40752945] 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 08:20:31,252 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:21:48,540 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:17\n",
      "2021-01-26 08:21:48,542 Train Evaluator INFO: Engine run complete. Time taken: 00:01:17\n",
      "2021-01-26 08:21:48,543 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:22:15,191 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:27\n",
      "2021-01-26 08:22:17,476 Val Evaluator INFO: Engine run complete. Time taken: 00:00:29\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 8 < 64; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 08:22:17,497 Trainer INFO: Epoch[8] Complete. Time taken: 00:03:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 4.26357067618235\n",
      "val loss 6.192138267930146\n",
      "validation roc auc [0.54477612 0.37614679] 8\n",
      "train roc auc [0.78059666 0.37564874] 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 08:23:34,469 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:24:51,500 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:17\n",
      "2021-01-26 08:24:51,503 Train Evaluator INFO: Engine run complete. Time taken: 00:01:17\n",
      "2021-01-26 08:24:51,503 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:25:16,040 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:25\n",
      "2021-01-26 08:25:18,318 Val Evaluator INFO: Engine run complete. Time taken: 00:00:27\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 9 < 72; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 08:25:18,326 Trainer INFO: Epoch[9] Complete. Time taken: 00:03:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 23.24710481514858\n",
      "val loss 30.436920032379735\n",
      "validation roc auc [0.55107794 0.46062691] 9\n",
      "train roc auc [0.8182846  0.34104951] 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 08:26:35,457 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:27:51,331 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:16\n",
      "2021-01-26 08:27:51,334 Train Evaluator INFO: Engine run complete. Time taken: 00:01:16\n",
      "2021-01-26 08:27:51,335 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:28:16,483 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:25\n",
      "2021-01-26 08:28:18,724 Val Evaluator INFO: Engine run complete. Time taken: 00:00:27\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 10 < 80; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 08:28:18,733 Trainer INFO: Epoch[10] Complete. Time taken: 00:03:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 14.896045211093877\n",
      "val loss 14.532115699379307\n",
      "validation roc auc [0.65588723 0.17316514] 10\n",
      "train roc auc [0.86196295 0.3111047 ] 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 08:29:28,435 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:30:44,202 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:16\n",
      "2021-01-26 08:30:44,205 Train Evaluator INFO: Engine run complete. Time taken: 00:01:16\n",
      "2021-01-26 08:30:44,207 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:31:10,649 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:26\n",
      "2021-01-26 08:31:12,810 Val Evaluator INFO: Engine run complete. Time taken: 00:00:29\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 11 < 88; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 08:31:12,826 Trainer INFO: Epoch[11] Complete. Time taken: 00:02:54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 24.641562222915017\n",
      "val loss 36.14072763236465\n",
      "validation roc auc [0.56533997 0.21253823] 11\n",
      "train roc auc [0.87412227 0.27708213] 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 08:32:28,815 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:33:43,297 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:14\n",
      "2021-01-26 08:33:43,301 Train Evaluator INFO: Engine run complete. Time taken: 00:01:14\n",
      "2021-01-26 08:33:43,303 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:34:08,715 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:25\n",
      "2021-01-26 08:34:10,793 Val Evaluator INFO: Engine run complete. Time taken: 00:00:27\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 12 < 96; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 08:34:10,802 Trainer INFO: Epoch[12] Complete. Time taken: 00:02:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 28.682247857902045\n",
      "val loss 41.190926934503445\n",
      "validation roc auc [0.49983416 0.48509174] 12\n",
      "train roc auc [0.6825485  0.57055771] 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 08:35:28,222 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:36:47,466 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:19\n",
      "2021-01-26 08:36:47,469 Train Evaluator INFO: Engine run complete. Time taken: 00:01:19\n",
      "2021-01-26 08:36:47,471 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:37:13,812 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:26\n",
      "2021-01-26 08:37:15,975 Val Evaluator INFO: Engine run complete. Time taken: 00:00:29\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 13 < 104; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 08:37:15,984 Trainer INFO: Epoch[13] Complete. Time taken: 00:03:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.6878151488459967\n",
      "val loss 0.6863514803777075\n",
      "validation roc auc [0.50555556 0.50458716] 13\n",
      "train roc auc [0.5 0.5] 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 08:38:34,810 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:39:52,567 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:18\n",
      "2021-01-26 08:39:52,570 Train Evaluator INFO: Engine run complete. Time taken: 00:01:18\n",
      "2021-01-26 08:39:52,571 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:40:19,452 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:27\n",
      "2021-01-26 08:40:21,673 Val Evaluator INFO: Engine run complete. Time taken: 00:00:29\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 14 < 112; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 08:40:21,686 Trainer INFO: Epoch[14] Complete. Time taken: 00:03:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.6866800718837314\n",
      "val loss 0.6857937137792065\n",
      "validation roc auc [0.50555556 0.50458716] 14\n",
      "train roc auc [0.5 0.5] 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 08:41:35,963 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:42:46,898 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:11\n",
      "2021-01-26 08:42:46,900 Train Evaluator INFO: Engine run complete. Time taken: 00:01:11\n",
      "2021-01-26 08:42:46,902 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:43:13,255 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:26\n",
      "2021-01-26 08:43:15,557 Val Evaluator INFO: Engine run complete. Time taken: 00:00:29\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 15 < 120; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 08:43:15,568 Trainer INFO: Epoch[15] Complete. Time taken: 00:02:54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.6853231592895159\n",
      "val loss 0.6851787889838978\n",
      "validation roc auc [0.50555556 0.50458716] 15\n",
      "train roc auc [0.5 0.5] 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 08:44:29,526 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:45:45,451 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:16\n",
      "2021-01-26 08:45:45,454 Train Evaluator INFO: Engine run complete. Time taken: 00:01:16\n",
      "2021-01-26 08:45:45,455 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:46:12,075 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:27\n",
      "2021-01-26 08:46:14,141 Val Evaluator INFO: Engine run complete. Time taken: 00:00:29\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 16 < 128; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 08:46:14,159 Trainer INFO: Epoch[16] Complete. Time taken: 00:02:59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.6837998420844151\n",
      "val loss 0.6845265262445827\n",
      "validation roc auc [0.50555556 0.50458716] 16\n",
      "train roc auc [0.5 0.5] 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 08:47:30,638 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:48:46,538 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:16\n",
      "2021-01-26 08:48:46,540 Train Evaluator INFO: Engine run complete. Time taken: 00:01:16\n",
      "2021-01-26 08:48:46,541 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:49:12,695 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:26\n",
      "2021-01-26 08:49:14,884 Val Evaluator INFO: Engine run complete. Time taken: 00:00:28\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 17 < 136; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 08:49:14,913 Trainer INFO: Epoch[17] Complete. Time taken: 00:03:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.6822134995252738\n",
      "val loss 0.6838684826140191\n",
      "validation roc auc [0.50555556 0.50458716] 17\n",
      "train roc auc [0.5 0.5] 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 08:50:31,401 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:51:50,384 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:19\n",
      "2021-01-26 08:51:50,389 Train Evaluator INFO: Engine run complete. Time taken: 00:01:19\n",
      "2021-01-26 08:51:50,390 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:52:17,581 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:27\n",
      "2021-01-26 08:52:17,584 Val Evaluator INFO: Engine run complete. Time taken: 00:00:27\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 18 < 144; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 08:52:17,593 Trainer INFO: Epoch[18] Complete. Time taken: 00:03:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.6807228652740096\n",
      "val loss 0.6832496174581492\n",
      "validation roc auc [0.50555556 0.50458716] 18\n",
      "train roc auc [0.5 0.5] 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 08:53:33,114 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:54:52,483 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:19\n",
      "2021-01-26 08:54:52,486 Train Evaluator INFO: Engine run complete. Time taken: 00:01:19\n",
      "2021-01-26 08:54:52,487 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:55:19,002 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:27\n",
      "2021-01-26 08:55:19,006 Val Evaluator INFO: Engine run complete. Time taken: 00:00:27\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 19 < 152; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 08:55:19,015 Trainer INFO: Epoch[19] Complete. Time taken: 00:03:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.6791712224873063\n",
      "val loss 0.6826195451104717\n",
      "validation roc auc [0.50555556 0.50458716] 19\n",
      "train roc auc [0.5 0.5] 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 08:56:38,295 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:57:56,997 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:19\n",
      "2021-01-26 08:57:56,999 Train Evaluator INFO: Engine run complete. Time taken: 00:01:19\n",
      "2021-01-26 08:57:57,003 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 08:58:23,483 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:26\n",
      "2021-01-26 08:58:23,486 Val Evaluator INFO: Engine run complete. Time taken: 00:00:26\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 20 < 160; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 08:58:23,495 Trainer INFO: Epoch[20] Complete. Time taken: 00:03:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.6776353263647208\n",
      "val loss 0.6820036260185728\n",
      "validation roc auc [0.50555556 0.50458716] 20\n",
      "train roc auc [0.5 0.5] 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 08:59:41,677 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:00:58,673 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:17\n",
      "2021-01-26 09:00:58,676 Train Evaluator INFO: Engine run complete. Time taken: 00:01:17\n",
      "2021-01-26 09:00:58,676 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:01:22,352 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:24\n",
      "2021-01-26 09:01:22,355 Val Evaluator INFO: Engine run complete. Time taken: 00:00:24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 21 < 168; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:01:22,367 Trainer INFO: Epoch[21] Complete. Time taken: 00:02:59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.6761756397799988\n",
      "val loss 0.6814196834898298\n",
      "validation roc auc [0.50555556 0.50458716] 21\n",
      "train roc auc [0.5 0.5] 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:02:40,008 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:03:57,053 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:17\n",
      "2021-01-26 09:03:57,056 Train Evaluator INFO: Engine run complete. Time taken: 00:01:17\n",
      "2021-01-26 09:03:57,057 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:04:22,228 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:25\n",
      "2021-01-26 09:04:22,231 Val Evaluator INFO: Engine run complete. Time taken: 00:00:25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 22 < 176; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:04:22,239 Trainer INFO: Epoch[22] Complete. Time taken: 00:02:60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.6746709085757436\n",
      "val loss 0.6808439599480599\n",
      "validation roc auc [0.50555556 0.50458716] 22\n",
      "train roc auc [0.5 0.5] 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:05:41,793 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:06:59,702 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:18\n",
      "2021-01-26 09:06:59,705 Train Evaluator INFO: Engine run complete. Time taken: 00:01:18\n",
      "2021-01-26 09:06:59,706 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:07:26,159 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:26\n",
      "2021-01-26 09:07:26,160 Val Evaluator INFO: Engine run complete. Time taken: 00:00:26\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 23 < 184; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:07:26,168 Trainer INFO: Epoch[23] Complete. Time taken: 00:03:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.6731741868592556\n",
      "val loss 0.6802789257590178\n",
      "validation roc auc [0.50555556 0.50458716] 23\n",
      "train roc auc [0.5 0.5] 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:08:45,105 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:10:03,255 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:18\n",
      "2021-01-26 09:10:03,259 Train Evaluator INFO: Engine run complete. Time taken: 00:01:18\n",
      "2021-01-26 09:10:03,260 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:10:30,084 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:27\n",
      "2021-01-26 09:10:30,087 Val Evaluator INFO: Engine run complete. Time taken: 00:00:27\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 24 < 192; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:10:30,096 Trainer INFO: Epoch[24] Complete. Time taken: 00:03:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.6716590560079919\n",
      "val loss 0.6797049258165299\n",
      "validation roc auc [0.50555556 0.50458716] 24\n",
      "train roc auc [0.5 0.5] 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:11:47,737 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:13:06,671 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:19\n",
      "2021-01-26 09:13:06,674 Train Evaluator INFO: Engine run complete. Time taken: 00:01:19\n",
      "2021-01-26 09:13:06,675 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:13:32,897 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:26\n",
      "2021-01-26 09:13:32,898 Val Evaluator INFO: Engine run complete. Time taken: 00:00:26\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 25 < 200; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:13:32,908 Trainer INFO: Epoch[25] Complete. Time taken: 00:03:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.6702322894971096\n",
      "val loss 0.6791632543703553\n",
      "validation roc auc [0.50555556 0.50458716] 25\n",
      "train roc auc [0.5 0.5] 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:14:49,217 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:16:05,215 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:16\n",
      "2021-01-26 09:16:05,217 Train Evaluator INFO: Engine run complete. Time taken: 00:01:16\n",
      "2021-01-26 09:16:05,219 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:16:32,206 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:27\n",
      "2021-01-26 09:16:32,209 Val Evaluator INFO: Engine run complete. Time taken: 00:00:27\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 26 < 208; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:16:32,217 Trainer INFO: Epoch[26] Complete. Time taken: 00:02:59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.6688101356585301\n",
      "val loss 0.6786314932404051\n",
      "validation roc auc [0.50555556 0.50458716] 26\n",
      "train roc auc [0.5 0.5] 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:17:49,245 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:19:06,742 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:17\n",
      "2021-01-26 09:19:06,745 Train Evaluator INFO: Engine run complete. Time taken: 00:01:17\n",
      "2021-01-26 09:19:06,746 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:19:33,506 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:27\n",
      "2021-01-26 09:19:33,509 Val Evaluator INFO: Engine run complete. Time taken: 00:00:27\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 27 < 216; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:19:33,518 Trainer INFO: Epoch[27] Complete. Time taken: 00:03:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.6674504281388908\n",
      "val loss 0.6781189756788266\n",
      "validation roc auc [0.50555556 0.50458716] 27\n",
      "train roc auc [0.5 0.5] 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:20:50,421 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:22:08,319 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:18\n",
      "2021-01-26 09:22:08,322 Train Evaluator INFO: Engine run complete. Time taken: 00:01:18\n",
      "2021-01-26 09:22:08,323 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:22:35,145 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:27\n",
      "2021-01-26 09:22:35,148 Val Evaluator INFO: Engine run complete. Time taken: 00:00:27\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 28 < 224; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:22:35,157 Trainer INFO: Epoch[28] Complete. Time taken: 00:03:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.6660929567673627\n",
      "val loss 0.6776294594357728\n",
      "validation roc auc [0.50555556 0.50458716] 28\n",
      "train roc auc [0.5 0.5] 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:23:53,520 Train Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:25:10,865 Train Evaluator INFO: Epoch[1] Complete. Time taken: 00:01:17\n",
      "2021-01-26 09:25:10,868 Train Evaluator INFO: Engine run complete. Time taken: 00:01:17\n",
      "2021-01-26 09:25:10,869 Val Evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-01-26 09:25:37,605 Val Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:27\n",
      "2021-01-26 09:25:37,608 Val Evaluator INFO: Engine run complete. Time taken: 00:00:27\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 29 < 232; dropping {'lr/group_0': 0.001}.\n",
      "2021-01-26 09:25:37,617 Trainer INFO: Epoch[29] Complete. Time taken: 00:03:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.664763367773401\n",
      "val loss 0.6771520896322408\n",
      "validation roc auc [0.50555556 0.50458716] 29\n",
      "train roc auc [0.5 0.5] 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-26 09:26:20,299 Trainer ERROR: Engine run is terminating due to exception: .\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-5270feba9838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ready ?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrunutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPROJECT_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/nna/src/nna/exp/runutils.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(model, dataloaders, optimizer, criterion, metrics, device, config, wandb_project_name, run_name)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;31m#     kick everything off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0mwandb_logger_ins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Engine run is terminating due to exception: %s.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    728\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/nna/src/nna/exp/runutils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-7b1cd6b0f521>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mdb_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAmplitudeToDB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"power\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmelspect_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0man_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#librosa version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/torchaudio/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, waveform)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMel\u001b[0m \u001b[0mfrequency\u001b[0m \u001b[0mspectrogram\u001b[0m \u001b[0mof\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mn_mels\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \"\"\"\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0mspecgram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         \u001b[0mmel_specgram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmel_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspecgram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmel_specgram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/torchaudio/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, waveform)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \"\"\"\n\u001b[1;32m     83\u001b[0m         return F.spectrogram(waveform, self.pad, self.window, self.n_fft, self.hop_length,\n\u001b[0;32m---> 84\u001b[0;31m                              self.win_length, self.power, self.normalized)\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/torchaudio/functional.py\u001b[0m in \u001b[0;36mspectrogram\u001b[0;34m(waveform, pad, window, n_fft, hop_length, win_length, power, normalized)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mspec_f\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpower\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mspec_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplex_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mspec_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/torchaudio/functional.py\u001b[0m in \u001b[0;36mcomplex_norm\u001b[0;34m(complex_tensor, power)\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;31m# Replace by torch.norm once issue is fixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;31m# https://github.com/pytorch/pytorch/issues/34279\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcomplex_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('ready ?')\n",
    "runutils.run(model, dataloaders, optimizer, criterion, metrics, device,config, runconfigs.PROJECT_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example_input = (torch.ones((1,1,h_w[0]*h_w[1]))*-32767)\n",
    "example_input = example_input.float().to(device)\n",
    "out=model(example_input)\n",
    "out\n",
    "\n",
    "activated_output_transform((out,out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor([10,10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(model.fc1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "input = torch.tensor([100.0,100,100], requires_grad=True)\n",
    "# target = torch.empty(3).random_(2)\n",
    "target = torch.ones(3)\n",
    "output = loss((input), target)\n",
    "input,target,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soundenv3",
   "language": "python",
   "name": "soundenv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
